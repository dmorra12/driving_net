libdc1394 error: Failed to initialize libdc1394
I0503 04:13:21.809370  2066 caffe.cpp:185] Using GPUs 0
I0503 04:13:22.165609  2066 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 450000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "/home/user012/caffe/models/driving_caffenet/driving_caffenet"
solver_mode: GPU
device_id: 0
net: "/home/user012/caffe/models/driving_caffenet/train_val.prototxt"
I0503 04:13:22.168418  2066 solver.cpp:91] Creating training net from net file: /home/user012/caffe/models/driving_caffenet/train_val.prototxt
I0503 04:13:22.171169  2066 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0503 04:13:22.171203  2066 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0503 04:13:22.171407  2066 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "data/driving/drivingnet_mean.binaryproto"
  }
  data_param {
    source: "data/driving/driving_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0503 04:13:22.171561  2066 layer_factory.hpp:77] Creating layer data
I0503 04:13:22.172263  2066 net.cpp:106] Creating Layer data
I0503 04:13:22.172312  2066 net.cpp:411] data -> data
I0503 04:13:22.172359  2066 net.cpp:411] data -> label
I0503 04:13:22.172385  2066 data_transformer.cpp:25] Loading mean file from: data/driving/drivingnet_mean.binaryproto
I0503 04:13:22.176445  2072 db_lmdb.cpp:38] Opened lmdb data/driving/driving_train_lmdb
I0503 04:13:22.185572  2066 data_layer.cpp:41] output data size: 256,3,227,227
I0503 04:13:22.551507  2066 net.cpp:150] Setting up data
I0503 04:13:22.551576  2066 net.cpp:157] Top shape: 256 3 227 227 (39574272)
I0503 04:13:22.551587  2066 net.cpp:157] Top shape: 256 (256)
I0503 04:13:22.551592  2066 net.cpp:165] Memory required for data: 158298112
I0503 04:13:22.551611  2066 layer_factory.hpp:77] Creating layer conv1
I0503 04:13:22.551648  2066 net.cpp:106] Creating Layer conv1
I0503 04:13:22.551658  2066 net.cpp:454] conv1 <- data
I0503 04:13:22.551676  2066 net.cpp:411] conv1 -> conv1
I0503 04:13:22.572789  2066 net.cpp:150] Setting up conv1
I0503 04:13:22.572809  2066 net.cpp:157] Top shape: 256 96 55 55 (74342400)
I0503 04:13:22.572815  2066 net.cpp:165] Memory required for data: 455667712
I0503 04:13:22.572839  2066 layer_factory.hpp:77] Creating layer relu1
I0503 04:13:22.572855  2066 net.cpp:106] Creating Layer relu1
I0503 04:13:22.572861  2066 net.cpp:454] relu1 <- conv1
I0503 04:13:22.572870  2066 net.cpp:397] relu1 -> conv1 (in-place)
I0503 04:13:22.572885  2066 net.cpp:150] Setting up relu1
I0503 04:13:22.572893  2066 net.cpp:157] Top shape: 256 96 55 55 (74342400)
I0503 04:13:22.572898  2066 net.cpp:165] Memory required for data: 753037312
I0503 04:13:22.572902  2066 layer_factory.hpp:77] Creating layer pool1
I0503 04:13:22.572914  2066 net.cpp:106] Creating Layer pool1
I0503 04:13:22.572919  2066 net.cpp:454] pool1 <- conv1
I0503 04:13:22.572926  2066 net.cpp:411] pool1 -> pool1
I0503 04:13:22.572981  2066 net.cpp:150] Setting up pool1
I0503 04:13:22.572993  2066 net.cpp:157] Top shape: 256 96 27 27 (17915904)
I0503 04:13:22.572998  2066 net.cpp:165] Memory required for data: 824700928
I0503 04:13:22.573004  2066 layer_factory.hpp:77] Creating layer norm1
I0503 04:13:22.573016  2066 net.cpp:106] Creating Layer norm1
I0503 04:13:22.573027  2066 net.cpp:454] norm1 <- pool1
I0503 04:13:22.573035  2066 net.cpp:411] norm1 -> norm1
I0503 04:13:22.573102  2066 net.cpp:150] Setting up norm1
I0503 04:13:22.573114  2066 net.cpp:157] Top shape: 256 96 27 27 (17915904)
I0503 04:13:22.573118  2066 net.cpp:165] Memory required for data: 896364544
I0503 04:13:22.573124  2066 layer_factory.hpp:77] Creating layer conv2
I0503 04:13:22.573137  2066 net.cpp:106] Creating Layer conv2
I0503 04:13:22.573142  2066 net.cpp:454] conv2 <- norm1
I0503 04:13:22.573151  2066 net.cpp:411] conv2 -> conv2
I0503 04:13:22.586422  2066 net.cpp:150] Setting up conv2
I0503 04:13:22.586465  2066 net.cpp:157] Top shape: 256 256 27 27 (47775744)
I0503 04:13:22.586472  2066 net.cpp:165] Memory required for data: 1087467520
I0503 04:13:22.586491  2066 layer_factory.hpp:77] Creating layer relu2
I0503 04:13:22.586506  2066 net.cpp:106] Creating Layer relu2
I0503 04:13:22.586513  2066 net.cpp:454] relu2 <- conv2
I0503 04:13:22.586526  2066 net.cpp:397] relu2 -> conv2 (in-place)
I0503 04:13:22.586544  2066 net.cpp:150] Setting up relu2
I0503 04:13:22.586550  2066 net.cpp:157] Top shape: 256 256 27 27 (47775744)
I0503 04:13:22.586555  2066 net.cpp:165] Memory required for data: 1278570496
I0503 04:13:22.586560  2066 layer_factory.hpp:77] Creating layer pool2
I0503 04:13:22.586571  2066 net.cpp:106] Creating Layer pool2
I0503 04:13:22.586576  2066 net.cpp:454] pool2 <- conv2
I0503 04:13:22.586585  2066 net.cpp:411] pool2 -> pool2
I0503 04:13:22.586626  2066 net.cpp:150] Setting up pool2
I0503 04:13:22.586635  2066 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I0503 04:13:22.586640  2066 net.cpp:165] Memory required for data: 1322872832
I0503 04:13:22.586645  2066 layer_factory.hpp:77] Creating layer norm2
I0503 04:13:22.586660  2066 net.cpp:106] Creating Layer norm2
I0503 04:13:22.586665  2066 net.cpp:454] norm2 <- pool2
I0503 04:13:22.586673  2066 net.cpp:411] norm2 -> norm2
I0503 04:13:22.586709  2066 net.cpp:150] Setting up norm2
I0503 04:13:22.586719  2066 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I0503 04:13:22.586725  2066 net.cpp:165] Memory required for data: 1367175168
I0503 04:13:22.586730  2066 layer_factory.hpp:77] Creating layer conv3
I0503 04:13:22.586746  2066 net.cpp:106] Creating Layer conv3
I0503 04:13:22.586751  2066 net.cpp:454] conv3 <- norm2
I0503 04:13:22.586762  2066 net.cpp:411] conv3 -> conv3
I0503 04:13:22.623563  2066 net.cpp:150] Setting up conv3
I0503 04:13:22.623608  2066 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I0503 04:13:22.623615  2066 net.cpp:165] Memory required for data: 1433628672
I0503 04:13:22.623633  2066 layer_factory.hpp:77] Creating layer relu3
I0503 04:13:22.623656  2066 net.cpp:106] Creating Layer relu3
I0503 04:13:22.623663  2066 net.cpp:454] relu3 <- conv3
I0503 04:13:22.623677  2066 net.cpp:397] relu3 -> conv3 (in-place)
I0503 04:13:22.623693  2066 net.cpp:150] Setting up relu3
I0503 04:13:22.623700  2066 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I0503 04:13:22.623705  2066 net.cpp:165] Memory required for data: 1500082176
I0503 04:13:22.623710  2066 layer_factory.hpp:77] Creating layer conv4
I0503 04:13:22.623726  2066 net.cpp:106] Creating Layer conv4
I0503 04:13:22.623731  2066 net.cpp:454] conv4 <- conv3
I0503 04:13:22.623740  2066 net.cpp:411] conv4 -> conv4
I0503 04:13:22.651816  2066 net.cpp:150] Setting up conv4
I0503 04:13:22.651870  2066 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I0503 04:13:22.651877  2066 net.cpp:165] Memory required for data: 1566535680
I0503 04:13:22.651895  2066 layer_factory.hpp:77] Creating layer relu4
I0503 04:13:22.651911  2066 net.cpp:106] Creating Layer relu4
I0503 04:13:22.651918  2066 net.cpp:454] relu4 <- conv4
I0503 04:13:22.651932  2066 net.cpp:397] relu4 -> conv4 (in-place)
I0503 04:13:22.651950  2066 net.cpp:150] Setting up relu4
I0503 04:13:22.651957  2066 net.cpp:157] Top shape: 256 384 13 13 (16613376)
I0503 04:13:22.651962  2066 net.cpp:165] Memory required for data: 1632989184
I0503 04:13:22.651967  2066 layer_factory.hpp:77] Creating layer conv5
I0503 04:13:22.651990  2066 net.cpp:106] Creating Layer conv5
I0503 04:13:22.651996  2066 net.cpp:454] conv5 <- conv4
I0503 04:13:22.652031  2066 net.cpp:411] conv5 -> conv5
I0503 04:13:22.670279  2066 net.cpp:150] Setting up conv5
I0503 04:13:22.670328  2066 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I0503 04:13:22.670334  2066 net.cpp:165] Memory required for data: 1677291520
I0503 04:13:22.670356  2066 layer_factory.hpp:77] Creating layer relu5
I0503 04:13:22.670373  2066 net.cpp:106] Creating Layer relu5
I0503 04:13:22.670380  2066 net.cpp:454] relu5 <- conv5
I0503 04:13:22.670393  2066 net.cpp:397] relu5 -> conv5 (in-place)
I0503 04:13:22.670410  2066 net.cpp:150] Setting up relu5
I0503 04:13:22.670418  2066 net.cpp:157] Top shape: 256 256 13 13 (11075584)
I0503 04:13:22.670423  2066 net.cpp:165] Memory required for data: 1721593856
I0503 04:13:22.670428  2066 layer_factory.hpp:77] Creating layer pool5
I0503 04:13:22.670439  2066 net.cpp:106] Creating Layer pool5
I0503 04:13:22.670444  2066 net.cpp:454] pool5 <- conv5
I0503 04:13:22.670451  2066 net.cpp:411] pool5 -> pool5
I0503 04:13:22.670498  2066 net.cpp:150] Setting up pool5
I0503 04:13:22.670509  2066 net.cpp:157] Top shape: 256 256 6 6 (2359296)
I0503 04:13:22.670514  2066 net.cpp:165] Memory required for data: 1731031040
I0503 04:13:22.670519  2066 layer_factory.hpp:77] Creating layer fc6
I0503 04:13:22.670547  2066 net.cpp:106] Creating Layer fc6
I0503 04:13:22.670552  2066 net.cpp:454] fc6 <- pool5
I0503 04:13:22.670562  2066 net.cpp:411] fc6 -> fc6
I0503 04:13:24.300001  2066 net.cpp:150] Setting up fc6
I0503 04:13:24.300053  2066 net.cpp:157] Top shape: 256 4096 (1048576)
I0503 04:13:24.300060  2066 net.cpp:165] Memory required for data: 1735225344
I0503 04:13:24.300076  2066 layer_factory.hpp:77] Creating layer relu6
I0503 04:13:24.300093  2066 net.cpp:106] Creating Layer relu6
I0503 04:13:24.300101  2066 net.cpp:454] relu6 <- fc6
I0503 04:13:24.300115  2066 net.cpp:397] relu6 -> fc6 (in-place)
I0503 04:13:24.300134  2066 net.cpp:150] Setting up relu6
I0503 04:13:24.300140  2066 net.cpp:157] Top shape: 256 4096 (1048576)
I0503 04:13:24.300145  2066 net.cpp:165] Memory required for data: 1739419648
I0503 04:13:24.300150  2066 layer_factory.hpp:77] Creating layer drop6
I0503 04:13:24.300163  2066 net.cpp:106] Creating Layer drop6
I0503 04:13:24.300168  2066 net.cpp:454] drop6 <- fc6
I0503 04:13:24.300176  2066 net.cpp:397] drop6 -> fc6 (in-place)
I0503 04:13:24.300211  2066 net.cpp:150] Setting up drop6
I0503 04:13:24.300221  2066 net.cpp:157] Top shape: 256 4096 (1048576)
I0503 04:13:24.300226  2066 net.cpp:165] Memory required for data: 1743613952
I0503 04:13:24.300232  2066 layer_factory.hpp:77] Creating layer fc7
I0503 04:13:24.300246  2066 net.cpp:106] Creating Layer fc7
I0503 04:13:24.300251  2066 net.cpp:454] fc7 <- fc6
I0503 04:13:24.300261  2066 net.cpp:411] fc7 -> fc7
I0503 04:13:25.016433  2066 net.cpp:150] Setting up fc7
I0503 04:13:25.017115  2066 net.cpp:157] Top shape: 256 4096 (1048576)
I0503 04:13:25.017127  2066 net.cpp:165] Memory required for data: 1747808256
I0503 04:13:25.017143  2066 layer_factory.hpp:77] Creating layer relu7
I0503 04:13:25.017161  2066 net.cpp:106] Creating Layer relu7
I0503 04:13:25.017169  2066 net.cpp:454] relu7 <- fc7
I0503 04:13:25.017184  2066 net.cpp:397] relu7 -> fc7 (in-place)
I0503 04:13:25.017201  2066 net.cpp:150] Setting up relu7
I0503 04:13:25.017209  2066 net.cpp:157] Top shape: 256 4096 (1048576)
I0503 04:13:25.017213  2066 net.cpp:165] Memory required for data: 1752002560
I0503 04:13:25.017221  2066 layer_factory.hpp:77] Creating layer drop7
I0503 04:13:25.017232  2066 net.cpp:106] Creating Layer drop7
I0503 04:13:25.017238  2066 net.cpp:454] drop7 <- fc7
I0503 04:13:25.017246  2066 net.cpp:397] drop7 -> fc7 (in-place)
I0503 04:13:25.017280  2066 net.cpp:150] Setting up drop7
I0503 04:13:25.017290  2066 net.cpp:157] Top shape: 256 4096 (1048576)
I0503 04:13:25.017295  2066 net.cpp:165] Memory required for data: 1756196864
I0503 04:13:25.017302  2066 layer_factory.hpp:77] Creating layer fc8
I0503 04:13:25.017321  2066 net.cpp:106] Creating Layer fc8
I0503 04:13:25.017326  2066 net.cpp:454] fc8 <- fc7
I0503 04:13:25.017361  2066 net.cpp:411] fc8 -> fc8
I0503 04:13:25.192411  2066 net.cpp:150] Setting up fc8
I0503 04:13:25.192459  2066 net.cpp:157] Top shape: 256 1000 (256000)
I0503 04:13:25.192466  2066 net.cpp:165] Memory required for data: 1757220864
I0503 04:13:25.192478  2066 layer_factory.hpp:77] Creating layer loss
I0503 04:13:25.192494  2066 net.cpp:106] Creating Layer loss
I0503 04:13:25.192502  2066 net.cpp:454] loss <- fc8
I0503 04:13:25.192512  2066 net.cpp:454] loss <- label
I0503 04:13:25.192525  2066 net.cpp:411] loss -> loss
I0503 04:13:25.192561  2066 layer_factory.hpp:77] Creating layer loss
I0503 04:13:25.193364  2066 net.cpp:150] Setting up loss
I0503 04:13:25.193378  2066 net.cpp:157] Top shape: (1)
I0503 04:13:25.193384  2066 net.cpp:160]     with loss weight 1
I0503 04:13:25.193420  2066 net.cpp:165] Memory required for data: 1757220868
I0503 04:13:25.193426  2066 net.cpp:226] loss needs backward computation.
I0503 04:13:25.193433  2066 net.cpp:226] fc8 needs backward computation.
I0503 04:13:25.193439  2066 net.cpp:226] drop7 needs backward computation.
I0503 04:13:25.193444  2066 net.cpp:226] relu7 needs backward computation.
I0503 04:13:25.193449  2066 net.cpp:226] fc7 needs backward computation.
I0503 04:13:25.193454  2066 net.cpp:226] drop6 needs backward computation.
I0503 04:13:25.193459  2066 net.cpp:226] relu6 needs backward computation.
I0503 04:13:25.193462  2066 net.cpp:226] fc6 needs backward computation.
I0503 04:13:25.193467  2066 net.cpp:226] pool5 needs backward computation.
I0503 04:13:25.193473  2066 net.cpp:226] relu5 needs backward computation.
I0503 04:13:25.193478  2066 net.cpp:226] conv5 needs backward computation.
I0503 04:13:25.193483  2066 net.cpp:226] relu4 needs backward computation.
I0503 04:13:25.193488  2066 net.cpp:226] conv4 needs backward computation.
I0503 04:13:25.193493  2066 net.cpp:226] relu3 needs backward computation.
I0503 04:13:25.193498  2066 net.cpp:226] conv3 needs backward computation.
I0503 04:13:25.193505  2066 net.cpp:226] norm2 needs backward computation.
I0503 04:13:25.193509  2066 net.cpp:226] pool2 needs backward computation.
I0503 04:13:25.193514  2066 net.cpp:226] relu2 needs backward computation.
I0503 04:13:25.193519  2066 net.cpp:226] conv2 needs backward computation.
I0503 04:13:25.193524  2066 net.cpp:226] norm1 needs backward computation.
I0503 04:13:25.193529  2066 net.cpp:226] pool1 needs backward computation.
I0503 04:13:25.193534  2066 net.cpp:226] relu1 needs backward computation.
I0503 04:13:25.193539  2066 net.cpp:226] conv1 needs backward computation.
I0503 04:13:25.193545  2066 net.cpp:228] data does not need backward computation.
I0503 04:13:25.193549  2066 net.cpp:270] This network produces output loss
I0503 04:13:25.193567  2066 net.cpp:283] Network initialization done.
I0503 04:13:25.194941  2066 solver.cpp:181] Creating test net (#0) specified by net file: /home/user012/caffe/models/driving_caffenet/train_val.prototxt
I0503 04:13:25.194990  2066 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0503 04:13:25.195204  2066 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "data/driving/drivingnet_mean.binaryproto"
  }
  data_param {
    source: "data/driving/driving_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0503 04:13:25.195361  2066 layer_factory.hpp:77] Creating layer data
I0503 04:13:25.195523  2066 net.cpp:106] Creating Layer data
I0503 04:13:25.195538  2066 net.cpp:411] data -> data
I0503 04:13:25.195550  2066 net.cpp:411] data -> label
I0503 04:13:25.195570  2066 data_transformer.cpp:25] Loading mean file from: data/driving/drivingnet_mean.binaryproto
I0503 04:13:25.224534  2094 db_lmdb.cpp:38] Opened lmdb data/driving/driving_val_lmdb
I0503 04:13:25.313336  2066 data_layer.cpp:41] output data size: 50,3,227,227
I0503 04:13:25.405447  2066 net.cpp:150] Setting up data
I0503 04:13:25.405504  2066 net.cpp:157] Top shape: 50 3 227 227 (7729350)
I0503 04:13:25.405514  2066 net.cpp:157] Top shape: 50 (50)
I0503 04:13:25.405520  2066 net.cpp:165] Memory required for data: 30917600
I0503 04:13:25.405534  2066 layer_factory.hpp:77] Creating layer label_data_1_split
I0503 04:13:25.405553  2066 net.cpp:106] Creating Layer label_data_1_split
I0503 04:13:25.405560  2066 net.cpp:454] label_data_1_split <- label
I0503 04:13:25.405573  2066 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0503 04:13:25.405591  2066 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0503 04:13:25.405649  2066 net.cpp:150] Setting up label_data_1_split
I0503 04:13:25.405660  2066 net.cpp:157] Top shape: 50 (50)
I0503 04:13:25.405668  2066 net.cpp:157] Top shape: 50 (50)
I0503 04:13:25.405673  2066 net.cpp:165] Memory required for data: 30918000
I0503 04:13:25.405678  2066 layer_factory.hpp:77] Creating layer conv1
I0503 04:13:25.405741  2066 net.cpp:106] Creating Layer conv1
I0503 04:13:25.405752  2066 net.cpp:454] conv1 <- data
I0503 04:13:25.405768  2066 net.cpp:411] conv1 -> conv1
I0503 04:13:25.411746  2066 net.cpp:150] Setting up conv1
I0503 04:13:25.411762  2066 net.cpp:157] Top shape: 50 96 55 55 (14520000)
I0503 04:13:25.411768  2066 net.cpp:165] Memory required for data: 88998000
I0503 04:13:25.411783  2066 layer_factory.hpp:77] Creating layer relu1
I0503 04:13:25.411815  2066 net.cpp:106] Creating Layer relu1
I0503 04:13:25.411828  2066 net.cpp:454] relu1 <- conv1
I0503 04:13:25.411839  2066 net.cpp:397] relu1 -> conv1 (in-place)
I0503 04:13:25.411850  2066 net.cpp:150] Setting up relu1
I0503 04:13:25.411857  2066 net.cpp:157] Top shape: 50 96 55 55 (14520000)
I0503 04:13:25.411862  2066 net.cpp:165] Memory required for data: 147078000
I0503 04:13:25.411867  2066 layer_factory.hpp:77] Creating layer pool1
I0503 04:13:25.411880  2066 net.cpp:106] Creating Layer pool1
I0503 04:13:25.411885  2066 net.cpp:454] pool1 <- conv1
I0503 04:13:25.411892  2066 net.cpp:411] pool1 -> pool1
I0503 04:13:25.411937  2066 net.cpp:150] Setting up pool1
I0503 04:13:25.411948  2066 net.cpp:157] Top shape: 50 96 27 27 (3499200)
I0503 04:13:25.411953  2066 net.cpp:165] Memory required for data: 161074800
I0503 04:13:25.411958  2066 layer_factory.hpp:77] Creating layer norm1
I0503 04:13:25.411969  2066 net.cpp:106] Creating Layer norm1
I0503 04:13:25.411975  2066 net.cpp:454] norm1 <- pool1
I0503 04:13:25.411983  2066 net.cpp:411] norm1 -> norm1
I0503 04:13:25.412022  2066 net.cpp:150] Setting up norm1
I0503 04:13:25.412031  2066 net.cpp:157] Top shape: 50 96 27 27 (3499200)
I0503 04:13:25.412036  2066 net.cpp:165] Memory required for data: 175071600
I0503 04:13:25.412041  2066 layer_factory.hpp:77] Creating layer conv2
I0503 04:13:25.412055  2066 net.cpp:106] Creating Layer conv2
I0503 04:13:25.412060  2066 net.cpp:454] conv2 <- norm1
I0503 04:13:25.412070  2066 net.cpp:411] conv2 -> conv2
I0503 04:13:25.428112  2066 net.cpp:150] Setting up conv2
I0503 04:13:25.428165  2066 net.cpp:157] Top shape: 50 256 27 27 (9331200)
I0503 04:13:25.428177  2066 net.cpp:165] Memory required for data: 212396400
I0503 04:13:25.428200  2066 layer_factory.hpp:77] Creating layer relu2
I0503 04:13:25.428216  2066 net.cpp:106] Creating Layer relu2
I0503 04:13:25.428225  2066 net.cpp:454] relu2 <- conv2
I0503 04:13:25.428237  2066 net.cpp:397] relu2 -> conv2 (in-place)
I0503 04:13:25.428261  2066 net.cpp:150] Setting up relu2
I0503 04:13:25.428290  2066 net.cpp:157] Top shape: 50 256 27 27 (9331200)
I0503 04:13:25.428295  2066 net.cpp:165] Memory required for data: 249721200
I0503 04:13:25.428300  2066 layer_factory.hpp:77] Creating layer pool2
I0503 04:13:25.428314  2066 net.cpp:106] Creating Layer pool2
I0503 04:13:25.428319  2066 net.cpp:454] pool2 <- conv2
I0503 04:13:25.428328  2066 net.cpp:411] pool2 -> pool2
I0503 04:13:25.428380  2066 net.cpp:150] Setting up pool2
I0503 04:13:25.428390  2066 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I0503 04:13:25.428395  2066 net.cpp:165] Memory required for data: 258374000
I0503 04:13:25.428400  2066 layer_factory.hpp:77] Creating layer norm2
I0503 04:13:25.428412  2066 net.cpp:106] Creating Layer norm2
I0503 04:13:25.428417  2066 net.cpp:454] norm2 <- pool2
I0503 04:13:25.428426  2066 net.cpp:411] norm2 -> norm2
I0503 04:13:25.428469  2066 net.cpp:150] Setting up norm2
I0503 04:13:25.428479  2066 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I0503 04:13:25.428484  2066 net.cpp:165] Memory required for data: 267026800
I0503 04:13:25.428489  2066 layer_factory.hpp:77] Creating layer conv3
I0503 04:13:25.428506  2066 net.cpp:106] Creating Layer conv3
I0503 04:13:25.428511  2066 net.cpp:454] conv3 <- norm2
I0503 04:13:25.428520  2066 net.cpp:411] conv3 -> conv3
I0503 04:13:25.428596  2099 blocking_queue.cpp:50] Waiting for data
I0503 04:13:25.473915  2066 net.cpp:150] Setting up conv3
I0503 04:13:25.473958  2066 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0503 04:13:25.473964  2066 net.cpp:165] Memory required for data: 280006000
I0503 04:13:25.473984  2066 layer_factory.hpp:77] Creating layer relu3
I0503 04:13:25.473999  2066 net.cpp:106] Creating Layer relu3
I0503 04:13:25.474007  2066 net.cpp:454] relu3 <- conv3
I0503 04:13:25.474020  2066 net.cpp:397] relu3 -> conv3 (in-place)
I0503 04:13:25.474038  2066 net.cpp:150] Setting up relu3
I0503 04:13:25.474045  2066 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0503 04:13:25.474050  2066 net.cpp:165] Memory required for data: 292985200
I0503 04:13:25.474056  2066 layer_factory.hpp:77] Creating layer conv4
I0503 04:13:25.474069  2066 net.cpp:106] Creating Layer conv4
I0503 04:13:25.474076  2066 net.cpp:454] conv4 <- conv3
I0503 04:13:25.474084  2066 net.cpp:411] conv4 -> conv4
I0503 04:13:25.518507  2066 net.cpp:150] Setting up conv4
I0503 04:13:25.518626  2066 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0503 04:13:25.518667  2066 net.cpp:165] Memory required for data: 305964400
I0503 04:13:25.518753  2066 layer_factory.hpp:77] Creating layer relu4
I0503 04:13:25.518798  2066 net.cpp:106] Creating Layer relu4
I0503 04:13:25.518860  2066 net.cpp:454] relu4 <- conv4
I0503 04:13:25.518882  2066 net.cpp:397] relu4 -> conv4 (in-place)
I0503 04:13:25.518900  2066 net.cpp:150] Setting up relu4
I0503 04:13:25.518908  2066 net.cpp:157] Top shape: 50 384 13 13 (3244800)
I0503 04:13:25.518913  2066 net.cpp:165] Memory required for data: 318943600
I0503 04:13:25.518918  2066 layer_factory.hpp:77] Creating layer conv5
I0503 04:13:25.518966  2066 net.cpp:106] Creating Layer conv5
I0503 04:13:25.518978  2066 net.cpp:454] conv5 <- conv4
I0503 04:13:25.518990  2066 net.cpp:411] conv5 -> conv5
I0503 04:13:25.548120  2066 net.cpp:150] Setting up conv5
I0503 04:13:25.548238  2066 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I0503 04:13:25.548250  2066 net.cpp:165] Memory required for data: 327596400
I0503 04:13:25.548318  2066 layer_factory.hpp:77] Creating layer relu5
I0503 04:13:25.548343  2066 net.cpp:106] Creating Layer relu5
I0503 04:13:25.548352  2066 net.cpp:454] relu5 <- conv5
I0503 04:13:25.548363  2066 net.cpp:397] relu5 -> conv5 (in-place)
I0503 04:13:25.548379  2066 net.cpp:150] Setting up relu5
I0503 04:13:25.548387  2066 net.cpp:157] Top shape: 50 256 13 13 (2163200)
I0503 04:13:25.548390  2066 net.cpp:165] Memory required for data: 336249200
I0503 04:13:25.548395  2066 layer_factory.hpp:77] Creating layer pool5
I0503 04:13:25.548410  2066 net.cpp:106] Creating Layer pool5
I0503 04:13:25.548420  2066 net.cpp:454] pool5 <- conv5
I0503 04:13:25.548429  2066 net.cpp:411] pool5 -> pool5
I0503 04:13:25.548646  2066 net.cpp:150] Setting up pool5
I0503 04:13:25.548660  2066 net.cpp:157] Top shape: 50 256 6 6 (460800)
I0503 04:13:25.548665  2066 net.cpp:165] Memory required for data: 338092400
I0503 04:13:25.548669  2066 layer_factory.hpp:77] Creating layer fc6
I0503 04:13:25.548682  2066 net.cpp:106] Creating Layer fc6
I0503 04:13:25.548688  2066 net.cpp:454] fc6 <- pool5
I0503 04:13:25.548697  2066 net.cpp:411] fc6 -> fc6
I0503 04:13:27.299787  2066 net.cpp:150] Setting up fc6
I0503 04:13:27.299849  2066 net.cpp:157] Top shape: 50 4096 (204800)
I0503 04:13:27.299856  2066 net.cpp:165] Memory required for data: 338911600
I0503 04:13:27.299871  2066 layer_factory.hpp:77] Creating layer relu6
I0503 04:13:27.299891  2066 net.cpp:106] Creating Layer relu6
I0503 04:13:27.299899  2066 net.cpp:454] relu6 <- fc6
I0503 04:13:27.299913  2066 net.cpp:397] relu6 -> fc6 (in-place)
I0503 04:13:27.299932  2066 net.cpp:150] Setting up relu6
I0503 04:13:27.299938  2066 net.cpp:157] Top shape: 50 4096 (204800)
I0503 04:13:27.299942  2066 net.cpp:165] Memory required for data: 339730800
I0503 04:13:27.299947  2066 layer_factory.hpp:77] Creating layer drop6
I0503 04:13:27.299959  2066 net.cpp:106] Creating Layer drop6
I0503 04:13:27.299964  2066 net.cpp:454] drop6 <- fc6
I0503 04:13:27.299971  2066 net.cpp:397] drop6 -> fc6 (in-place)
I0503 04:13:27.300007  2066 net.cpp:150] Setting up drop6
I0503 04:13:27.300017  2066 net.cpp:157] Top shape: 50 4096 (204800)
I0503 04:13:27.300021  2066 net.cpp:165] Memory required for data: 340550000
I0503 04:13:27.300027  2066 layer_factory.hpp:77] Creating layer fc7
I0503 04:13:27.300040  2066 net.cpp:106] Creating Layer fc7
I0503 04:13:27.300045  2066 net.cpp:454] fc7 <- fc6
I0503 04:13:27.300058  2066 net.cpp:411] fc7 -> fc7
I0503 04:13:27.985086  2066 net.cpp:150] Setting up fc7
I0503 04:13:27.985138  2066 net.cpp:157] Top shape: 50 4096 (204800)
I0503 04:13:27.985146  2066 net.cpp:165] Memory required for data: 341369200
I0503 04:13:27.985160  2066 layer_factory.hpp:77] Creating layer relu7
I0503 04:13:27.985177  2066 net.cpp:106] Creating Layer relu7
I0503 04:13:27.985185  2066 net.cpp:454] relu7 <- fc7
I0503 04:13:27.985204  2066 net.cpp:397] relu7 -> fc7 (in-place)
I0503 04:13:27.985224  2066 net.cpp:150] Setting up relu7
I0503 04:13:27.985230  2066 net.cpp:157] Top shape: 50 4096 (204800)
I0503 04:13:27.985234  2066 net.cpp:165] Memory required for data: 342188400
I0503 04:13:27.985239  2066 layer_factory.hpp:77] Creating layer drop7
I0503 04:13:27.985251  2066 net.cpp:106] Creating Layer drop7
I0503 04:13:27.985256  2066 net.cpp:454] drop7 <- fc7
I0503 04:13:27.985263  2066 net.cpp:397] drop7 -> fc7 (in-place)
I0503 04:13:27.985299  2066 net.cpp:150] Setting up drop7
I0503 04:13:27.985311  2066 net.cpp:157] Top shape: 50 4096 (204800)
I0503 04:13:27.985314  2066 net.cpp:165] Memory required for data: 343007600
I0503 04:13:27.985319  2066 layer_factory.hpp:77] Creating layer fc8
I0503 04:13:27.985333  2066 net.cpp:106] Creating Layer fc8
I0503 04:13:27.985338  2066 net.cpp:454] fc8 <- fc7
I0503 04:13:27.985348  2066 net.cpp:411] fc8 -> fc8
I0503 04:13:28.153843  2066 net.cpp:150] Setting up fc8
I0503 04:13:28.153892  2066 net.cpp:157] Top shape: 50 1000 (50000)
I0503 04:13:28.153898  2066 net.cpp:165] Memory required for data: 343207600
I0503 04:13:28.153913  2066 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0503 04:13:28.153930  2066 net.cpp:106] Creating Layer fc8_fc8_0_split
I0503 04:13:28.153939  2066 net.cpp:454] fc8_fc8_0_split <- fc8
I0503 04:13:28.153952  2066 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0503 04:13:28.153970  2066 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0503 04:13:28.154018  2066 net.cpp:150] Setting up fc8_fc8_0_split
I0503 04:13:28.154028  2066 net.cpp:157] Top shape: 50 1000 (50000)
I0503 04:13:28.154036  2066 net.cpp:157] Top shape: 50 1000 (50000)
I0503 04:13:28.154042  2066 net.cpp:165] Memory required for data: 343607600
I0503 04:13:28.154054  2066 layer_factory.hpp:77] Creating layer accuracy
I0503 04:13:28.154090  2066 net.cpp:106] Creating Layer accuracy
I0503 04:13:28.154096  2066 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0503 04:13:28.154106  2066 net.cpp:454] accuracy <- label_data_1_split_0
I0503 04:13:28.154115  2066 net.cpp:411] accuracy -> accuracy
I0503 04:13:28.154132  2066 net.cpp:150] Setting up accuracy
I0503 04:13:28.154139  2066 net.cpp:157] Top shape: (1)
I0503 04:13:28.154144  2066 net.cpp:165] Memory required for data: 343607604
I0503 04:13:28.154148  2066 layer_factory.hpp:77] Creating layer loss
I0503 04:13:28.154158  2066 net.cpp:106] Creating Layer loss
I0503 04:13:28.154163  2066 net.cpp:454] loss <- fc8_fc8_0_split_1
I0503 04:13:28.154170  2066 net.cpp:454] loss <- label_data_1_split_1
I0503 04:13:28.154177  2066 net.cpp:411] loss -> loss
I0503 04:13:28.154189  2066 layer_factory.hpp:77] Creating layer loss
I0503 04:13:28.154350  2066 net.cpp:150] Setting up loss
I0503 04:13:28.154361  2066 net.cpp:157] Top shape: (1)
I0503 04:13:28.154366  2066 net.cpp:160]     with loss weight 1
I0503 04:13:28.154383  2066 net.cpp:165] Memory required for data: 343607608
I0503 04:13:28.154388  2066 net.cpp:226] loss needs backward computation.
I0503 04:13:28.154398  2066 net.cpp:228] accuracy does not need backward computation.
I0503 04:13:28.154404  2066 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0503 04:13:28.154409  2066 net.cpp:226] fc8 needs backward computation.
I0503 04:13:28.154414  2066 net.cpp:226] drop7 needs backward computation.
I0503 04:13:28.154419  2066 net.cpp:226] relu7 needs backward computation.
I0503 04:13:28.154424  2066 net.cpp:226] fc7 needs backward computation.
I0503 04:13:28.154429  2066 net.cpp:226] drop6 needs backward computation.
I0503 04:13:28.154433  2066 net.cpp:226] relu6 needs backward computation.
I0503 04:13:28.154438  2066 net.cpp:226] fc6 needs backward computation.
I0503 04:13:28.154443  2066 net.cpp:226] pool5 needs backward computation.
I0503 04:13:28.154448  2066 net.cpp:226] relu5 needs backward computation.
I0503 04:13:28.154453  2066 net.cpp:226] conv5 needs backward computation.
I0503 04:13:28.154458  2066 net.cpp:226] relu4 needs backward computation.
I0503 04:13:28.154464  2066 net.cpp:226] conv4 needs backward computation.
I0503 04:13:28.154469  2066 net.cpp:226] relu3 needs backward computation.
I0503 04:13:28.154474  2066 net.cpp:226] conv3 needs backward computation.
I0503 04:13:28.154479  2066 net.cpp:226] norm2 needs backward computation.
I0503 04:13:28.154484  2066 net.cpp:226] pool2 needs backward computation.
I0503 04:13:28.154489  2066 net.cpp:226] relu2 needs backward computation.
I0503 04:13:28.154494  2066 net.cpp:226] conv2 needs backward computation.
I0503 04:13:28.154498  2066 net.cpp:226] norm1 needs backward computation.
I0503 04:13:28.154503  2066 net.cpp:226] pool1 needs backward computation.
I0503 04:13:28.154508  2066 net.cpp:226] relu1 needs backward computation.
I0503 04:13:28.154512  2066 net.cpp:226] conv1 needs backward computation.
I0503 04:13:28.154518  2066 net.cpp:228] label_data_1_split does not need backward computation.
I0503 04:13:28.154523  2066 net.cpp:228] data does not need backward computation.
I0503 04:13:28.154528  2066 net.cpp:270] This network produces output accuracy
I0503 04:13:28.154533  2066 net.cpp:270] This network produces output loss
I0503 04:13:28.154552  2066 net.cpp:283] Network initialization done.
I0503 04:13:28.154664  2066 solver.cpp:60] Solver scaffolding done.
I0503 04:13:28.155179  2066 caffe.cpp:213] Starting Optimization
I0503 04:13:28.155191  2066 solver.cpp:280] Solving CaffeNet
I0503 04:13:28.155196  2066 solver.cpp:281] Learning Rate Policy: step
I0503 04:13:28.156620  2066 solver.cpp:338] Iteration 0, Testing net (#0)
I0503 04:13:36.360512  2066 blocking_queue.cpp:50] Data layer prefetch queue empty
I0503 04:13:42.913422  2099 blocking_queue.cpp:50] Waiting for data
I0503 04:16:22.264605  2066 solver.cpp:406]     Test net output #0: accuracy = 0
I0503 04:16:22.265844  2066 solver.cpp:406]     Test net output #1: loss = 7.48565 (* 1 = 7.48565 loss)
I0503 04:16:24.271633  2066 solver.cpp:229] Iteration 0, loss = 7.77057
I0503 04:16:24.271704  2066 solver.cpp:245]     Train net output #0: loss = 7.77057 (* 1 = 7.77057 loss)
I0503 04:16:24.271740  2066 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0503 04:17:07.310051  2066 solver.cpp:229] Iteration 20, loss = 3.77441
I0503 04:17:07.311172  2066 solver.cpp:245]     Train net output #0: loss = 3.77441 (* 1 = 3.77441 loss)
I0503 04:17:07.311190  2066 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0503 04:17:50.341413  2066 solver.cpp:229] Iteration 40, loss = 2.39278
I0503 04:17:50.342576  2066 solver.cpp:245]     Train net output #0: loss = 2.39278 (* 1 = 2.39278 loss)
I0503 04:17:50.342593  2066 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0503 04:18:33.368855  2066 solver.cpp:229] Iteration 60, loss = 2.38478
I0503 04:18:33.370087  2066 solver.cpp:245]     Train net output #0: loss = 2.38478 (* 1 = 2.38478 loss)
I0503 04:18:33.370105  2066 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0503 04:19:16.384169  2066 solver.cpp:229] Iteration 80, loss = 2.38192
I0503 04:19:16.385406  2066 solver.cpp:245]     Train net output #0: loss = 2.38192 (* 1 = 2.38192 loss)
I0503 04:19:16.385426  2066 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0503 04:19:59.397038  2066 solver.cpp:229] Iteration 100, loss = 2.36222
I0503 04:19:59.398164  2066 solver.cpp:245]     Train net output #0: loss = 2.36222 (* 1 = 2.36222 loss)
I0503 04:19:59.398180  2066 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0503 04:20:42.410425  2066 solver.cpp:229] Iteration 120, loss = 2.38519
I0503 04:20:42.411633  2066 solver.cpp:245]     Train net output #0: loss = 2.38519 (* 1 = 2.38519 loss)
I0503 04:20:42.411648  2066 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0503 04:21:25.423524  2066 solver.cpp:229] Iteration 140, loss = 2.37529
I0503 04:21:25.424899  2066 solver.cpp:245]     Train net output #0: loss = 2.37529 (* 1 = 2.37529 loss)
I0503 04:21:25.424917  2066 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0503 04:22:08.436266  2066 solver.cpp:229] Iteration 160, loss = 2.36336
I0503 04:22:08.437464  2066 solver.cpp:245]     Train net output #0: loss = 2.36336 (* 1 = 2.36336 loss)
I0503 04:22:08.437482  2066 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0503 04:22:51.447461  2066 solver.cpp:229] Iteration 180, loss = 2.36813
I0503 04:22:51.448736  2066 solver.cpp:245]     Train net output #0: loss = 2.36813 (* 1 = 2.36813 loss)
I0503 04:22:51.448755  2066 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0503 04:23:34.459159  2066 solver.cpp:229] Iteration 200, loss = 2.34849
I0503 04:23:34.460428  2066 solver.cpp:245]     Train net output #0: loss = 2.34849 (* 1 = 2.34849 loss)
I0503 04:23:34.460446  2066 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0503 04:24:17.473006  2066 solver.cpp:229] Iteration 220, loss = 2.3336
I0503 04:24:17.474274  2066 solver.cpp:245]     Train net output #0: loss = 2.3336 (* 1 = 2.3336 loss)
I0503 04:24:17.474292  2066 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0503 04:25:00.482435  2066 solver.cpp:229] Iteration 240, loss = 2.33959
I0503 04:25:00.483780  2066 solver.cpp:245]     Train net output #0: loss = 2.33959 (* 1 = 2.33959 loss)
I0503 04:25:00.483798  2066 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0503 04:25:43.492192  2066 solver.cpp:229] Iteration 260, loss = 2.32358
I0503 04:25:43.493386  2066 solver.cpp:245]     Train net output #0: loss = 2.32358 (* 1 = 2.32358 loss)
I0503 04:25:43.493403  2066 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0503 04:26:26.498118  2066 solver.cpp:229] Iteration 280, loss = 2.33635
I0503 04:26:26.499238  2066 solver.cpp:245]     Train net output #0: loss = 2.33635 (* 1 = 2.33635 loss)
I0503 04:26:26.499254  2066 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0503 04:27:09.504505  2066 solver.cpp:229] Iteration 300, loss = 2.25278
I0503 04:27:09.505604  2066 solver.cpp:245]     Train net output #0: loss = 2.25278 (* 1 = 2.25278 loss)
I0503 04:27:09.505622  2066 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0503 04:27:52.509918  2066 solver.cpp:229] Iteration 320, loss = 2.25897
I0503 04:27:52.511019  2066 solver.cpp:245]     Train net output #0: loss = 2.25897 (* 1 = 2.25897 loss)
I0503 04:27:52.511039  2066 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0503 04:28:35.517019  2066 solver.cpp:229] Iteration 340, loss = 2.21916
I0503 04:28:35.518122  2066 solver.cpp:245]     Train net output #0: loss = 2.21916 (* 1 = 2.21916 loss)
I0503 04:28:35.518141  2066 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0503 04:29:18.523068  2066 solver.cpp:229] Iteration 360, loss = 2.17336
I0503 04:29:18.524143  2066 solver.cpp:245]     Train net output #0: loss = 2.17336 (* 1 = 2.17336 loss)
I0503 04:29:18.524160  2066 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0503 04:30:01.530048  2066 solver.cpp:229] Iteration 380, loss = 2.10477
I0503 04:30:01.531275  2066 solver.cpp:245]     Train net output #0: loss = 2.10477 (* 1 = 2.10477 loss)
I0503 04:30:01.531291  2066 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0503 04:30:44.538918  2066 solver.cpp:229] Iteration 400, loss = 2.06868
I0503 04:30:44.539986  2066 solver.cpp:245]     Train net output #0: loss = 2.06868 (* 1 = 2.06868 loss)
I0503 04:30:44.540004  2066 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0503 04:31:27.547309  2066 solver.cpp:229] Iteration 420, loss = 2.03871
I0503 04:31:27.548468  2066 solver.cpp:245]     Train net output #0: loss = 2.03871 (* 1 = 2.03871 loss)
I0503 04:31:27.548485  2066 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0503 04:32:10.557438  2066 solver.cpp:229] Iteration 440, loss = 2.06309
I0503 04:32:10.558647  2066 solver.cpp:245]     Train net output #0: loss = 2.06309 (* 1 = 2.06309 loss)
I0503 04:32:10.558665  2066 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0503 04:32:53.568634  2066 solver.cpp:229] Iteration 460, loss = 1.89361
I0503 04:32:53.569738  2066 solver.cpp:245]     Train net output #0: loss = 1.89361 (* 1 = 1.89361 loss)
I0503 04:32:53.569756  2066 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0503 04:33:36.580183  2066 solver.cpp:229] Iteration 480, loss = 1.91152
I0503 04:33:36.581362  2066 solver.cpp:245]     Train net output #0: loss = 1.91152 (* 1 = 1.91152 loss)
I0503 04:33:36.581379  2066 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0503 04:34:19.589694  2066 solver.cpp:229] Iteration 500, loss = 1.75127
I0503 04:34:19.590759  2066 solver.cpp:245]     Train net output #0: loss = 1.75127 (* 1 = 1.75127 loss)
I0503 04:34:19.590780  2066 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0503 04:35:02.600030  2066 solver.cpp:229] Iteration 520, loss = 1.67197
I0503 04:35:02.601191  2066 solver.cpp:245]     Train net output #0: loss = 1.67197 (* 1 = 1.67197 loss)
I0503 04:35:02.601207  2066 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0503 04:35:45.608947  2066 solver.cpp:229] Iteration 540, loss = 1.60341
I0503 04:35:45.609951  2066 solver.cpp:245]     Train net output #0: loss = 1.60341 (* 1 = 1.60341 loss)
I0503 04:35:45.609969  2066 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0503 04:36:28.618041  2066 solver.cpp:229] Iteration 560, loss = 1.3827
I0503 04:36:28.619177  2066 solver.cpp:245]     Train net output #0: loss = 1.3827 (* 1 = 1.3827 loss)
I0503 04:36:28.619194  2066 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0503 04:37:11.628595  2066 solver.cpp:229] Iteration 580, loss = 1.41254
I0503 04:37:11.629752  2066 solver.cpp:245]     Train net output #0: loss = 1.41254 (* 1 = 1.41254 loss)
I0503 04:37:11.629768  2066 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0503 04:37:54.641197  2066 solver.cpp:229] Iteration 600, loss = 1.38797
I0503 04:37:54.642230  2066 solver.cpp:245]     Train net output #0: loss = 1.38797 (* 1 = 1.38797 loss)
I0503 04:37:54.642247  2066 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0503 04:38:37.655557  2066 solver.cpp:229] Iteration 620, loss = 1.26055
I0503 04:38:37.656592  2066 solver.cpp:245]     Train net output #0: loss = 1.26055 (* 1 = 1.26055 loss)
I0503 04:38:37.656610  2066 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0503 04:39:20.672592  2066 solver.cpp:229] Iteration 640, loss = 1.19143
I0503 04:39:20.673764  2066 solver.cpp:245]     Train net output #0: loss = 1.19143 (* 1 = 1.19143 loss)
I0503 04:39:20.673782  2066 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0503 04:40:03.690160  2066 solver.cpp:229] Iteration 660, loss = 1.0657
I0503 04:40:03.691473  2066 solver.cpp:245]     Train net output #0: loss = 1.0657 (* 1 = 1.0657 loss)
I0503 04:40:03.691491  2066 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0503 04:40:46.706470  2066 solver.cpp:229] Iteration 680, loss = 0.899729
I0503 04:40:46.707658  2066 solver.cpp:245]     Train net output #0: loss = 0.899729 (* 1 = 0.899729 loss)
I0503 04:40:46.707674  2066 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0503 04:41:29.725042  2066 solver.cpp:229] Iteration 700, loss = 0.88512
I0503 04:41:29.726253  2066 solver.cpp:245]     Train net output #0: loss = 0.88512 (* 1 = 0.88512 loss)
I0503 04:41:29.726271  2066 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0503 04:42:12.743962  2066 solver.cpp:229] Iteration 720, loss = 0.900271
I0503 04:42:12.745133  2066 solver.cpp:245]     Train net output #0: loss = 0.900271 (* 1 = 0.900271 loss)
I0503 04:42:12.745151  2066 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0503 04:42:55.762956  2066 solver.cpp:229] Iteration 740, loss = 0.736218
I0503 04:42:55.764031  2066 solver.cpp:245]     Train net output #0: loss = 0.736218 (* 1 = 0.736218 loss)
I0503 04:42:55.764048  2066 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0503 04:43:38.784313  2066 solver.cpp:229] Iteration 760, loss = 0.751149
I0503 04:43:38.785411  2066 solver.cpp:245]     Train net output #0: loss = 0.751149 (* 1 = 0.751149 loss)
I0503 04:43:38.785428  2066 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0503 04:44:21.803841  2066 solver.cpp:229] Iteration 780, loss = 0.681796
I0503 04:44:21.804957  2066 solver.cpp:245]     Train net output #0: loss = 0.681796 (* 1 = 0.681796 loss)
I0503 04:44:21.804976  2066 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0503 04:45:04.825364  2066 solver.cpp:229] Iteration 800, loss = 0.664217
I0503 04:45:04.826526  2066 solver.cpp:245]     Train net output #0: loss = 0.664217 (* 1 = 0.664217 loss)
I0503 04:45:04.826541  2066 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0503 04:45:47.849459  2066 solver.cpp:229] Iteration 820, loss = 0.572765
I0503 04:45:47.850533  2066 solver.cpp:245]     Train net output #0: loss = 0.572765 (* 1 = 0.572765 loss)
I0503 04:45:47.850551  2066 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0503 04:46:30.871239  2066 solver.cpp:229] Iteration 840, loss = 0.579799
I0503 04:46:30.872437  2066 solver.cpp:245]     Train net output #0: loss = 0.579799 (* 1 = 0.579799 loss)
I0503 04:46:30.872454  2066 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0503 04:47:13.894435  2066 solver.cpp:229] Iteration 860, loss = 0.48033
I0503 04:47:13.895581  2066 solver.cpp:245]     Train net output #0: loss = 0.48033 (* 1 = 0.48033 loss)
I0503 04:47:13.895597  2066 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0503 04:47:56.915129  2066 solver.cpp:229] Iteration 880, loss = 0.490003
I0503 04:47:56.916280  2066 solver.cpp:245]     Train net output #0: loss = 0.490003 (* 1 = 0.490003 loss)
I0503 04:47:56.916298  2066 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0503 04:48:39.937872  2066 solver.cpp:229] Iteration 900, loss = 0.485462
I0503 04:48:39.939101  2066 solver.cpp:245]     Train net output #0: loss = 0.485462 (* 1 = 0.485462 loss)
I0503 04:48:39.939118  2066 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0503 04:49:22.962918  2066 solver.cpp:229] Iteration 920, loss = 0.519669
I0503 04:49:22.963982  2066 solver.cpp:245]     Train net output #0: loss = 0.519669 (* 1 = 0.519669 loss)
I0503 04:49:22.964000  2066 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0503 04:50:05.982817  2066 solver.cpp:229] Iteration 940, loss = 0.416135
I0503 04:50:05.983950  2066 solver.cpp:245]     Train net output #0: loss = 0.416135 (* 1 = 0.416135 loss)
I0503 04:50:05.983966  2066 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0503 04:50:49.004322  2066 solver.cpp:229] Iteration 960, loss = 0.357615
I0503 04:50:49.005478  2066 solver.cpp:245]     Train net output #0: loss = 0.357615 (* 1 = 0.357615 loss)
I0503 04:50:49.005497  2066 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0503 04:51:32.028791  2066 solver.cpp:229] Iteration 980, loss = 0.341549
I0503 04:51:32.029961  2066 solver.cpp:245]     Train net output #0: loss = 0.341549 (* 1 = 0.341549 loss)
I0503 04:51:32.029978  2066 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0503 04:52:12.909508  2066 solver.cpp:338] Iteration 1000, Testing net (#0)
I0503 04:55:02.881439  2066 solver.cpp:406]     Test net output #0: accuracy = 0.937062
I0503 04:55:02.882725  2066 solver.cpp:406]     Test net output #1: loss = 0.202754 (* 1 = 0.202754 loss)
I0503 04:55:04.849053  2066 solver.cpp:229] Iteration 1000, loss = 0.37539
I0503 04:55:04.849126  2066 solver.cpp:245]     Train net output #0: loss = 0.37539 (* 1 = 0.37539 loss)
I0503 04:55:04.849141  2066 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0503 04:55:47.875068  2066 solver.cpp:229] Iteration 1020, loss = 0.283355
I0503 04:55:47.876497  2066 solver.cpp:245]     Train net output #0: loss = 0.283355 (* 1 = 0.283355 loss)
I0503 04:55:47.876514  2066 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0503 04:56:30.899770  2066 solver.cpp:229] Iteration 1040, loss = 0.522132
I0503 04:56:30.901029  2066 solver.cpp:245]     Train net output #0: loss = 0.522132 (* 1 = 0.522132 loss)
I0503 04:56:30.901047  2066 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0503 04:57:13.924331  2066 solver.cpp:229] Iteration 1060, loss = 0.336224
I0503 04:57:13.925592  2066 solver.cpp:245]     Train net output #0: loss = 0.336224 (* 1 = 0.336224 loss)
I0503 04:57:13.925612  2066 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0503 04:57:56.949795  2066 solver.cpp:229] Iteration 1080, loss = 0.321004
I0503 04:57:56.950891  2066 solver.cpp:245]     Train net output #0: loss = 0.321004 (* 1 = 0.321004 loss)
I0503 04:57:56.950907  2066 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0503 04:58:39.974364  2066 solver.cpp:229] Iteration 1100, loss = 0.331973
I0503 04:58:39.975545  2066 solver.cpp:245]     Train net output #0: loss = 0.331973 (* 1 = 0.331973 loss)
I0503 04:58:39.975564  2066 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0503 04:59:23.000298  2066 solver.cpp:229] Iteration 1120, loss = 0.319696
I0503 04:59:23.001466  2066 solver.cpp:245]     Train net output #0: loss = 0.319696 (* 1 = 0.319696 loss)
I0503 04:59:23.001487  2066 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0503 05:00:06.026051  2066 solver.cpp:229] Iteration 1140, loss = 0.238484
I0503 05:00:06.027204  2066 solver.cpp:245]     Train net output #0: loss = 0.238484 (* 1 = 0.238484 loss)
I0503 05:00:06.027225  2066 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0503 05:00:49.055356  2066 solver.cpp:229] Iteration 1160, loss = 0.343767
I0503 05:00:49.056418  2066 solver.cpp:245]     Train net output #0: loss = 0.343767 (* 1 = 0.343767 loss)
I0503 05:00:49.056435  2066 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0503 05:01:32.082183  2066 solver.cpp:229] Iteration 1180, loss = 0.255518
I0503 05:01:32.083513  2066 solver.cpp:245]     Train net output #0: loss = 0.255518 (* 1 = 0.255518 loss)
I0503 05:01:32.083675  2066 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0503 05:02:15.110800  2066 solver.cpp:229] Iteration 1200, loss = 0.21557
I0503 05:02:15.111946  2066 solver.cpp:245]     Train net output #0: loss = 0.21557 (* 1 = 0.21557 loss)
I0503 05:02:15.111974  2066 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0503 05:02:58.136184  2066 solver.cpp:229] Iteration 1220, loss = 0.218964
I0503 05:02:58.137260  2066 solver.cpp:245]     Train net output #0: loss = 0.218964 (* 1 = 0.218964 loss)
I0503 05:02:58.137276  2066 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0503 05:03:41.161361  2066 solver.cpp:229] Iteration 1240, loss = 0.21538
I0503 05:03:41.162449  2066 solver.cpp:245]     Train net output #0: loss = 0.21538 (* 1 = 0.21538 loss)
I0503 05:03:41.162466  2066 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0503 05:04:24.189751  2066 solver.cpp:229] Iteration 1260, loss = 0.26094
I0503 05:04:24.191036  2066 solver.cpp:245]     Train net output #0: loss = 0.26094 (* 1 = 0.26094 loss)
I0503 05:04:24.191056  2066 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0503 05:05:07.216593  2066 solver.cpp:229] Iteration 1280, loss = 0.194115
I0503 05:05:07.217800  2066 solver.cpp:245]     Train net output #0: loss = 0.194115 (* 1 = 0.194115 loss)
I0503 05:05:07.217818  2066 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0503 05:05:50.244354  2066 solver.cpp:229] Iteration 1300, loss = 0.234201
I0503 05:05:50.245434  2066 solver.cpp:245]     Train net output #0: loss = 0.234201 (* 1 = 0.234201 loss)
I0503 05:05:50.245450  2066 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0503 05:06:33.271927  2066 solver.cpp:229] Iteration 1320, loss = 0.193624
I0503 05:06:33.273032  2066 solver.cpp:245]     Train net output #0: loss = 0.193624 (* 1 = 0.193624 loss)
I0503 05:06:33.273051  2066 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0503 05:07:16.302074  2066 solver.cpp:229] Iteration 1340, loss = 0.161849
I0503 05:07:16.303131  2066 solver.cpp:245]     Train net output #0: loss = 0.161849 (* 1 = 0.161849 loss)
I0503 05:07:16.303149  2066 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0503 05:07:59.334537  2066 solver.cpp:229] Iteration 1360, loss = 0.145293
I0503 05:07:59.335592  2066 solver.cpp:245]     Train net output #0: loss = 0.145293 (* 1 = 0.145293 loss)
I0503 05:07:59.335608  2066 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0503 05:08:42.364279  2066 solver.cpp:229] Iteration 1380, loss = 0.204434
I0503 05:08:42.365353  2066 solver.cpp:245]     Train net output #0: loss = 0.204434 (* 1 = 0.204434 loss)
I0503 05:08:42.365370  2066 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0503 05:09:25.394350  2066 solver.cpp:229] Iteration 1400, loss = 0.130671
I0503 05:09:25.395545  2066 solver.cpp:245]     Train net output #0: loss = 0.130671 (* 1 = 0.130671 loss)
I0503 05:09:25.395562  2066 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0503 05:10:08.424639  2066 solver.cpp:229] Iteration 1420, loss = 0.0657008
I0503 05:10:08.425729  2066 solver.cpp:245]     Train net output #0: loss = 0.0657008 (* 1 = 0.0657008 loss)
I0503 05:10:08.425745  2066 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0503 05:10:51.453204  2066 solver.cpp:229] Iteration 1440, loss = 0.213064
I0503 05:10:51.454224  2066 solver.cpp:245]     Train net output #0: loss = 0.213064 (* 1 = 0.213064 loss)
I0503 05:10:51.454241  2066 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0503 05:11:34.484189  2066 solver.cpp:229] Iteration 1460, loss = 0.195063
I0503 05:11:34.485234  2066 solver.cpp:245]     Train net output #0: loss = 0.195063 (* 1 = 0.195063 loss)
I0503 05:11:34.485251  2066 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0503 05:12:17.513238  2066 solver.cpp:229] Iteration 1480, loss = 0.142823
I0503 05:12:17.514255  2066 solver.cpp:245]     Train net output #0: loss = 0.142823 (* 1 = 0.142823 loss)
I0503 05:12:17.514271  2066 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0503 05:13:00.543596  2066 solver.cpp:229] Iteration 1500, loss = 0.141278
I0503 05:13:00.544778  2066 solver.cpp:245]     Train net output #0: loss = 0.141278 (* 1 = 0.141278 loss)
I0503 05:13:00.544798  2066 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0503 05:13:43.573864  2066 solver.cpp:229] Iteration 1520, loss = 0.180017
I0503 05:13:43.574942  2066 solver.cpp:245]     Train net output #0: loss = 0.180017 (* 1 = 0.180017 loss)
I0503 05:13:43.574959  2066 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0503 05:14:26.603842  2066 solver.cpp:229] Iteration 1540, loss = 0.122859
I0503 05:14:26.604837  2066 solver.cpp:245]     Train net output #0: loss = 0.122859 (* 1 = 0.122859 loss)
I0503 05:14:26.604853  2066 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0503 05:15:09.634929  2066 solver.cpp:229] Iteration 1560, loss = 0.090324
I0503 05:15:09.635962  2066 solver.cpp:245]     Train net output #0: loss = 0.090324 (* 1 = 0.090324 loss)
I0503 05:15:09.635977  2066 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0503 05:15:52.665823  2066 solver.cpp:229] Iteration 1580, loss = 0.0905555
I0503 05:15:52.666983  2066 solver.cpp:245]     Train net output #0: loss = 0.0905555 (* 1 = 0.0905555 loss)
I0503 05:15:52.667001  2066 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0503 05:16:35.696262  2066 solver.cpp:229] Iteration 1600, loss = 0.128332
I0503 05:16:35.697343  2066 solver.cpp:245]     Train net output #0: loss = 0.128332 (* 1 = 0.128332 loss)
I0503 05:16:35.697360  2066 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0503 05:17:18.725589  2066 solver.cpp:229] Iteration 1620, loss = 0.145972
I0503 05:17:18.726640  2066 solver.cpp:245]     Train net output #0: loss = 0.145972 (* 1 = 0.145972 loss)
I0503 05:17:18.726658  2066 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0503 05:18:01.755378  2066 solver.cpp:229] Iteration 1640, loss = 0.117053
I0503 05:18:01.756597  2066 solver.cpp:245]     Train net output #0: loss = 0.117053 (* 1 = 0.117053 loss)
I0503 05:18:01.756614  2066 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0503 05:18:44.786531  2066 solver.cpp:229] Iteration 1660, loss = 0.0754532
I0503 05:18:44.787644  2066 solver.cpp:245]     Train net output #0: loss = 0.0754532 (* 1 = 0.0754532 loss)
I0503 05:18:44.787662  2066 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0503 05:19:27.816213  2066 solver.cpp:229] Iteration 1680, loss = 0.0464745
I0503 05:19:27.817260  2066 solver.cpp:245]     Train net output #0: loss = 0.0464745 (* 1 = 0.0464745 loss)
I0503 05:19:27.817278  2066 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0503 05:20:10.847868  2066 solver.cpp:229] Iteration 1700, loss = 0.141744
I0503 05:20:10.848950  2066 solver.cpp:245]     Train net output #0: loss = 0.141744 (* 1 = 0.141744 loss)
I0503 05:20:10.848976  2066 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0503 05:20:53.878674  2066 solver.cpp:229] Iteration 1720, loss = 0.223203
I0503 05:20:53.879752  2066 solver.cpp:245]     Train net output #0: loss = 0.223203 (* 1 = 0.223203 loss)
I0503 05:20:53.879770  2066 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0503 05:21:36.908017  2066 solver.cpp:229] Iteration 1740, loss = 0.118037
I0503 05:21:36.908992  2066 solver.cpp:245]     Train net output #0: loss = 0.118037 (* 1 = 0.118037 loss)
I0503 05:21:36.909008  2066 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0503 05:22:19.939450  2066 solver.cpp:229] Iteration 1760, loss = 0.0918749
I0503 05:22:19.940628  2066 solver.cpp:245]     Train net output #0: loss = 0.0918749 (* 1 = 0.0918749 loss)
I0503 05:22:19.940649  2066 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0503 05:23:02.968312  2066 solver.cpp:229] Iteration 1780, loss = 0.108073
I0503 05:23:02.969540  2066 solver.cpp:245]     Train net output #0: loss = 0.108073 (* 1 = 0.108073 loss)
I0503 05:23:02.969558  2066 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0503 05:23:45.996495  2066 solver.cpp:229] Iteration 1800, loss = 0.10276
I0503 05:23:45.997486  2066 solver.cpp:245]     Train net output #0: loss = 0.10276 (* 1 = 0.10276 loss)
I0503 05:23:45.997503  2066 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0503 05:24:29.023059  2066 solver.cpp:229] Iteration 1820, loss = 0.185357
I0503 05:24:29.024060  2066 solver.cpp:245]     Train net output #0: loss = 0.185357 (* 1 = 0.185357 loss)
I0503 05:24:29.024076  2066 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0503 05:25:12.050334  2066 solver.cpp:229] Iteration 1840, loss = 0.0571243
I0503 05:25:12.051442  2066 solver.cpp:245]     Train net output #0: loss = 0.0571243 (* 1 = 0.0571243 loss)
I0503 05:25:12.051461  2066 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0503 05:25:55.076874  2066 solver.cpp:229] Iteration 1860, loss = 0.0880644
I0503 05:25:55.077875  2066 solver.cpp:245]     Train net output #0: loss = 0.0880644 (* 1 = 0.0880644 loss)
I0503 05:25:55.077893  2066 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0503 05:26:38.105460  2066 solver.cpp:229] Iteration 1880, loss = 0.16788
I0503 05:26:38.106459  2066 solver.cpp:245]     Train net output #0: loss = 0.16788 (* 1 = 0.16788 loss)
I0503 05:26:38.106477  2066 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0503 05:27:21.133664  2066 solver.cpp:229] Iteration 1900, loss = 0.124123
I0503 05:27:21.134896  2066 solver.cpp:245]     Train net output #0: loss = 0.124123 (* 1 = 0.124123 loss)
I0503 05:27:21.134912  2066 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0503 05:28:04.164619  2066 solver.cpp:229] Iteration 1920, loss = 0.06031
I0503 05:28:04.165791  2066 solver.cpp:245]     Train net output #0: loss = 0.06031 (* 1 = 0.06031 loss)
I0503 05:28:04.165807  2066 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0503 05:28:47.193722  2066 solver.cpp:229] Iteration 1940, loss = 0.102516
I0503 05:28:47.194852  2066 solver.cpp:245]     Train net output #0: loss = 0.102516 (* 1 = 0.102516 loss)
I0503 05:28:47.194876  2066 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0503 05:29:30.224426  2066 solver.cpp:229] Iteration 1960, loss = 0.0816961
I0503 05:29:30.225565  2066 solver.cpp:245]     Train net output #0: loss = 0.0816961 (* 1 = 0.0816961 loss)
I0503 05:29:30.225582  2066 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0503 05:30:13.256737  2066 solver.cpp:229] Iteration 1980, loss = 0.0935978
I0503 05:30:13.257858  2066 solver.cpp:245]     Train net output #0: loss = 0.0935978 (* 1 = 0.0935978 loss)
I0503 05:30:13.257879  2066 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0503 05:30:54.144352  2066 solver.cpp:338] Iteration 2000, Testing net (#0)
I0503 05:33:44.127506  2066 solver.cpp:406]     Test net output #0: accuracy = 0.981239
I0503 05:33:44.128496  2066 solver.cpp:406]     Test net output #1: loss = 0.0527189 (* 1 = 0.0527189 loss)
I0503 05:33:46.094810  2066 solver.cpp:229] Iteration 2000, loss = 0.171458
I0503 05:33:46.094869  2066 solver.cpp:245]     Train net output #0: loss = 0.171458 (* 1 = 0.171458 loss)
I0503 05:33:46.094882  2066 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0503 05:34:29.122380  2066 solver.cpp:229] Iteration 2020, loss = 0.0925853
I0503 05:34:29.123436  2066 solver.cpp:245]     Train net output #0: loss = 0.0925853 (* 1 = 0.0925853 loss)
I0503 05:34:29.123455  2066 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0503 05:35:12.148619  2066 solver.cpp:229] Iteration 2040, loss = 0.062037
I0503 05:35:12.149818  2066 solver.cpp:245]     Train net output #0: loss = 0.062037 (* 1 = 0.062037 loss)
I0503 05:35:12.149842  2066 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0503 05:35:55.171406  2066 solver.cpp:229] Iteration 2060, loss = 0.053063
I0503 05:35:55.172495  2066 solver.cpp:245]     Train net output #0: loss = 0.053063 (* 1 = 0.053063 loss)
I0503 05:35:55.172513  2066 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0503 05:36:38.196478  2066 solver.cpp:229] Iteration 2080, loss = 0.110145
I0503 05:36:38.197492  2066 solver.cpp:245]     Train net output #0: loss = 0.110145 (* 1 = 0.110145 loss)
I0503 05:36:38.197509  2066 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0503 05:37:21.222129  2066 solver.cpp:229] Iteration 2100, loss = 0.160651
I0503 05:37:21.230609  2066 solver.cpp:245]     Train net output #0: loss = 0.160651 (* 1 = 0.160651 loss)
I0503 05:37:21.230628  2066 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0503 05:38:04.246680  2066 solver.cpp:229] Iteration 2120, loss = 0.0515367
I0503 05:38:04.247931  2066 solver.cpp:245]     Train net output #0: loss = 0.0515367 (* 1 = 0.0515367 loss)
I0503 05:38:04.247958  2066 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0503 05:38:47.275090  2066 solver.cpp:229] Iteration 2140, loss = 0.104298
I0503 05:38:47.276260  2066 solver.cpp:245]     Train net output #0: loss = 0.104298 (* 1 = 0.104298 loss)
I0503 05:38:47.276278  2066 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0503 05:39:30.301267  2066 solver.cpp:229] Iteration 2160, loss = 0.0739583
I0503 05:39:30.302434  2066 solver.cpp:245]     Train net output #0: loss = 0.0739583 (* 1 = 0.0739583 loss)
I0503 05:39:30.302453  2066 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0503 05:40:13.330389  2066 solver.cpp:229] Iteration 2180, loss = 0.0405584
I0503 05:40:13.331542  2066 solver.cpp:245]     Train net output #0: loss = 0.0405584 (* 1 = 0.0405584 loss)
I0503 05:40:13.331560  2066 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0503 05:40:56.357393  2066 solver.cpp:229] Iteration 2200, loss = 0.113811
I0503 05:40:56.358602  2066 solver.cpp:245]     Train net output #0: loss = 0.113811 (* 1 = 0.113811 loss)
I0503 05:40:56.358618  2066 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0503 05:41:39.389912  2066 solver.cpp:229] Iteration 2220, loss = 0.0963372
I0503 05:41:39.391028  2066 solver.cpp:245]     Train net output #0: loss = 0.0963372 (* 1 = 0.0963372 loss)
I0503 05:41:39.391046  2066 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0503 05:42:22.418073  2066 solver.cpp:229] Iteration 2240, loss = 0.111534
I0503 05:42:22.419162  2066 solver.cpp:245]     Train net output #0: loss = 0.111534 (* 1 = 0.111534 loss)
I0503 05:42:22.419180  2066 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0503 05:43:05.444792  2066 solver.cpp:229] Iteration 2260, loss = 0.130195
I0503 05:43:05.446027  2066 solver.cpp:245]     Train net output #0: loss = 0.130195 (* 1 = 0.130195 loss)
I0503 05:43:05.446045  2066 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0503 05:43:48.471868  2066 solver.cpp:229] Iteration 2280, loss = 0.0529156
I0503 05:43:48.473014  2066 solver.cpp:245]     Train net output #0: loss = 0.0529156 (* 1 = 0.0529156 loss)
I0503 05:43:48.473031  2066 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0503 05:44:31.499377  2066 solver.cpp:229] Iteration 2300, loss = 0.0541614
I0503 05:44:31.500560  2066 solver.cpp:245]     Train net output #0: loss = 0.0541614 (* 1 = 0.0541614 loss)
I0503 05:44:31.500579  2066 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0503 05:45:14.528806  2066 solver.cpp:229] Iteration 2320, loss = 0.0491858
I0503 05:45:14.529963  2066 solver.cpp:245]     Train net output #0: loss = 0.0491858 (* 1 = 0.0491858 loss)
I0503 05:45:14.529980  2066 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0503 05:45:57.555923  2066 solver.cpp:229] Iteration 2340, loss = 0.0365849
I0503 05:45:57.557031  2066 solver.cpp:245]     Train net output #0: loss = 0.0365849 (* 1 = 0.0365849 loss)
I0503 05:45:57.557049  2066 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0503 05:46:40.583395  2066 solver.cpp:229] Iteration 2360, loss = 0.0516124
I0503 05:46:40.584565  2066 solver.cpp:245]     Train net output #0: loss = 0.0516124 (* 1 = 0.0516124 loss)
I0503 05:46:40.584583  2066 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0503 05:47:23.609536  2066 solver.cpp:229] Iteration 2380, loss = 0.0427887
I0503 05:47:23.610582  2066 solver.cpp:245]     Train net output #0: loss = 0.0427887 (* 1 = 0.0427887 loss)
I0503 05:47:23.610599  2066 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0503 05:48:06.634932  2066 solver.cpp:229] Iteration 2400, loss = 0.0543612
I0503 05:48:06.636030  2066 solver.cpp:245]     Train net output #0: loss = 0.0543612 (* 1 = 0.0543612 loss)
I0503 05:48:06.636046  2066 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0503 05:48:49.660266  2066 solver.cpp:229] Iteration 2420, loss = 0.106675
I0503 05:48:49.661475  2066 solver.cpp:245]     Train net output #0: loss = 0.106675 (* 1 = 0.106675 loss)
I0503 05:48:49.661494  2066 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0503 05:49:32.686801  2066 solver.cpp:229] Iteration 2440, loss = 0.0207127
I0503 05:49:32.687891  2066 solver.cpp:245]     Train net output #0: loss = 0.0207127 (* 1 = 0.0207127 loss)
I0503 05:49:32.687908  2066 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0503 05:50:15.714045  2066 solver.cpp:229] Iteration 2460, loss = 0.0360641
I0503 05:50:15.715225  2066 solver.cpp:245]     Train net output #0: loss = 0.0360641 (* 1 = 0.0360641 loss)
I0503 05:50:15.715242  2066 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0503 05:50:58.742897  2066 solver.cpp:229] Iteration 2480, loss = 0.0403862
I0503 05:50:58.744101  2066 solver.cpp:245]     Train net output #0: loss = 0.0403862 (* 1 = 0.0403862 loss)
I0503 05:50:58.744117  2066 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0503 05:51:41.770324  2066 solver.cpp:229] Iteration 2500, loss = 0.114872
I0503 05:51:41.771567  2066 solver.cpp:245]     Train net output #0: loss = 0.114872 (* 1 = 0.114872 loss)
I0503 05:51:41.771589  2066 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0503 05:52:24.797293  2066 solver.cpp:229] Iteration 2520, loss = 0.042263
I0503 05:52:24.798336  2066 solver.cpp:245]     Train net output #0: loss = 0.042263 (* 1 = 0.042263 loss)
I0503 05:52:24.798352  2066 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0503 05:53:07.823632  2066 solver.cpp:229] Iteration 2540, loss = 0.054291
I0503 05:53:07.824759  2066 solver.cpp:245]     Train net output #0: loss = 0.054291 (* 1 = 0.054291 loss)
I0503 05:53:07.824776  2066 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0503 05:53:50.851702  2066 solver.cpp:229] Iteration 2560, loss = 0.0732405
I0503 05:53:50.852851  2066 solver.cpp:245]     Train net output #0: loss = 0.0732405 (* 1 = 0.0732405 loss)
I0503 05:53:50.852879  2066 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0503 05:54:33.880226  2066 solver.cpp:229] Iteration 2580, loss = 0.0826292
I0503 05:54:33.881320  2066 solver.cpp:245]     Train net output #0: loss = 0.0826292 (* 1 = 0.0826292 loss)
I0503 05:54:33.881337  2066 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0503 05:55:16.909637  2066 solver.cpp:229] Iteration 2600, loss = 0.0564427
I0503 05:55:16.910893  2066 solver.cpp:245]     Train net output #0: loss = 0.0564427 (* 1 = 0.0564427 loss)
I0503 05:55:16.910910  2066 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0503 05:55:59.937646  2066 solver.cpp:229] Iteration 2620, loss = 0.0676475
I0503 05:55:59.938809  2066 solver.cpp:245]     Train net output #0: loss = 0.0676475 (* 1 = 0.0676475 loss)
I0503 05:55:59.938827  2066 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0503 05:56:42.967679  2066 solver.cpp:229] Iteration 2640, loss = 0.103139
I0503 05:56:42.968734  2066 solver.cpp:245]     Train net output #0: loss = 0.103139 (* 1 = 0.103139 loss)
I0503 05:56:42.968750  2066 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0503 05:57:25.995303  2066 solver.cpp:229] Iteration 2660, loss = 0.0306161
I0503 05:57:25.996424  2066 solver.cpp:245]     Train net output #0: loss = 0.030616 (* 1 = 0.030616 loss)
I0503 05:57:25.996440  2066 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0503 05:58:09.022572  2066 solver.cpp:229] Iteration 2680, loss = 0.0947214
I0503 05:58:09.023674  2066 solver.cpp:245]     Train net output #0: loss = 0.0947213 (* 1 = 0.0947213 loss)
I0503 05:58:09.023691  2066 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0503 05:58:52.049445  2066 solver.cpp:229] Iteration 2700, loss = 0.0646365
I0503 05:58:52.050570  2066 solver.cpp:245]     Train net output #0: loss = 0.0646365 (* 1 = 0.0646365 loss)
I0503 05:58:52.050595  2066 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0503 05:59:35.080345  2066 solver.cpp:229] Iteration 2720, loss = 0.106361
I0503 05:59:35.081493  2066 solver.cpp:245]     Train net output #0: loss = 0.106361 (* 1 = 0.106361 loss)
I0503 05:59:35.081511  2066 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0503 06:00:18.109956  2066 solver.cpp:229] Iteration 2740, loss = 0.0892041
I0503 06:00:18.111069  2066 solver.cpp:245]     Train net output #0: loss = 0.0892041 (* 1 = 0.0892041 loss)
I0503 06:00:18.111084  2066 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0503 06:01:01.139837  2066 solver.cpp:229] Iteration 2760, loss = 0.0318344
I0503 06:01:01.141371  2066 solver.cpp:245]     Train net output #0: loss = 0.0318344 (* 1 = 0.0318344 loss)
I0503 06:01:01.141389  2066 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0503 06:01:44.169070  2066 solver.cpp:229] Iteration 2780, loss = 0.0509596
I0503 06:01:44.170244  2066 solver.cpp:245]     Train net output #0: loss = 0.0509595 (* 1 = 0.0509595 loss)
I0503 06:01:44.170260  2066 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0503 06:02:27.198488  2066 solver.cpp:229] Iteration 2800, loss = 0.0352641
I0503 06:02:27.199597  2066 solver.cpp:245]     Train net output #0: loss = 0.0352641 (* 1 = 0.0352641 loss)
I0503 06:02:27.199614  2066 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0503 06:03:10.225392  2066 solver.cpp:229] Iteration 2820, loss = 0.0107632
I0503 06:03:10.226629  2066 solver.cpp:245]     Train net output #0: loss = 0.0107632 (* 1 = 0.0107632 loss)
I0503 06:03:10.226650  2066 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0503 06:03:53.254693  2066 solver.cpp:229] Iteration 2840, loss = 0.0524956
I0503 06:03:53.255756  2066 solver.cpp:245]     Train net output #0: loss = 0.0524956 (* 1 = 0.0524956 loss)
I0503 06:03:53.255775  2066 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0503 06:04:36.281843  2066 solver.cpp:229] Iteration 2860, loss = 0.0430213
I0503 06:04:36.282968  2066 solver.cpp:245]     Train net output #0: loss = 0.0430213 (* 1 = 0.0430213 loss)
I0503 06:04:36.282985  2066 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0503 06:05:19.308887  2066 solver.cpp:229] Iteration 2880, loss = 0.0335497
I0503 06:05:19.309970  2066 solver.cpp:245]     Train net output #0: loss = 0.0335496 (* 1 = 0.0335496 loss)
I0503 06:05:19.309986  2066 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0503 06:06:02.335048  2066 solver.cpp:229] Iteration 2900, loss = 0.0494308
I0503 06:06:02.336261  2066 solver.cpp:245]     Train net output #0: loss = 0.0494308 (* 1 = 0.0494308 loss)
I0503 06:06:02.336278  2066 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0503 06:06:45.361454  2066 solver.cpp:229] Iteration 2920, loss = 0.0458119
I0503 06:06:45.362541  2066 solver.cpp:245]     Train net output #0: loss = 0.0458119 (* 1 = 0.0458119 loss)
I0503 06:06:45.362560  2066 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0503 06:07:28.389155  2066 solver.cpp:229] Iteration 2940, loss = 0.0546438
I0503 06:07:28.390331  2066 solver.cpp:245]     Train net output #0: loss = 0.0546437 (* 1 = 0.0546437 loss)
I0503 06:07:28.390349  2066 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0503 06:08:11.419149  2066 solver.cpp:229] Iteration 2960, loss = 0.0356351
I0503 06:08:11.420207  2066 solver.cpp:245]     Train net output #0: loss = 0.035635 (* 1 = 0.035635 loss)
I0503 06:08:11.420225  2066 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0503 06:08:54.449765  2066 solver.cpp:229] Iteration 2980, loss = 0.0645981
I0503 06:08:54.450951  2066 solver.cpp:245]     Train net output #0: loss = 0.0645981 (* 1 = 0.0645981 loss)
I0503 06:08:54.450968  2066 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0503 06:09:35.336724  2066 solver.cpp:338] Iteration 3000, Testing net (#0)
I0503 06:12:25.312082  2066 solver.cpp:406]     Test net output #0: accuracy = 0.987898
I0503 06:12:25.313174  2066 solver.cpp:406]     Test net output #1: loss = 0.0347696 (* 1 = 0.0347696 loss)
I0503 06:12:27.279048  2066 solver.cpp:229] Iteration 3000, loss = 0.0652457
I0503 06:12:27.279116  2066 solver.cpp:245]     Train net output #0: loss = 0.0652457 (* 1 = 0.0652457 loss)
I0503 06:12:27.279131  2066 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0503 06:13:10.296855  2066 solver.cpp:229] Iteration 3020, loss = 0.0300422
I0503 06:13:10.297999  2066 solver.cpp:245]     Train net output #0: loss = 0.0300422 (* 1 = 0.0300422 loss)
I0503 06:13:10.298017  2066 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0503 06:13:53.314539  2066 solver.cpp:229] Iteration 3040, loss = 0.0394868
I0503 06:13:53.315634  2066 solver.cpp:245]     Train net output #0: loss = 0.0394867 (* 1 = 0.0394867 loss)
I0503 06:13:53.315654  2066 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0503 06:14:36.334106  2066 solver.cpp:229] Iteration 3060, loss = 0.0497798
I0503 06:14:36.335175  2066 solver.cpp:245]     Train net output #0: loss = 0.0497797 (* 1 = 0.0497797 loss)
I0503 06:14:36.335191  2066 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0503 06:15:19.354161  2066 solver.cpp:229] Iteration 3080, loss = 0.0211673
I0503 06:15:19.355221  2066 solver.cpp:245]     Train net output #0: loss = 0.0211672 (* 1 = 0.0211672 loss)
I0503 06:15:19.355238  2066 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0503 06:16:02.381291  2066 solver.cpp:229] Iteration 3100, loss = 0.0306485
I0503 06:16:02.382486  2066 solver.cpp:245]     Train net output #0: loss = 0.0306484 (* 1 = 0.0306484 loss)
I0503 06:16:02.382503  2066 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0503 06:16:45.403450  2066 solver.cpp:229] Iteration 3120, loss = 0.0649062
I0503 06:16:45.407636  2066 solver.cpp:245]     Train net output #0: loss = 0.0649062 (* 1 = 0.0649062 loss)
I0503 06:16:45.407656  2066 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0503 06:17:28.422418  2066 solver.cpp:229] Iteration 3140, loss = 0.0198298
I0503 06:17:28.423499  2066 solver.cpp:245]     Train net output #0: loss = 0.0198297 (* 1 = 0.0198297 loss)
I0503 06:17:28.423516  2066 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0503 06:18:11.440543  2066 solver.cpp:229] Iteration 3160, loss = 0.0334793
I0503 06:18:11.441617  2066 solver.cpp:245]     Train net output #0: loss = 0.0334792 (* 1 = 0.0334792 loss)
I0503 06:18:11.441634  2066 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0503 06:18:54.459067  2066 solver.cpp:229] Iteration 3180, loss = 0.0427363
I0503 06:18:54.460132  2066 solver.cpp:245]     Train net output #0: loss = 0.0427362 (* 1 = 0.0427362 loss)
I0503 06:18:54.460150  2066 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0503 06:19:37.480322  2066 solver.cpp:229] Iteration 3200, loss = 0.0297044
I0503 06:19:37.481362  2066 solver.cpp:245]     Train net output #0: loss = 0.0297043 (* 1 = 0.0297043 loss)
I0503 06:19:37.481380  2066 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0503 06:20:20.501338  2066 solver.cpp:229] Iteration 3220, loss = 0.03474
I0503 06:20:20.502693  2066 solver.cpp:245]     Train net output #0: loss = 0.0347399 (* 1 = 0.0347399 loss)
I0503 06:20:20.502710  2066 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0503 06:21:03.521950  2066 solver.cpp:229] Iteration 3240, loss = 0.0276989
I0503 06:21:03.523075  2066 solver.cpp:245]     Train net output #0: loss = 0.0276989 (* 1 = 0.0276989 loss)
I0503 06:21:03.523092  2066 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0503 06:21:46.541996  2066 solver.cpp:229] Iteration 3260, loss = 0.0184754
I0503 06:21:46.543067  2066 solver.cpp:245]     Train net output #0: loss = 0.0184753 (* 1 = 0.0184753 loss)
I0503 06:21:46.543084  2066 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0503 06:22:29.562072  2066 solver.cpp:229] Iteration 3280, loss = 0.0380769
I0503 06:22:29.563068  2066 solver.cpp:245]     Train net output #0: loss = 0.0380768 (* 1 = 0.0380768 loss)
I0503 06:22:29.563086  2066 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0503 06:23:12.581984  2066 solver.cpp:229] Iteration 3300, loss = 0.0381236
I0503 06:23:12.583101  2066 solver.cpp:245]     Train net output #0: loss = 0.0381235 (* 1 = 0.0381235 loss)
I0503 06:23:12.583118  2066 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0503 06:23:55.601723  2066 solver.cpp:229] Iteration 3320, loss = 0.0446656
I0503 06:23:55.602807  2066 solver.cpp:245]     Train net output #0: loss = 0.0446656 (* 1 = 0.0446656 loss)
I0503 06:23:55.602826  2066 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0503 06:24:38.623083  2066 solver.cpp:229] Iteration 3340, loss = 0.0376368
I0503 06:24:38.624176  2066 solver.cpp:245]     Train net output #0: loss = 0.0376368 (* 1 = 0.0376368 loss)
I0503 06:24:38.624193  2066 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0503 06:25:21.642846  2066 solver.cpp:229] Iteration 3360, loss = 0.0518163
I0503 06:25:21.644098  2066 solver.cpp:245]     Train net output #0: loss = 0.0518163 (* 1 = 0.0518163 loss)
I0503 06:25:21.644117  2066 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0503 06:26:04.665671  2066 solver.cpp:229] Iteration 3380, loss = 0.0206532
I0503 06:26:04.666795  2066 solver.cpp:245]     Train net output #0: loss = 0.0206531 (* 1 = 0.0206531 loss)
I0503 06:26:04.666811  2066 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0503 06:26:47.686269  2066 solver.cpp:229] Iteration 3400, loss = 0.00407611
I0503 06:26:47.687371  2066 solver.cpp:245]     Train net output #0: loss = 0.00407606 (* 1 = 0.00407606 loss)
I0503 06:26:47.687388  2066 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0503 06:27:30.709574  2066 solver.cpp:229] Iteration 3420, loss = 0.0446379
I0503 06:27:30.711020  2066 solver.cpp:245]     Train net output #0: loss = 0.0446379 (* 1 = 0.0446379 loss)
I0503 06:27:30.711042  2066 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0503 06:28:13.731619  2066 solver.cpp:229] Iteration 3440, loss = 0.0419036
I0503 06:28:13.732772  2066 solver.cpp:245]     Train net output #0: loss = 0.0419036 (* 1 = 0.0419036 loss)
I0503 06:28:13.732789  2066 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0503 06:28:56.755632  2066 solver.cpp:229] Iteration 3460, loss = 0.023675
I0503 06:28:56.756573  2066 solver.cpp:245]     Train net output #0: loss = 0.0236749 (* 1 = 0.0236749 loss)
I0503 06:28:56.756590  2066 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0503 06:29:39.777259  2066 solver.cpp:229] Iteration 3480, loss = 0.024423
I0503 06:29:39.778266  2066 solver.cpp:245]     Train net output #0: loss = 0.0244229 (* 1 = 0.0244229 loss)
I0503 06:29:39.778285  2066 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0503 06:30:22.796563  2066 solver.cpp:229] Iteration 3500, loss = 0.0342907
I0503 06:30:22.797577  2066 solver.cpp:245]     Train net output #0: loss = 0.0342907 (* 1 = 0.0342907 loss)
I0503 06:30:22.797595  2066 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0503 06:31:05.818234  2066 solver.cpp:229] Iteration 3520, loss = 0.00628916
I0503 06:31:05.819231  2066 solver.cpp:245]     Train net output #0: loss = 0.00628913 (* 1 = 0.00628913 loss)
I0503 06:31:05.819249  2066 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0503 06:31:48.838214  2066 solver.cpp:229] Iteration 3540, loss = 0.0864264
I0503 06:31:48.839342  2066 solver.cpp:245]     Train net output #0: loss = 0.0864264 (* 1 = 0.0864264 loss)
I0503 06:31:48.839359  2066 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0503 06:32:31.858798  2066 solver.cpp:229] Iteration 3560, loss = 0.0492491
I0503 06:32:31.860149  2066 solver.cpp:245]     Train net output #0: loss = 0.0492491 (* 1 = 0.0492491 loss)
I0503 06:32:31.860169  2066 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0503 06:33:14.879737  2066 solver.cpp:229] Iteration 3580, loss = 0.0188653
I0503 06:33:14.880822  2066 solver.cpp:245]     Train net output #0: loss = 0.0188652 (* 1 = 0.0188652 loss)
I0503 06:33:14.880838  2066 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0503 06:33:57.897965  2066 solver.cpp:229] Iteration 3600, loss = 0.074529
I0503 06:33:57.899065  2066 solver.cpp:245]     Train net output #0: loss = 0.074529 (* 1 = 0.074529 loss)
I0503 06:33:57.899082  2066 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0503 06:34:40.918329  2066 solver.cpp:229] Iteration 3620, loss = 0.0503243
I0503 06:34:40.919395  2066 solver.cpp:245]     Train net output #0: loss = 0.0503242 (* 1 = 0.0503242 loss)
I0503 06:34:40.919412  2066 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0503 06:35:23.937782  2066 solver.cpp:229] Iteration 3640, loss = 0.0421427
I0503 06:35:23.938828  2066 solver.cpp:245]     Train net output #0: loss = 0.0421427 (* 1 = 0.0421427 loss)
I0503 06:35:23.938845  2066 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0503 06:36:06.955437  2066 solver.cpp:229] Iteration 3660, loss = 0.0574809
I0503 06:36:06.956651  2066 solver.cpp:245]     Train net output #0: loss = 0.0574809 (* 1 = 0.0574809 loss)
I0503 06:36:06.956672  2066 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0503 06:36:49.972618  2066 solver.cpp:229] Iteration 3680, loss = 0.054297
I0503 06:36:49.973665  2066 solver.cpp:245]     Train net output #0: loss = 0.054297 (* 1 = 0.054297 loss)
I0503 06:36:49.973685  2066 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0503 06:37:32.992015  2066 solver.cpp:229] Iteration 3700, loss = 0.0237361
I0503 06:37:32.993088  2066 solver.cpp:245]     Train net output #0: loss = 0.023736 (* 1 = 0.023736 loss)
I0503 06:37:32.993104  2066 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0503 06:38:16.009291  2066 solver.cpp:229] Iteration 3720, loss = 0.042008
I0503 06:38:16.010395  2066 solver.cpp:245]     Train net output #0: loss = 0.0420079 (* 1 = 0.0420079 loss)
I0503 06:38:16.010411  2066 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0503 06:38:59.025185  2066 solver.cpp:229] Iteration 3740, loss = 0.0441578
I0503 06:38:59.026303  2066 solver.cpp:245]     Train net output #0: loss = 0.0441577 (* 1 = 0.0441577 loss)
I0503 06:38:59.026319  2066 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0503 06:39:42.045768  2066 solver.cpp:229] Iteration 3760, loss = 0.0416009
I0503 06:39:42.046859  2066 solver.cpp:245]     Train net output #0: loss = 0.0416008 (* 1 = 0.0416008 loss)
I0503 06:39:42.046876  2066 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0503 06:40:25.066087  2066 solver.cpp:229] Iteration 3780, loss = 0.0675016
I0503 06:40:25.067244  2066 solver.cpp:245]     Train net output #0: loss = 0.0675015 (* 1 = 0.0675015 loss)
I0503 06:40:25.067260  2066 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0503 06:41:08.086163  2066 solver.cpp:229] Iteration 3800, loss = 0.0499046
I0503 06:41:08.087322  2066 solver.cpp:245]     Train net output #0: loss = 0.0499046 (* 1 = 0.0499046 loss)
I0503 06:41:08.087342  2066 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0503 06:41:51.104938  2066 solver.cpp:229] Iteration 3820, loss = 0.0529206
I0503 06:41:51.106053  2066 solver.cpp:245]     Train net output #0: loss = 0.0529206 (* 1 = 0.0529206 loss)
I0503 06:41:51.106070  2066 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0503 06:42:34.121420  2066 solver.cpp:229] Iteration 3840, loss = 0.0136188
I0503 06:42:34.122529  2066 solver.cpp:245]     Train net output #0: loss = 0.0136187 (* 1 = 0.0136187 loss)
I0503 06:42:34.122546  2066 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0503 06:43:17.137416  2066 solver.cpp:229] Iteration 3860, loss = 0.0190047
I0503 06:43:17.138690  2066 solver.cpp:245]     Train net output #0: loss = 0.0190047 (* 1 = 0.0190047 loss)
I0503 06:43:17.138707  2066 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0503 06:44:00.157433  2066 solver.cpp:229] Iteration 3880, loss = 0.011076
I0503 06:44:00.158666  2066 solver.cpp:245]     Train net output #0: loss = 0.011076 (* 1 = 0.011076 loss)
I0503 06:44:00.158684  2066 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0503 06:44:43.177664  2066 solver.cpp:229] Iteration 3900, loss = 0.0318363
I0503 06:44:43.178930  2066 solver.cpp:245]     Train net output #0: loss = 0.0318363 (* 1 = 0.0318363 loss)
I0503 06:44:43.178946  2066 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0503 06:45:26.201273  2066 solver.cpp:229] Iteration 3920, loss = 0.0348446
I0503 06:45:26.202292  2066 solver.cpp:245]     Train net output #0: loss = 0.0348446 (* 1 = 0.0348446 loss)
I0503 06:45:26.202308  2066 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0503 06:46:09.223861  2066 solver.cpp:229] Iteration 3940, loss = 0.0248687
I0503 06:46:09.225033  2066 solver.cpp:245]     Train net output #0: loss = 0.0248687 (* 1 = 0.0248687 loss)
I0503 06:46:09.225051  2066 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0503 06:46:52.247115  2066 solver.cpp:229] Iteration 3960, loss = 0.0315281
I0503 06:46:52.248138  2066 solver.cpp:245]     Train net output #0: loss = 0.031528 (* 1 = 0.031528 loss)
I0503 06:46:52.248155  2066 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0503 06:47:35.271054  2066 solver.cpp:229] Iteration 3980, loss = 0.0400041
I0503 06:47:35.272089  2066 solver.cpp:245]     Train net output #0: loss = 0.0400041 (* 1 = 0.0400041 loss)
I0503 06:47:35.272106  2066 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0503 06:48:16.150470  2066 solver.cpp:338] Iteration 4000, Testing net (#0)
I0503 06:51:06.131266  2066 solver.cpp:406]     Test net output #0: accuracy = 0.992358
I0503 06:51:06.132480  2066 solver.cpp:406]     Test net output #1: loss = 0.0258084 (* 1 = 0.0258084 loss)
I0503 06:51:08.098636  2066 solver.cpp:229] Iteration 4000, loss = 0.0178396
I0503 06:51:08.098709  2066 solver.cpp:245]     Train net output #0: loss = 0.0178395 (* 1 = 0.0178395 loss)
I0503 06:51:08.098727  2066 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0503 06:51:51.115223  2066 solver.cpp:229] Iteration 4020, loss = 0.0555572
I0503 06:51:51.116322  2066 solver.cpp:245]     Train net output #0: loss = 0.0555571 (* 1 = 0.0555571 loss)
I0503 06:51:51.116339  2066 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0503 06:52:34.129899  2066 solver.cpp:229] Iteration 4040, loss = 0.0200291
I0503 06:52:34.131006  2066 solver.cpp:245]     Train net output #0: loss = 0.0200291 (* 1 = 0.0200291 loss)
I0503 06:52:34.131026  2066 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0503 06:53:17.146669  2066 solver.cpp:229] Iteration 4060, loss = 0.0164911
I0503 06:53:17.147781  2066 solver.cpp:245]     Train net output #0: loss = 0.0164911 (* 1 = 0.0164911 loss)
I0503 06:53:17.147800  2066 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0503 06:54:00.160668  2066 solver.cpp:229] Iteration 4080, loss = 0.0122283
I0503 06:54:00.161969  2066 solver.cpp:245]     Train net output #0: loss = 0.0122283 (* 1 = 0.0122283 loss)
I0503 06:54:00.161989  2066 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0503 06:54:43.175223  2066 solver.cpp:229] Iteration 4100, loss = 0.0151073
I0503 06:54:43.176302  2066 solver.cpp:245]     Train net output #0: loss = 0.0151073 (* 1 = 0.0151073 loss)
I0503 06:54:43.176318  2066 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0503 06:55:26.191340  2066 solver.cpp:229] Iteration 4120, loss = 0.0152069
I0503 06:55:26.192473  2066 solver.cpp:245]     Train net output #0: loss = 0.0152069 (* 1 = 0.0152069 loss)
I0503 06:55:26.192490  2066 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0503 06:56:09.209197  2066 solver.cpp:229] Iteration 4140, loss = 0.0170642
I0503 06:56:09.210350  2066 solver.cpp:245]     Train net output #0: loss = 0.0170642 (* 1 = 0.0170642 loss)
I0503 06:56:09.210368  2066 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0503 06:56:52.226235  2066 solver.cpp:229] Iteration 4160, loss = 0.0208938
I0503 06:56:52.227293  2066 solver.cpp:245]     Train net output #0: loss = 0.0208937 (* 1 = 0.0208937 loss)
I0503 06:56:52.227309  2066 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0503 06:57:35.245544  2066 solver.cpp:229] Iteration 4180, loss = 0.0263379
I0503 06:57:35.246568  2066 solver.cpp:245]     Train net output #0: loss = 0.0263379 (* 1 = 0.0263379 loss)
I0503 06:57:35.246587  2066 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0503 06:58:18.266113  2066 solver.cpp:229] Iteration 4200, loss = 0.0142387
I0503 06:58:18.267189  2066 solver.cpp:245]     Train net output #0: loss = 0.0142387 (* 1 = 0.0142387 loss)
I0503 06:58:18.267205  2066 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0503 06:59:01.281620  2066 solver.cpp:229] Iteration 4220, loss = 0.0456269
I0503 06:59:01.282811  2066 solver.cpp:245]     Train net output #0: loss = 0.0456269 (* 1 = 0.0456269 loss)
I0503 06:59:01.282829  2066 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0503 06:59:44.297626  2066 solver.cpp:229] Iteration 4240, loss = 0.0150254
I0503 06:59:44.298679  2066 solver.cpp:245]     Train net output #0: loss = 0.0150254 (* 1 = 0.0150254 loss)
I0503 06:59:44.298696  2066 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0503 07:00:27.312870  2066 solver.cpp:229] Iteration 4260, loss = 0.0301937
I0503 07:00:27.313940  2066 solver.cpp:245]     Train net output #0: loss = 0.0301937 (* 1 = 0.0301937 loss)
I0503 07:00:27.313956  2066 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0503 07:01:10.330485  2066 solver.cpp:229] Iteration 4280, loss = 0.0493886
I0503 07:01:10.331868  2066 solver.cpp:245]     Train net output #0: loss = 0.0493886 (* 1 = 0.0493886 loss)
I0503 07:01:10.331887  2066 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0503 07:01:53.345727  2066 solver.cpp:229] Iteration 4300, loss = 0.0404696
I0503 07:01:53.346810  2066 solver.cpp:245]     Train net output #0: loss = 0.0404696 (* 1 = 0.0404696 loss)
I0503 07:01:53.346827  2066 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0503 07:02:36.365547  2066 solver.cpp:229] Iteration 4320, loss = 0.00671557
I0503 07:02:36.366652  2066 solver.cpp:245]     Train net output #0: loss = 0.00671557 (* 1 = 0.00671557 loss)
I0503 07:02:36.366668  2066 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0503 07:03:19.384724  2066 solver.cpp:229] Iteration 4340, loss = 0.0167677
I0503 07:03:19.385834  2066 solver.cpp:245]     Train net output #0: loss = 0.0167677 (* 1 = 0.0167677 loss)
I0503 07:03:19.385851  2066 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0503 07:04:02.403416  2066 solver.cpp:229] Iteration 4360, loss = 0.00440235
I0503 07:04:02.404675  2066 solver.cpp:245]     Train net output #0: loss = 0.00440235 (* 1 = 0.00440235 loss)
I0503 07:04:02.404695  2066 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0503 07:04:45.422809  2066 solver.cpp:229] Iteration 4380, loss = 0.0217188
I0503 07:04:45.423810  2066 solver.cpp:245]     Train net output #0: loss = 0.0217188 (* 1 = 0.0217188 loss)
I0503 07:04:45.423826  2066 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0503 07:05:28.442380  2066 solver.cpp:229] Iteration 4400, loss = 0.00451885
I0503 07:05:28.443434  2066 solver.cpp:245]     Train net output #0: loss = 0.00451885 (* 1 = 0.00451885 loss)
I0503 07:05:28.443452  2066 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0503 07:06:11.458580  2066 solver.cpp:229] Iteration 4420, loss = 0.0171764
I0503 07:06:11.459765  2066 solver.cpp:245]     Train net output #0: loss = 0.0171764 (* 1 = 0.0171764 loss)
I0503 07:06:11.459782  2066 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0503 07:06:54.480532  2066 solver.cpp:229] Iteration 4440, loss = 0.0101217
I0503 07:06:54.481581  2066 solver.cpp:245]     Train net output #0: loss = 0.0101217 (* 1 = 0.0101217 loss)
I0503 07:06:54.481597  2066 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0503 07:07:37.497923  2066 solver.cpp:229] Iteration 4460, loss = 0.0436223
I0503 07:07:37.499043  2066 solver.cpp:245]     Train net output #0: loss = 0.0436223 (* 1 = 0.0436223 loss)
I0503 07:07:37.499060  2066 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0503 07:08:20.514072  2066 solver.cpp:229] Iteration 4480, loss = 0.00879624
I0503 07:08:20.515215  2066 solver.cpp:245]     Train net output #0: loss = 0.00879623 (* 1 = 0.00879623 loss)
I0503 07:08:20.515233  2066 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0503 07:09:03.531954  2066 solver.cpp:229] Iteration 4500, loss = 0.0295611
I0503 07:09:03.532984  2066 solver.cpp:245]     Train net output #0: loss = 0.0295611 (* 1 = 0.0295611 loss)
I0503 07:09:03.533000  2066 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0503 07:09:46.550791  2066 solver.cpp:229] Iteration 4520, loss = 0.0182726
I0503 07:09:46.551841  2066 solver.cpp:245]     Train net output #0: loss = 0.0182726 (* 1 = 0.0182726 loss)
I0503 07:09:46.551859  2066 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0503 07:10:29.571966  2066 solver.cpp:229] Iteration 4540, loss = 0.0091551
I0503 07:10:29.573087  2066 solver.cpp:245]     Train net output #0: loss = 0.0091551 (* 1 = 0.0091551 loss)
I0503 07:10:29.573104  2066 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0503 07:11:12.592095  2066 solver.cpp:229] Iteration 4560, loss = 0.0428419
I0503 07:11:12.593226  2066 solver.cpp:245]     Train net output #0: loss = 0.0428419 (* 1 = 0.0428419 loss)
I0503 07:11:12.593245  2066 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0503 07:11:55.611970  2066 solver.cpp:229] Iteration 4580, loss = 0.0488247
I0503 07:11:55.613181  2066 solver.cpp:245]     Train net output #0: loss = 0.0488247 (* 1 = 0.0488247 loss)
I0503 07:11:55.613200  2066 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0503 07:12:38.630247  2066 solver.cpp:229] Iteration 4600, loss = 0.0338147
I0503 07:12:38.631425  2066 solver.cpp:245]     Train net output #0: loss = 0.0338147 (* 1 = 0.0338147 loss)
I0503 07:12:38.631443  2066 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0503 07:13:21.648795  2066 solver.cpp:229] Iteration 4620, loss = 0.0206106
I0503 07:13:21.649868  2066 solver.cpp:245]     Train net output #0: loss = 0.0206106 (* 1 = 0.0206106 loss)
I0503 07:13:21.649886  2066 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0503 07:14:04.663674  2066 solver.cpp:229] Iteration 4640, loss = 0.0077928
I0503 07:14:04.664788  2066 solver.cpp:245]     Train net output #0: loss = 0.0077928 (* 1 = 0.0077928 loss)
I0503 07:14:04.664808  2066 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0503 07:14:47.682579  2066 solver.cpp:229] Iteration 4660, loss = 0.0397609
I0503 07:14:47.683603  2066 solver.cpp:245]     Train net output #0: loss = 0.0397609 (* 1 = 0.0397609 loss)
I0503 07:14:47.683621  2066 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0503 07:15:30.698889  2066 solver.cpp:229] Iteration 4680, loss = 0.0330448
I0503 07:15:30.699882  2066 solver.cpp:245]     Train net output #0: loss = 0.0330448 (* 1 = 0.0330448 loss)
I0503 07:15:30.699898  2066 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0503 07:16:13.716274  2066 solver.cpp:229] Iteration 4700, loss = 0.00701202
I0503 07:16:13.717532  2066 solver.cpp:245]     Train net output #0: loss = 0.00701202 (* 1 = 0.00701202 loss)
I0503 07:16:13.717551  2066 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0503 07:16:56.733952  2066 solver.cpp:229] Iteration 4720, loss = 0.013431
I0503 07:16:56.735026  2066 solver.cpp:245]     Train net output #0: loss = 0.013431 (* 1 = 0.013431 loss)
I0503 07:16:56.735043  2066 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0503 07:17:39.751504  2066 solver.cpp:229] Iteration 4740, loss = 0.00708407
I0503 07:17:39.752630  2066 solver.cpp:245]     Train net output #0: loss = 0.00708407 (* 1 = 0.00708407 loss)
I0503 07:17:39.752647  2066 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0503 07:18:22.769675  2066 solver.cpp:229] Iteration 4760, loss = 0.00785874
I0503 07:18:22.770798  2066 solver.cpp:245]     Train net output #0: loss = 0.00785874 (* 1 = 0.00785874 loss)
I0503 07:18:22.770814  2066 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0503 07:19:05.789270  2066 solver.cpp:229] Iteration 4780, loss = 0.0119524
I0503 07:19:05.790490  2066 solver.cpp:245]     Train net output #0: loss = 0.0119524 (* 1 = 0.0119524 loss)
I0503 07:19:05.790509  2066 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0503 07:19:48.808207  2066 solver.cpp:229] Iteration 4800, loss = 0.0073039
I0503 07:19:48.809265  2066 solver.cpp:245]     Train net output #0: loss = 0.00730391 (* 1 = 0.00730391 loss)
I0503 07:19:48.809285  2066 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0503 07:20:31.827846  2066 solver.cpp:229] Iteration 4820, loss = 0.0846611
I0503 07:20:31.829040  2066 solver.cpp:245]     Train net output #0: loss = 0.0846611 (* 1 = 0.0846611 loss)
I0503 07:20:31.829056  2066 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0503 07:21:14.848402  2066 solver.cpp:229] Iteration 4840, loss = 0.0388185
I0503 07:21:14.849472  2066 solver.cpp:245]     Train net output #0: loss = 0.0388185 (* 1 = 0.0388185 loss)
I0503 07:21:14.849488  2066 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0503 07:21:57.871459  2066 solver.cpp:229] Iteration 4860, loss = 0.0369281
I0503 07:21:57.872476  2066 solver.cpp:245]     Train net output #0: loss = 0.0369281 (* 1 = 0.0369281 loss)
I0503 07:21:57.872493  2066 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0503 07:22:40.891782  2066 solver.cpp:229] Iteration 4880, loss = 0.0304878
I0503 07:22:40.892930  2066 solver.cpp:245]     Train net output #0: loss = 0.0304878 (* 1 = 0.0304878 loss)
I0503 07:22:40.892949  2066 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0503 07:23:23.913550  2066 solver.cpp:229] Iteration 4900, loss = 0.0282323
I0503 07:23:23.914651  2066 solver.cpp:245]     Train net output #0: loss = 0.0282323 (* 1 = 0.0282323 loss)
I0503 07:23:23.914669  2066 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0503 07:24:06.934154  2066 solver.cpp:229] Iteration 4920, loss = 0.0046654
I0503 07:24:06.935185  2066 solver.cpp:245]     Train net output #0: loss = 0.00466539 (* 1 = 0.00466539 loss)
I0503 07:24:06.935202  2066 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0503 07:24:49.953238  2066 solver.cpp:229] Iteration 4940, loss = 0.00970521
I0503 07:24:49.954443  2066 solver.cpp:245]     Train net output #0: loss = 0.00970521 (* 1 = 0.00970521 loss)
I0503 07:24:49.954460  2066 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0503 07:25:32.973866  2066 solver.cpp:229] Iteration 4960, loss = 0.00362001
I0503 07:25:32.974913  2066 solver.cpp:245]     Train net output #0: loss = 0.00362001 (* 1 = 0.00362001 loss)
I0503 07:25:32.974930  2066 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0503 07:26:15.993880  2066 solver.cpp:229] Iteration 4980, loss = 0.0154965
I0503 07:26:15.995074  2066 solver.cpp:245]     Train net output #0: loss = 0.0154965 (* 1 = 0.0154965 loss)
I0503 07:26:15.995095  2066 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0503 07:26:56.871696  2066 solver.cpp:338] Iteration 5000, Testing net (#0)
I0503 07:29:46.881216  2066 solver.cpp:406]     Test net output #0: accuracy = 0.992818
I0503 07:29:46.882307  2066 solver.cpp:406]     Test net output #1: loss = 0.0235876 (* 1 = 0.0235876 loss)
I0503 07:29:48.848762  2066 solver.cpp:229] Iteration 5000, loss = 0.013876
I0503 07:29:48.848822  2066 solver.cpp:245]     Train net output #0: loss = 0.013876 (* 1 = 0.013876 loss)
I0503 07:29:48.848835  2066 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0503 07:30:31.873836  2066 solver.cpp:229] Iteration 5020, loss = 0.0452307
I0503 07:30:31.875026  2066 solver.cpp:245]     Train net output #0: loss = 0.0452307 (* 1 = 0.0452307 loss)
I0503 07:30:31.875043  2066 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0503 07:31:14.897151  2066 solver.cpp:229] Iteration 5040, loss = 0.0324862
I0503 07:31:14.898249  2066 solver.cpp:245]     Train net output #0: loss = 0.0324862 (* 1 = 0.0324862 loss)
I0503 07:31:14.898268  2066 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0503 07:31:57.922875  2066 solver.cpp:229] Iteration 5060, loss = 0.0201311
I0503 07:31:57.923980  2066 solver.cpp:245]     Train net output #0: loss = 0.0201311 (* 1 = 0.0201311 loss)
I0503 07:31:57.924000  2066 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0503 07:32:40.948520  2066 solver.cpp:229] Iteration 5080, loss = 0.00743377
I0503 07:32:40.949605  2066 solver.cpp:245]     Train net output #0: loss = 0.00743377 (* 1 = 0.00743377 loss)
I0503 07:32:40.949622  2066 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0503 07:33:23.973417  2066 solver.cpp:229] Iteration 5100, loss = 0.0216778
I0503 07:33:23.974552  2066 solver.cpp:245]     Train net output #0: loss = 0.0216778 (* 1 = 0.0216778 loss)
I0503 07:33:23.974568  2066 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0503 07:34:06.997295  2066 solver.cpp:229] Iteration 5120, loss = 0.0078736
I0503 07:34:06.998381  2066 solver.cpp:245]     Train net output #0: loss = 0.0078736 (* 1 = 0.0078736 loss)
I0503 07:34:06.998399  2066 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0503 07:34:50.022357  2066 solver.cpp:229] Iteration 5140, loss = 0.0233091
I0503 07:34:50.023397  2066 solver.cpp:245]     Train net output #0: loss = 0.0233091 (* 1 = 0.0233091 loss)
I0503 07:34:50.023413  2066 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0503 07:35:33.048063  2066 solver.cpp:229] Iteration 5160, loss = 0.003095
I0503 07:35:33.049116  2066 solver.cpp:245]     Train net output #0: loss = 0.003095 (* 1 = 0.003095 loss)
I0503 07:35:33.049134  2066 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0503 07:36:16.075098  2066 solver.cpp:229] Iteration 5180, loss = 0.0257818
I0503 07:36:16.076179  2066 solver.cpp:245]     Train net output #0: loss = 0.0257818 (* 1 = 0.0257818 loss)
I0503 07:36:16.076196  2066 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0503 07:36:59.103204  2066 solver.cpp:229] Iteration 5200, loss = 0.0411693
I0503 07:36:59.104432  2066 solver.cpp:245]     Train net output #0: loss = 0.0411693 (* 1 = 0.0411693 loss)
I0503 07:36:59.104452  2066 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0503 07:37:42.129164  2066 solver.cpp:229] Iteration 5220, loss = 0.0158543
I0503 07:37:42.130240  2066 solver.cpp:245]     Train net output #0: loss = 0.0158543 (* 1 = 0.0158543 loss)
I0503 07:37:42.130256  2066 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0503 07:38:25.153376  2066 solver.cpp:229] Iteration 5240, loss = 0.00874186
I0503 07:38:25.154407  2066 solver.cpp:245]     Train net output #0: loss = 0.00874186 (* 1 = 0.00874186 loss)
I0503 07:38:25.154423  2066 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0503 07:39:08.180007  2066 solver.cpp:229] Iteration 5260, loss = 0.027706
I0503 07:39:08.181160  2066 solver.cpp:245]     Train net output #0: loss = 0.027706 (* 1 = 0.027706 loss)
I0503 07:39:08.181177  2066 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0503 07:39:51.207528  2066 solver.cpp:229] Iteration 5280, loss = 0.0449602
I0503 07:39:51.208653  2066 solver.cpp:245]     Train net output #0: loss = 0.0449602 (* 1 = 0.0449602 loss)
I0503 07:39:51.208674  2066 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0503 07:40:34.233659  2066 solver.cpp:229] Iteration 5300, loss = 0.0210314
I0503 07:40:34.246050  2066 solver.cpp:245]     Train net output #0: loss = 0.0210314 (* 1 = 0.0210314 loss)
I0503 07:40:34.246068  2066 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0503 07:41:17.261502  2066 solver.cpp:229] Iteration 5320, loss = 0.0541515
I0503 07:41:17.262568  2066 solver.cpp:245]     Train net output #0: loss = 0.0541514 (* 1 = 0.0541514 loss)
I0503 07:41:17.262585  2066 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0503 07:42:00.288521  2066 solver.cpp:229] Iteration 5340, loss = 0.00639003
I0503 07:42:00.289683  2066 solver.cpp:245]     Train net output #0: loss = 0.00639001 (* 1 = 0.00639001 loss)
I0503 07:42:00.289700  2066 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0503 07:42:43.314294  2066 solver.cpp:229] Iteration 5360, loss = 0.00315023
I0503 07:42:43.315376  2066 solver.cpp:245]     Train net output #0: loss = 0.00315022 (* 1 = 0.00315022 loss)
I0503 07:42:43.315393  2066 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0503 07:43:26.339884  2066 solver.cpp:229] Iteration 5380, loss = 0.00281799
I0503 07:43:26.340917  2066 solver.cpp:245]     Train net output #0: loss = 0.00281798 (* 1 = 0.00281798 loss)
I0503 07:43:26.340934  2066 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0503 07:44:09.363548  2066 solver.cpp:229] Iteration 5400, loss = 0.00696899
I0503 07:44:09.364670  2066 solver.cpp:245]     Train net output #0: loss = 0.00696898 (* 1 = 0.00696898 loss)
I0503 07:44:09.364686  2066 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0503 07:44:52.387562  2066 solver.cpp:229] Iteration 5420, loss = 0.0217166
I0503 07:44:52.388838  2066 solver.cpp:245]     Train net output #0: loss = 0.0217165 (* 1 = 0.0217165 loss)
I0503 07:44:52.388854  2066 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0503 07:45:35.412649  2066 solver.cpp:229] Iteration 5440, loss = 0.0308789
I0503 07:45:35.413617  2066 solver.cpp:245]     Train net output #0: loss = 0.0308788 (* 1 = 0.0308788 loss)
I0503 07:45:35.413635  2066 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0503 07:46:18.436621  2066 solver.cpp:229] Iteration 5460, loss = 0.00469384
I0503 07:46:18.437734  2066 solver.cpp:245]     Train net output #0: loss = 0.00469382 (* 1 = 0.00469382 loss)
I0503 07:46:18.437752  2066 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0503 07:47:01.464517  2066 solver.cpp:229] Iteration 5480, loss = 0.0531389
I0503 07:47:01.466567  2066 solver.cpp:245]     Train net output #0: loss = 0.0531389 (* 1 = 0.0531389 loss)
I0503 07:47:01.466588  2066 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0503 07:47:44.490032  2066 solver.cpp:229] Iteration 5500, loss = 0.0513993
I0503 07:47:44.491000  2066 solver.cpp:245]     Train net output #0: loss = 0.0513992 (* 1 = 0.0513992 loss)
I0503 07:47:44.491016  2066 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0503 07:48:27.517779  2066 solver.cpp:229] Iteration 5520, loss = 0.0113156
I0503 07:48:27.518863  2066 solver.cpp:245]     Train net output #0: loss = 0.0113156 (* 1 = 0.0113156 loss)
I0503 07:48:27.518882  2066 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0503 07:49:10.543726  2066 solver.cpp:229] Iteration 5540, loss = 0.0138311
I0503 07:49:10.544827  2066 solver.cpp:245]     Train net output #0: loss = 0.0138311 (* 1 = 0.0138311 loss)
I0503 07:49:10.544844  2066 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0503 07:49:53.569499  2066 solver.cpp:229] Iteration 5560, loss = 0.016913
I0503 07:49:53.570566  2066 solver.cpp:245]     Train net output #0: loss = 0.016913 (* 1 = 0.016913 loss)
I0503 07:49:53.570583  2066 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0503 07:50:36.594202  2066 solver.cpp:229] Iteration 5580, loss = 0.0172557
I0503 07:50:36.595290  2066 solver.cpp:245]     Train net output #0: loss = 0.0172557 (* 1 = 0.0172557 loss)
I0503 07:50:36.595307  2066 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0503 07:51:19.621920  2066 solver.cpp:229] Iteration 5600, loss = 0.0245093
I0503 07:51:19.623128  2066 solver.cpp:245]     Train net output #0: loss = 0.0245093 (* 1 = 0.0245093 loss)
I0503 07:51:19.623147  2066 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0503 07:52:02.649832  2066 solver.cpp:229] Iteration 5620, loss = 0.0106582
I0503 07:52:02.651052  2066 solver.cpp:245]     Train net output #0: loss = 0.0106582 (* 1 = 0.0106582 loss)
I0503 07:52:02.651080  2066 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0503 07:52:45.679100  2066 solver.cpp:229] Iteration 5640, loss = 0.0177098
I0503 07:52:45.680200  2066 solver.cpp:245]     Train net output #0: loss = 0.0177098 (* 1 = 0.0177098 loss)
I0503 07:52:45.680217  2066 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0503 07:53:28.704586  2066 solver.cpp:229] Iteration 5660, loss = 0.0147436
I0503 07:53:28.705663  2066 solver.cpp:245]     Train net output #0: loss = 0.0147436 (* 1 = 0.0147436 loss)
I0503 07:53:28.705682  2066 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0503 07:54:11.730082  2066 solver.cpp:229] Iteration 5680, loss = 0.01045
I0503 07:54:11.731140  2066 solver.cpp:245]     Train net output #0: loss = 0.01045 (* 1 = 0.01045 loss)
I0503 07:54:11.731159  2066 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0503 07:54:54.758972  2066 solver.cpp:229] Iteration 5700, loss = 0.0114312
I0503 07:54:54.760267  2066 solver.cpp:245]     Train net output #0: loss = 0.0114312 (* 1 = 0.0114312 loss)
I0503 07:54:54.760285  2066 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0503 07:55:37.787973  2066 solver.cpp:229] Iteration 5720, loss = 0.00889638
I0503 07:55:37.789013  2066 solver.cpp:245]     Train net output #0: loss = 0.00889637 (* 1 = 0.00889637 loss)
I0503 07:55:37.789031  2066 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0503 07:56:20.813740  2066 solver.cpp:229] Iteration 5740, loss = 0.0187357
I0503 07:56:20.814762  2066 solver.cpp:245]     Train net output #0: loss = 0.0187357 (* 1 = 0.0187357 loss)
I0503 07:56:20.814779  2066 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0503 07:57:03.843327  2066 solver.cpp:229] Iteration 5760, loss = 0.00706363
I0503 07:57:03.848950  2066 solver.cpp:245]     Train net output #0: loss = 0.00706361 (* 1 = 0.00706361 loss)
I0503 07:57:03.848969  2066 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0503 07:57:46.873189  2066 solver.cpp:229] Iteration 5780, loss = 0.0194044
I0503 07:57:46.874270  2066 solver.cpp:245]     Train net output #0: loss = 0.0194044 (* 1 = 0.0194044 loss)
I0503 07:57:46.874286  2066 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0503 07:58:29.901784  2066 solver.cpp:229] Iteration 5800, loss = 0.00986765
I0503 07:58:29.902902  2066 solver.cpp:245]     Train net output #0: loss = 0.00986763 (* 1 = 0.00986763 loss)
I0503 07:58:29.902920  2066 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0503 07:59:12.931113  2066 solver.cpp:229] Iteration 5820, loss = 0.00710469
I0503 07:59:12.932235  2066 solver.cpp:245]     Train net output #0: loss = 0.00710467 (* 1 = 0.00710467 loss)
I0503 07:59:12.932255  2066 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0503 07:59:55.962263  2066 solver.cpp:229] Iteration 5840, loss = 0.00815841
I0503 07:59:55.963374  2066 solver.cpp:245]     Train net output #0: loss = 0.00815839 (* 1 = 0.00815839 loss)
I0503 07:59:55.963392  2066 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0503 08:00:38.993520  2066 solver.cpp:229] Iteration 5860, loss = 0.0148499
I0503 08:00:38.994549  2066 solver.cpp:245]     Train net output #0: loss = 0.0148499 (* 1 = 0.0148499 loss)
I0503 08:00:38.994565  2066 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0503 08:01:22.022452  2066 solver.cpp:229] Iteration 5880, loss = 0.0131649
I0503 08:01:22.023664  2066 solver.cpp:245]     Train net output #0: loss = 0.0131649 (* 1 = 0.0131649 loss)
I0503 08:01:22.023681  2066 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0503 08:02:05.049855  2066 solver.cpp:229] Iteration 5900, loss = 0.0134103
I0503 08:02:05.050956  2066 solver.cpp:245]     Train net output #0: loss = 0.0134103 (* 1 = 0.0134103 loss)
I0503 08:02:05.050971  2066 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0503 08:02:48.080795  2066 solver.cpp:229] Iteration 5920, loss = 0.021343
I0503 08:02:48.081933  2066 solver.cpp:245]     Train net output #0: loss = 0.021343 (* 1 = 0.021343 loss)
I0503 08:02:48.081949  2066 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0503 08:03:31.111618  2066 solver.cpp:229] Iteration 5940, loss = 0.0106175
I0503 08:03:31.112738  2066 solver.cpp:245]     Train net output #0: loss = 0.0106175 (* 1 = 0.0106175 loss)
I0503 08:03:31.112758  2066 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0503 08:04:14.141887  2066 solver.cpp:229] Iteration 5960, loss = 0.00533853
I0503 08:04:14.143003  2066 solver.cpp:245]     Train net output #0: loss = 0.00533851 (* 1 = 0.00533851 loss)
I0503 08:04:14.143023  2066 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0503 08:04:57.169268  2066 solver.cpp:229] Iteration 5980, loss = 0.0368642
I0503 08:04:57.170351  2066 solver.cpp:245]     Train net output #0: loss = 0.0368642 (* 1 = 0.0368642 loss)
I0503 08:04:57.170367  2066 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0503 08:05:38.053719  2066 solver.cpp:338] Iteration 6000, Testing net (#0)
I0503 08:08:28.134519  2066 solver.cpp:406]     Test net output #0: accuracy = 0.995659
I0503 08:08:28.135773  2066 solver.cpp:406]     Test net output #1: loss = 0.0152874 (* 1 = 0.0152874 loss)
I0503 08:08:30.102170  2066 solver.cpp:229] Iteration 6000, loss = 0.0134193
I0503 08:08:30.102243  2066 solver.cpp:245]     Train net output #0: loss = 0.0134193 (* 1 = 0.0134193 loss)
I0503 08:08:30.102257  2066 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0503 08:09:13.128123  2066 solver.cpp:229] Iteration 6020, loss = 0.0689508
I0503 08:09:13.129241  2066 solver.cpp:245]     Train net output #0: loss = 0.0689508 (* 1 = 0.0689508 loss)
I0503 08:09:13.129258  2066 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0503 08:09:56.150008  2066 solver.cpp:229] Iteration 6040, loss = 0.0306682
I0503 08:09:56.151087  2066 solver.cpp:245]     Train net output #0: loss = 0.0306682 (* 1 = 0.0306682 loss)
I0503 08:09:56.151103  2066 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0503 08:10:39.174618  2066 solver.cpp:229] Iteration 6060, loss = 0.0155026
I0503 08:10:39.175714  2066 solver.cpp:245]     Train net output #0: loss = 0.0155026 (* 1 = 0.0155026 loss)
I0503 08:10:39.175731  2066 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0503 08:11:22.200996  2066 solver.cpp:229] Iteration 6080, loss = 0.0120458
I0503 08:11:22.202105  2066 solver.cpp:245]     Train net output #0: loss = 0.0120458 (* 1 = 0.0120458 loss)
I0503 08:11:22.202121  2066 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0503 08:12:05.227833  2066 solver.cpp:229] Iteration 6100, loss = 0.0137216
I0503 08:12:05.229007  2066 solver.cpp:245]     Train net output #0: loss = 0.0137216 (* 1 = 0.0137216 loss)
I0503 08:12:05.229023  2066 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0503 08:12:48.254364  2066 solver.cpp:229] Iteration 6120, loss = 0.00399084
I0503 08:12:48.255465  2066 solver.cpp:245]     Train net output #0: loss = 0.00399084 (* 1 = 0.00399084 loss)
I0503 08:12:48.255482  2066 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0503 08:13:31.283063  2066 solver.cpp:229] Iteration 6140, loss = 0.00219599
I0503 08:13:31.284314  2066 solver.cpp:245]     Train net output #0: loss = 0.00219599 (* 1 = 0.00219599 loss)
I0503 08:13:31.284333  2066 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0503 08:14:14.309305  2066 solver.cpp:229] Iteration 6160, loss = 0.0297768
I0503 08:14:14.310441  2066 solver.cpp:245]     Train net output #0: loss = 0.0297768 (* 1 = 0.0297768 loss)
I0503 08:14:14.310457  2066 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0503 08:14:57.337512  2066 solver.cpp:229] Iteration 6180, loss = 0.00776964
I0503 08:14:57.338572  2066 solver.cpp:245]     Train net output #0: loss = 0.00776964 (* 1 = 0.00776964 loss)
I0503 08:14:57.338588  2066 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0503 08:15:40.364564  2066 solver.cpp:229] Iteration 6200, loss = 0.0249675
I0503 08:15:40.365582  2066 solver.cpp:245]     Train net output #0: loss = 0.0249675 (* 1 = 0.0249675 loss)
I0503 08:15:40.365602  2066 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0503 08:16:23.392371  2066 solver.cpp:229] Iteration 6220, loss = 0.00585543
I0503 08:16:23.393455  2066 solver.cpp:245]     Train net output #0: loss = 0.00585543 (* 1 = 0.00585543 loss)
I0503 08:16:23.393471  2066 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0503 08:17:06.420737  2066 solver.cpp:229] Iteration 6240, loss = 0.0302087
I0503 08:17:06.421892  2066 solver.cpp:245]     Train net output #0: loss = 0.0302087 (* 1 = 0.0302087 loss)
I0503 08:17:06.421911  2066 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0503 08:17:49.451980  2066 solver.cpp:229] Iteration 6260, loss = 0.0132435
I0503 08:17:49.453150  2066 solver.cpp:245]     Train net output #0: loss = 0.0132435 (* 1 = 0.0132435 loss)
I0503 08:17:49.453166  2066 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0503 08:18:32.480599  2066 solver.cpp:229] Iteration 6280, loss = 0.0152749
I0503 08:18:32.481721  2066 solver.cpp:245]     Train net output #0: loss = 0.0152749 (* 1 = 0.0152749 loss)
I0503 08:18:32.481741  2066 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0503 08:19:15.512217  2066 solver.cpp:229] Iteration 6300, loss = 0.0406094
I0503 08:19:15.513303  2066 solver.cpp:245]     Train net output #0: loss = 0.0406094 (* 1 = 0.0406094 loss)
I0503 08:19:15.513321  2066 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0503 08:19:58.541909  2066 solver.cpp:229] Iteration 6320, loss = 0.0159256
I0503 08:19:58.543179  2066 solver.cpp:245]     Train net output #0: loss = 0.0159256 (* 1 = 0.0159256 loss)
I0503 08:19:58.543197  2066 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0503 08:20:41.572505  2066 solver.cpp:229] Iteration 6340, loss = 0.0182315
I0503 08:20:41.573582  2066 solver.cpp:245]     Train net output #0: loss = 0.0182316 (* 1 = 0.0182316 loss)
I0503 08:20:41.573601  2066 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0503 08:21:24.602609  2066 solver.cpp:229] Iteration 6360, loss = 0.0265703
I0503 08:21:24.603700  2066 solver.cpp:245]     Train net output #0: loss = 0.0265703 (* 1 = 0.0265703 loss)
I0503 08:21:24.603718  2066 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0503 08:22:07.633373  2066 solver.cpp:229] Iteration 6380, loss = 0.00755686
I0503 08:22:07.634552  2066 solver.cpp:245]     Train net output #0: loss = 0.00755687 (* 1 = 0.00755687 loss)
I0503 08:22:07.634570  2066 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0503 08:22:50.667665  2066 solver.cpp:229] Iteration 6400, loss = 0.046835
I0503 08:22:50.668828  2066 solver.cpp:245]     Train net output #0: loss = 0.046835 (* 1 = 0.046835 loss)
I0503 08:22:50.668845  2066 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0503 08:23:33.698210  2066 solver.cpp:229] Iteration 6420, loss = 0.0191802
I0503 08:23:33.699285  2066 solver.cpp:245]     Train net output #0: loss = 0.0191802 (* 1 = 0.0191802 loss)
I0503 08:23:33.699301  2066 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0503 08:24:16.728828  2066 solver.cpp:229] Iteration 6440, loss = 0.00747783
I0503 08:24:16.729851  2066 solver.cpp:245]     Train net output #0: loss = 0.00747783 (* 1 = 0.00747783 loss)
I0503 08:24:16.729869  2066 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0503 08:24:59.759217  2066 solver.cpp:229] Iteration 6460, loss = 0.00780664
I0503 08:24:59.760558  2066 solver.cpp:245]     Train net output #0: loss = 0.00780665 (* 1 = 0.00780665 loss)
I0503 08:24:59.760576  2066 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0503 08:25:42.790328  2066 solver.cpp:229] Iteration 6480, loss = 0.00196982
I0503 08:25:42.791424  2066 solver.cpp:245]     Train net output #0: loss = 0.00196983 (* 1 = 0.00196983 loss)
I0503 08:25:42.791440  2066 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0503 08:26:25.821136  2066 solver.cpp:229] Iteration 6500, loss = 0.0318864
I0503 08:26:25.822129  2066 solver.cpp:245]     Train net output #0: loss = 0.0318864 (* 1 = 0.0318864 loss)
I0503 08:26:25.822145  2066 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0503 08:27:08.852221  2066 solver.cpp:229] Iteration 6520, loss = 0.0311979
I0503 08:27:08.853404  2066 solver.cpp:245]     Train net output #0: loss = 0.0311979 (* 1 = 0.0311979 loss)
I0503 08:27:08.853423  2066 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0503 08:27:51.885342  2066 solver.cpp:229] Iteration 6540, loss = 0.0102965
I0503 08:27:51.886431  2066 solver.cpp:245]     Train net output #0: loss = 0.0102965 (* 1 = 0.0102965 loss)
I0503 08:27:51.886448  2066 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0503 08:28:34.917093  2066 solver.cpp:229] Iteration 6560, loss = 0.0110049
I0503 08:28:34.918141  2066 solver.cpp:245]     Train net output #0: loss = 0.0110049 (* 1 = 0.0110049 loss)
I0503 08:28:34.918159  2066 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0503 08:29:17.947197  2066 solver.cpp:229] Iteration 6580, loss = 0.0203812
I0503 08:29:17.948289  2066 solver.cpp:245]     Train net output #0: loss = 0.0203812 (* 1 = 0.0203812 loss)
I0503 08:29:17.948307  2066 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0503 08:30:00.980507  2066 solver.cpp:229] Iteration 6600, loss = 0.00113472
I0503 08:30:00.981747  2066 solver.cpp:245]     Train net output #0: loss = 0.00113472 (* 1 = 0.00113472 loss)
I0503 08:30:00.981765  2066 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0503 08:30:44.014607  2066 solver.cpp:229] Iteration 6620, loss = 0.0147774
I0503 08:30:44.025624  2066 solver.cpp:245]     Train net output #0: loss = 0.0147774 (* 1 = 0.0147774 loss)
I0503 08:30:44.025641  2066 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0503 08:31:27.049199  2066 solver.cpp:229] Iteration 6640, loss = 0.00188912
I0503 08:31:27.050312  2066 solver.cpp:245]     Train net output #0: loss = 0.00188913 (* 1 = 0.00188913 loss)
I0503 08:31:27.050329  2066 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0503 08:32:10.083828  2066 solver.cpp:229] Iteration 6660, loss = 0.00199316
I0503 08:32:10.084985  2066 solver.cpp:245]     Train net output #0: loss = 0.00199317 (* 1 = 0.00199317 loss)
I0503 08:32:10.085003  2066 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0503 08:32:53.117619  2066 solver.cpp:229] Iteration 6680, loss = 0.0151397
I0503 08:32:53.118815  2066 solver.cpp:245]     Train net output #0: loss = 0.0151397 (* 1 = 0.0151397 loss)
I0503 08:32:53.118831  2066 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0503 08:33:36.150166  2066 solver.cpp:229] Iteration 6700, loss = 0.00830439
I0503 08:33:36.151275  2066 solver.cpp:245]     Train net output #0: loss = 0.0083044 (* 1 = 0.0083044 loss)
I0503 08:33:36.151291  2066 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0503 08:34:19.183472  2066 solver.cpp:229] Iteration 6720, loss = 0.0121378
I0503 08:34:19.184594  2066 solver.cpp:245]     Train net output #0: loss = 0.0121379 (* 1 = 0.0121379 loss)
I0503 08:34:19.184612  2066 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0503 08:35:02.217339  2066 solver.cpp:229] Iteration 6740, loss = 0.00607898
I0503 08:35:02.218557  2066 solver.cpp:245]     Train net output #0: loss = 0.00607899 (* 1 = 0.00607899 loss)
I0503 08:35:02.218576  2066 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0503 08:35:45.250030  2066 solver.cpp:229] Iteration 6760, loss = 0.0128427
I0503 08:35:45.251163  2066 solver.cpp:245]     Train net output #0: loss = 0.0128427 (* 1 = 0.0128427 loss)
I0503 08:35:45.251179  2066 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0503 08:36:28.281942  2066 solver.cpp:229] Iteration 6780, loss = 0.0163924
I0503 08:36:28.283078  2066 solver.cpp:245]     Train net output #0: loss = 0.0163925 (* 1 = 0.0163925 loss)
I0503 08:36:28.283097  2066 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0503 08:37:11.314411  2066 solver.cpp:229] Iteration 6800, loss = 0.00995255
I0503 08:37:11.315551  2066 solver.cpp:245]     Train net output #0: loss = 0.00995256 (* 1 = 0.00995256 loss)
I0503 08:37:11.315569  2066 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0503 08:37:54.348183  2066 solver.cpp:229] Iteration 6820, loss = 0.00502822
I0503 08:37:54.349498  2066 solver.cpp:245]     Train net output #0: loss = 0.00502823 (* 1 = 0.00502823 loss)
I0503 08:37:54.349516  2066 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0503 08:38:37.379516  2066 solver.cpp:229] Iteration 6840, loss = 0.0110091
I0503 08:38:37.380612  2066 solver.cpp:245]     Train net output #0: loss = 0.0110091 (* 1 = 0.0110091 loss)
I0503 08:38:37.380630  2066 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0503 08:39:20.412963  2066 solver.cpp:229] Iteration 6860, loss = 0.0162908
I0503 08:39:20.414037  2066 solver.cpp:245]     Train net output #0: loss = 0.0162908 (* 1 = 0.0162908 loss)
I0503 08:39:20.414054  2066 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0503 08:40:03.443461  2066 solver.cpp:229] Iteration 6880, loss = 0.00472804
I0503 08:40:03.444615  2066 solver.cpp:245]     Train net output #0: loss = 0.00472804 (* 1 = 0.00472804 loss)
I0503 08:40:03.444633  2066 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0503 08:40:46.475169  2066 solver.cpp:229] Iteration 6900, loss = 0.00147424
I0503 08:40:46.476228  2066 solver.cpp:245]     Train net output #0: loss = 0.00147424 (* 1 = 0.00147424 loss)
I0503 08:40:46.476244  2066 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0503 08:41:29.507948  2066 solver.cpp:229] Iteration 6920, loss = 0.0255163
I0503 08:41:29.509032  2066 solver.cpp:245]     Train net output #0: loss = 0.0255163 (* 1 = 0.0255163 loss)
I0503 08:41:29.509050  2066 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0503 08:42:12.539871  2066 solver.cpp:229] Iteration 6940, loss = 0.0138149
I0503 08:42:12.541021  2066 solver.cpp:245]     Train net output #0: loss = 0.0138149 (* 1 = 0.0138149 loss)
I0503 08:42:12.541041  2066 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0503 08:42:55.572363  2066 solver.cpp:229] Iteration 6960, loss = 0.00762948
I0503 08:42:55.573482  2066 solver.cpp:245]     Train net output #0: loss = 0.00762948 (* 1 = 0.00762948 loss)
I0503 08:42:55.573499  2066 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0503 08:43:38.606289  2066 solver.cpp:229] Iteration 6980, loss = 0.0101038
I0503 08:43:38.607352  2066 solver.cpp:245]     Train net output #0: loss = 0.0101038 (* 1 = 0.0101038 loss)
I0503 08:43:38.607368  2066 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0503 08:44:19.498730  2066 solver.cpp:338] Iteration 7000, Testing net (#0)
I0503 08:47:09.408783  2066 solver.cpp:406]     Test net output #0: accuracy = 0.994698
I0503 08:47:09.409987  2066 solver.cpp:406]     Test net output #1: loss = 0.0211607 (* 1 = 0.0211607 loss)
I0503 08:47:11.376199  2066 solver.cpp:229] Iteration 7000, loss = 0.00252698
I0503 08:47:11.376271  2066 solver.cpp:245]     Train net output #0: loss = 0.00252698 (* 1 = 0.00252698 loss)
I0503 08:47:11.376284  2066 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0503 08:47:54.393021  2066 solver.cpp:229] Iteration 7020, loss = 0.00532442
I0503 08:47:54.394142  2066 solver.cpp:245]     Train net output #0: loss = 0.00532442 (* 1 = 0.00532442 loss)
I0503 08:47:54.394160  2066 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0503 08:48:37.409963  2066 solver.cpp:229] Iteration 7040, loss = 0.0169981
I0503 08:48:37.411083  2066 solver.cpp:245]     Train net output #0: loss = 0.0169981 (* 1 = 0.0169981 loss)
I0503 08:48:37.411101  2066 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0503 08:49:20.428614  2066 solver.cpp:229] Iteration 7060, loss = 0.0104516
I0503 08:49:20.429718  2066 solver.cpp:245]     Train net output #0: loss = 0.0104516 (* 1 = 0.0104516 loss)
I0503 08:49:20.429733  2066 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0503 08:50:03.445457  2066 solver.cpp:229] Iteration 7080, loss = 0.0153893
I0503 08:50:03.446679  2066 solver.cpp:245]     Train net output #0: loss = 0.0153893 (* 1 = 0.0153893 loss)
I0503 08:50:03.446696  2066 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0503 08:50:46.461904  2066 solver.cpp:229] Iteration 7100, loss = 0.0140423
I0503 08:50:46.462982  2066 solver.cpp:245]     Train net output #0: loss = 0.0140423 (* 1 = 0.0140423 loss)
I0503 08:50:46.462997  2066 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0503 08:51:29.477849  2066 solver.cpp:229] Iteration 7120, loss = 0.00864319
I0503 08:51:29.479043  2066 solver.cpp:245]     Train net output #0: loss = 0.00864318 (* 1 = 0.00864318 loss)
I0503 08:51:29.479064  2066 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0503 08:52:12.495139  2066 solver.cpp:229] Iteration 7140, loss = 0.0223861
I0503 08:52:12.496345  2066 solver.cpp:245]     Train net output #0: loss = 0.0223861 (* 1 = 0.0223861 loss)
I0503 08:52:12.496363  2066 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0503 08:52:55.512569  2066 solver.cpp:229] Iteration 7160, loss = 0.0156098
I0503 08:52:55.513712  2066 solver.cpp:245]     Train net output #0: loss = 0.0156098 (* 1 = 0.0156098 loss)
I0503 08:52:55.513730  2066 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0503 08:53:38.533366  2066 solver.cpp:229] Iteration 7180, loss = 0.0226466
I0503 08:53:38.534503  2066 solver.cpp:245]     Train net output #0: loss = 0.0226466 (* 1 = 0.0226466 loss)
I0503 08:53:38.534521  2066 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0503 08:54:21.552757  2066 solver.cpp:229] Iteration 7200, loss = 0.00402277
I0503 08:54:21.553861  2066 solver.cpp:245]     Train net output #0: loss = 0.00402277 (* 1 = 0.00402277 loss)
I0503 08:54:21.553879  2066 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0503 08:55:04.572053  2066 solver.cpp:229] Iteration 7220, loss = 0.00688038
I0503 08:55:04.573173  2066 solver.cpp:245]     Train net output #0: loss = 0.00688038 (* 1 = 0.00688038 loss)
I0503 08:55:04.573189  2066 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0503 08:55:47.588951  2066 solver.cpp:229] Iteration 7240, loss = 0.0327657
I0503 08:55:47.589972  2066 solver.cpp:245]     Train net output #0: loss = 0.0327657 (* 1 = 0.0327657 loss)
I0503 08:55:47.589990  2066 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0503 08:56:30.604625  2066 solver.cpp:229] Iteration 7260, loss = 0.00507861
I0503 08:56:30.605808  2066 solver.cpp:245]     Train net output #0: loss = 0.00507861 (* 1 = 0.00507861 loss)
I0503 08:56:30.605825  2066 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0503 08:57:13.619511  2066 solver.cpp:229] Iteration 7280, loss = 0.028649
I0503 08:57:13.620669  2066 solver.cpp:245]     Train net output #0: loss = 0.028649 (* 1 = 0.028649 loss)
I0503 08:57:13.620688  2066 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0503 08:57:56.633293  2066 solver.cpp:229] Iteration 7300, loss = 0.0408612
I0503 08:57:56.634394  2066 solver.cpp:245]     Train net output #0: loss = 0.0408612 (* 1 = 0.0408612 loss)
I0503 08:57:56.634412  2066 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0503 08:58:39.650609  2066 solver.cpp:229] Iteration 7320, loss = 0.00722369
I0503 08:58:39.651671  2066 solver.cpp:245]     Train net output #0: loss = 0.00722368 (* 1 = 0.00722368 loss)
I0503 08:58:39.651690  2066 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0503 08:59:22.666841  2066 solver.cpp:229] Iteration 7340, loss = 0.0288141
I0503 08:59:22.667888  2066 solver.cpp:245]     Train net output #0: loss = 0.0288141 (* 1 = 0.0288141 loss)
I0503 08:59:22.667903  2066 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0503 09:00:05.679903  2066 solver.cpp:229] Iteration 7360, loss = 0.00850701
I0503 09:00:05.681071  2066 solver.cpp:245]     Train net output #0: loss = 0.008507 (* 1 = 0.008507 loss)
I0503 09:00:05.681087  2066 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0503 09:00:48.695765  2066 solver.cpp:229] Iteration 7380, loss = 0.00737055
I0503 09:00:48.696887  2066 solver.cpp:245]     Train net output #0: loss = 0.00737054 (* 1 = 0.00737054 loss)
I0503 09:00:48.696902  2066 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0503 09:01:31.711424  2066 solver.cpp:229] Iteration 7400, loss = 0.0129707
I0503 09:01:31.712551  2066 solver.cpp:245]     Train net output #0: loss = 0.0129707 (* 1 = 0.0129707 loss)
I0503 09:01:31.712568  2066 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0503 09:02:14.728428  2066 solver.cpp:229] Iteration 7420, loss = 0.00872666
I0503 09:02:14.729524  2066 solver.cpp:245]     Train net output #0: loss = 0.00872665 (* 1 = 0.00872665 loss)
I0503 09:02:14.729542  2066 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0503 09:02:57.745350  2066 solver.cpp:229] Iteration 7440, loss = 0.0205164
I0503 09:02:57.746412  2066 solver.cpp:245]     Train net output #0: loss = 0.0205164 (* 1 = 0.0205164 loss)
I0503 09:02:57.746428  2066 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0503 09:03:40.760936  2066 solver.cpp:229] Iteration 7460, loss = 0.0125755
I0503 09:03:40.762032  2066 solver.cpp:245]     Train net output #0: loss = 0.0125755 (* 1 = 0.0125755 loss)
I0503 09:03:40.762049  2066 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0503 09:04:23.776051  2066 solver.cpp:229] Iteration 7480, loss = 0.00775999
I0503 09:04:23.777181  2066 solver.cpp:245]     Train net output #0: loss = 0.00775997 (* 1 = 0.00775997 loss)
I0503 09:04:23.777200  2066 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0503 09:05:06.789341  2066 solver.cpp:229] Iteration 7500, loss = 0.00885206
I0503 09:05:06.790519  2066 solver.cpp:245]     Train net output #0: loss = 0.00885205 (* 1 = 0.00885205 loss)
I0503 09:05:06.790535  2066 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0503 09:05:49.802533  2066 solver.cpp:229] Iteration 7520, loss = 0.0163269
I0503 09:05:49.803593  2066 solver.cpp:245]     Train net output #0: loss = 0.0163269 (* 1 = 0.0163269 loss)
I0503 09:05:49.803609  2066 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0503 09:06:32.815910  2066 solver.cpp:229] Iteration 7540, loss = 0.00895506
I0503 09:06:32.817050  2066 solver.cpp:245]     Train net output #0: loss = 0.00895505 (* 1 = 0.00895505 loss)
I0503 09:06:32.817067  2066 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0503 09:07:15.829730  2066 solver.cpp:229] Iteration 7560, loss = 0.00377852
I0503 09:07:15.830790  2066 solver.cpp:245]     Train net output #0: loss = 0.00377851 (* 1 = 0.00377851 loss)
I0503 09:07:15.830806  2066 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0503 09:07:58.844446  2066 solver.cpp:229] Iteration 7580, loss = 0.00864378
I0503 09:07:58.845489  2066 solver.cpp:245]     Train net output #0: loss = 0.00864376 (* 1 = 0.00864376 loss)
I0503 09:07:58.845504  2066 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0503 09:08:41.864449  2066 solver.cpp:229] Iteration 7600, loss = 0.0207206
I0503 09:08:41.865519  2066 solver.cpp:245]     Train net output #0: loss = 0.0207206 (* 1 = 0.0207206 loss)
I0503 09:08:41.865535  2066 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0503 09:09:24.879950  2066 solver.cpp:229] Iteration 7620, loss = 0.00703294
I0503 09:09:24.880997  2066 solver.cpp:245]     Train net output #0: loss = 0.00703293 (* 1 = 0.00703293 loss)
I0503 09:09:24.881016  2066 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0503 09:10:07.899309  2066 solver.cpp:229] Iteration 7640, loss = 0.00537252
I0503 09:10:07.900518  2066 solver.cpp:245]     Train net output #0: loss = 0.00537251 (* 1 = 0.00537251 loss)
I0503 09:10:07.900537  2066 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0503 09:10:50.917764  2066 solver.cpp:229] Iteration 7660, loss = 0.00507955
I0503 09:10:50.918874  2066 solver.cpp:245]     Train net output #0: loss = 0.00507954 (* 1 = 0.00507954 loss)
I0503 09:10:50.918889  2066 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0503 09:11:33.934707  2066 solver.cpp:229] Iteration 7680, loss = 0.0234597
I0503 09:11:33.935811  2066 solver.cpp:245]     Train net output #0: loss = 0.0234597 (* 1 = 0.0234597 loss)
I0503 09:11:33.935827  2066 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0503 09:12:16.950026  2066 solver.cpp:229] Iteration 7700, loss = 0.0196843
I0503 09:12:16.951074  2066 solver.cpp:245]     Train net output #0: loss = 0.0196843 (* 1 = 0.0196843 loss)
I0503 09:12:16.951092  2066 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0503 09:12:59.964702  2066 solver.cpp:229] Iteration 7720, loss = 0.0199073
I0503 09:12:59.965881  2066 solver.cpp:245]     Train net output #0: loss = 0.0199073 (* 1 = 0.0199073 loss)
I0503 09:12:59.965898  2066 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0503 09:13:42.983645  2066 solver.cpp:229] Iteration 7740, loss = 0.0264917
I0503 09:13:42.984762  2066 solver.cpp:245]     Train net output #0: loss = 0.0264917 (* 1 = 0.0264917 loss)
I0503 09:13:42.984781  2066 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0503 09:14:26.002580  2066 solver.cpp:229] Iteration 7760, loss = 0.0270615
I0503 09:14:26.003783  2066 solver.cpp:245]     Train net output #0: loss = 0.0270615 (* 1 = 0.0270615 loss)
I0503 09:14:26.003801  2066 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0503 09:15:09.019562  2066 solver.cpp:229] Iteration 7780, loss = 0.00253161
I0503 09:15:09.020740  2066 solver.cpp:245]     Train net output #0: loss = 0.0025316 (* 1 = 0.0025316 loss)
I0503 09:15:09.020758  2066 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0503 09:15:52.034085  2066 solver.cpp:229] Iteration 7800, loss = 0.0124721
I0503 09:15:52.046645  2066 solver.cpp:245]     Train net output #0: loss = 0.012472 (* 1 = 0.012472 loss)
I0503 09:15:52.046663  2066 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0503 09:16:35.050214  2066 solver.cpp:229] Iteration 7820, loss = 0.00790348
I0503 09:16:35.051290  2066 solver.cpp:245]     Train net output #0: loss = 0.00790347 (* 1 = 0.00790347 loss)
I0503 09:16:35.051308  2066 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0503 09:17:18.064852  2066 solver.cpp:229] Iteration 7840, loss = 0.0124672
I0503 09:17:18.065914  2066 solver.cpp:245]     Train net output #0: loss = 0.0124672 (* 1 = 0.0124672 loss)
I0503 09:17:18.065930  2066 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0503 09:18:01.079356  2066 solver.cpp:229] Iteration 7860, loss = 0.0150789
I0503 09:18:01.080766  2066 solver.cpp:245]     Train net output #0: loss = 0.0150789 (* 1 = 0.0150789 loss)
I0503 09:18:01.080795  2066 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0503 09:18:44.097005  2066 solver.cpp:229] Iteration 7880, loss = 0.0133847
I0503 09:18:44.098198  2066 solver.cpp:245]     Train net output #0: loss = 0.0133847 (* 1 = 0.0133847 loss)
I0503 09:18:44.098217  2066 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0503 09:19:27.114305  2066 solver.cpp:229] Iteration 7900, loss = 0.00929646
I0503 09:19:27.115358  2066 solver.cpp:245]     Train net output #0: loss = 0.00929645 (* 1 = 0.00929645 loss)
I0503 09:19:27.115375  2066 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0503 09:20:10.131120  2066 solver.cpp:229] Iteration 7920, loss = 0.0149184
I0503 09:20:10.132163  2066 solver.cpp:245]     Train net output #0: loss = 0.0149184 (* 1 = 0.0149184 loss)
I0503 09:20:10.132179  2066 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0503 09:20:53.153280  2066 solver.cpp:229] Iteration 7940, loss = 0.0085066
I0503 09:20:53.154536  2066 solver.cpp:245]     Train net output #0: loss = 0.00850659 (* 1 = 0.00850659 loss)
I0503 09:20:53.154556  2066 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0503 09:21:36.171052  2066 solver.cpp:229] Iteration 7960, loss = 0.00641862
I0503 09:21:36.172116  2066 solver.cpp:245]     Train net output #0: loss = 0.00641861 (* 1 = 0.00641861 loss)
I0503 09:21:36.172132  2066 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0503 09:22:19.189656  2066 solver.cpp:229] Iteration 7980, loss = 0.00171355
I0503 09:22:19.190798  2066 solver.cpp:245]     Train net output #0: loss = 0.00171354 (* 1 = 0.00171354 loss)
I0503 09:22:19.190815  2066 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0503 09:23:00.061908  2066 solver.cpp:338] Iteration 8000, Testing net (#0)
I0503 09:25:49.816956  2066 solver.cpp:406]     Test net output #0: accuracy = 0.996799
I0503 09:25:49.818009  2066 solver.cpp:406]     Test net output #1: loss = 0.0131307 (* 1 = 0.0131307 loss)
I0503 09:25:51.784257  2066 solver.cpp:229] Iteration 8000, loss = 0.0176091
I0503 09:25:51.784324  2066 solver.cpp:245]     Train net output #0: loss = 0.0176091 (* 1 = 0.0176091 loss)
I0503 09:25:51.784338  2066 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0503 09:26:34.805747  2066 solver.cpp:229] Iteration 8020, loss = 0.0229234
I0503 09:26:34.806879  2066 solver.cpp:245]     Train net output #0: loss = 0.0229234 (* 1 = 0.0229234 loss)
I0503 09:26:34.806895  2066 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0503 09:27:17.828428  2066 solver.cpp:229] Iteration 8040, loss = 0.032984
I0503 09:27:17.829752  2066 solver.cpp:245]     Train net output #0: loss = 0.032984 (* 1 = 0.032984 loss)
I0503 09:27:17.829916  2066 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0503 09:28:00.849654  2066 solver.cpp:229] Iteration 8060, loss = 0.00190311
I0503 09:28:00.850826  2066 solver.cpp:245]     Train net output #0: loss = 0.00190311 (* 1 = 0.00190311 loss)
I0503 09:28:00.850842  2066 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0503 09:28:43.876534  2066 solver.cpp:229] Iteration 8080, loss = 0.0247731
I0503 09:28:43.877696  2066 solver.cpp:245]     Train net output #0: loss = 0.0247731 (* 1 = 0.0247731 loss)
I0503 09:28:43.877714  2066 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0503 09:29:26.902016  2066 solver.cpp:229] Iteration 8100, loss = 0.00377987
I0503 09:29:26.903203  2066 solver.cpp:245]     Train net output #0: loss = 0.00377986 (* 1 = 0.00377986 loss)
I0503 09:29:26.903218  2066 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0503 09:30:09.927146  2066 solver.cpp:229] Iteration 8120, loss = 0.0113327
I0503 09:30:09.928241  2066 solver.cpp:245]     Train net output #0: loss = 0.0113327 (* 1 = 0.0113327 loss)
I0503 09:30:09.928256  2066 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0503 09:30:52.950207  2066 solver.cpp:229] Iteration 8140, loss = 0.019037
I0503 09:30:52.951217  2066 solver.cpp:245]     Train net output #0: loss = 0.0190369 (* 1 = 0.0190369 loss)
I0503 09:30:52.951236  2066 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0503 09:31:35.973248  2066 solver.cpp:229] Iteration 8160, loss = 0.0184286
I0503 09:31:35.974328  2066 solver.cpp:245]     Train net output #0: loss = 0.0184286 (* 1 = 0.0184286 loss)
I0503 09:31:35.974346  2066 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0503 09:32:18.996942  2066 solver.cpp:229] Iteration 8180, loss = 0.0172588
I0503 09:32:18.997983  2066 solver.cpp:245]     Train net output #0: loss = 0.0172588 (* 1 = 0.0172588 loss)
I0503 09:32:18.997999  2066 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0503 09:33:02.019291  2066 solver.cpp:229] Iteration 8200, loss = 0.0152468
I0503 09:33:02.020493  2066 solver.cpp:245]     Train net output #0: loss = 0.0152468 (* 1 = 0.0152468 loss)
I0503 09:33:02.020512  2066 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0503 09:33:45.041831  2066 solver.cpp:229] Iteration 8220, loss = 0.00370638
I0503 09:33:45.042752  2066 solver.cpp:245]     Train net output #0: loss = 0.00370637 (* 1 = 0.00370637 loss)
I0503 09:33:45.042768  2066 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0503 09:34:28.063642  2066 solver.cpp:229] Iteration 8240, loss = 0.00198766
I0503 09:34:28.064738  2066 solver.cpp:245]     Train net output #0: loss = 0.00198764 (* 1 = 0.00198764 loss)
I0503 09:34:28.064759  2066 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0503 09:35:11.085521  2066 solver.cpp:229] Iteration 8260, loss = 0.00952119
I0503 09:35:11.086618  2066 solver.cpp:245]     Train net output #0: loss = 0.00952117 (* 1 = 0.00952117 loss)
I0503 09:35:11.086637  2066 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0503 09:35:54.105996  2066 solver.cpp:229] Iteration 8280, loss = 0.0234835
I0503 09:35:54.107101  2066 solver.cpp:245]     Train net output #0: loss = 0.0234835 (* 1 = 0.0234835 loss)
I0503 09:35:54.107117  2066 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0503 09:36:37.127724  2066 solver.cpp:229] Iteration 8300, loss = 0.00398814
I0503 09:36:37.128793  2066 solver.cpp:245]     Train net output #0: loss = 0.00398813 (* 1 = 0.00398813 loss)
I0503 09:36:37.128810  2066 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0503 09:37:20.146575  2066 solver.cpp:229] Iteration 8320, loss = 0.0120277
I0503 09:37:20.147665  2066 solver.cpp:245]     Train net output #0: loss = 0.0120277 (* 1 = 0.0120277 loss)
I0503 09:37:20.147682  2066 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0503 09:38:03.165967  2066 solver.cpp:229] Iteration 8340, loss = 0.0154043
I0503 09:38:03.167140  2066 solver.cpp:245]     Train net output #0: loss = 0.0154043 (* 1 = 0.0154043 loss)
I0503 09:38:03.167157  2066 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0503 09:38:46.184433  2066 solver.cpp:229] Iteration 8360, loss = 0.00634908
I0503 09:38:46.185593  2066 solver.cpp:245]     Train net output #0: loss = 0.00634907 (* 1 = 0.00634907 loss)
I0503 09:38:46.185611  2066 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0503 09:39:29.202684  2066 solver.cpp:229] Iteration 8380, loss = 0.0204615
I0503 09:39:29.203832  2066 solver.cpp:245]     Train net output #0: loss = 0.0204615 (* 1 = 0.0204615 loss)
I0503 09:39:29.203848  2066 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0503 09:40:12.219789  2066 solver.cpp:229] Iteration 8400, loss = 0.0098145
I0503 09:40:12.220938  2066 solver.cpp:245]     Train net output #0: loss = 0.00981448 (* 1 = 0.00981448 loss)
I0503 09:40:12.220958  2066 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0503 09:40:55.235002  2066 solver.cpp:229] Iteration 8420, loss = 0.0153557
I0503 09:40:55.236124  2066 solver.cpp:245]     Train net output #0: loss = 0.0153557 (* 1 = 0.0153557 loss)
I0503 09:40:55.236140  2066 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
I0503 09:41:38.254051  2066 solver.cpp:229] Iteration 8440, loss = 0.0170774
I0503 09:41:38.255149  2066 solver.cpp:245]     Train net output #0: loss = 0.0170774 (* 1 = 0.0170774 loss)
I0503 09:41:38.255165  2066 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I0503 09:42:21.273788  2066 solver.cpp:229] Iteration 8460, loss = 0.0137004
I0503 09:42:21.274901  2066 solver.cpp:245]     Train net output #0: loss = 0.0137004 (* 1 = 0.0137004 loss)
I0503 09:42:21.274917  2066 sgd_solver.cpp:106] Iteration 8460, lr = 0.01
I0503 09:43:04.294329  2066 solver.cpp:229] Iteration 8480, loss = 0.0101998
I0503 09:43:04.295585  2066 solver.cpp:245]     Train net output #0: loss = 0.0101998 (* 1 = 0.0101998 loss)
I0503 09:43:04.295605  2066 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I0503 09:43:47.313678  2066 solver.cpp:229] Iteration 8500, loss = 0.0119711
I0503 09:43:47.317770  2066 solver.cpp:245]     Train net output #0: loss = 0.0119711 (* 1 = 0.0119711 loss)
I0503 09:43:47.317788  2066 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0503 09:44:30.333947  2066 solver.cpp:229] Iteration 8520, loss = 0.0165357
I0503 09:44:30.334985  2066 solver.cpp:245]     Train net output #0: loss = 0.0165357 (* 1 = 0.0165357 loss)
I0503 09:44:30.335002  2066 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I0503 09:45:13.352193  2066 solver.cpp:229] Iteration 8540, loss = 0.0163695
I0503 09:45:13.353269  2066 solver.cpp:245]     Train net output #0: loss = 0.0163695 (* 1 = 0.0163695 loss)
I0503 09:45:13.353286  2066 sgd_solver.cpp:106] Iteration 8540, lr = 0.01
I0503 09:45:56.368904  2066 solver.cpp:229] Iteration 8560, loss = 0.00711259
I0503 09:45:56.370064  2066 solver.cpp:245]     Train net output #0: loss = 0.00711257 (* 1 = 0.00711257 loss)
I0503 09:45:56.370082  2066 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I0503 09:46:39.388478  2066 solver.cpp:229] Iteration 8580, loss = 0.00821558
I0503 09:46:39.389945  2066 solver.cpp:245]     Train net output #0: loss = 0.00821556 (* 1 = 0.00821556 loss)
I0503 09:46:39.389961  2066 sgd_solver.cpp:106] Iteration 8580, lr = 0.01
I0503 09:47:22.407325  2066 solver.cpp:229] Iteration 8600, loss = 0.00523089
I0503 09:47:22.408475  2066 solver.cpp:245]     Train net output #0: loss = 0.00523088 (* 1 = 0.00523088 loss)
I0503 09:47:22.408493  2066 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0503 09:48:05.428731  2066 solver.cpp:229] Iteration 8620, loss = 0.00321627
I0503 09:48:05.429903  2066 solver.cpp:245]     Train net output #0: loss = 0.00321625 (* 1 = 0.00321625 loss)
I0503 09:48:05.429920  2066 sgd_solver.cpp:106] Iteration 8620, lr = 0.01
I0503 09:48:48.454046  2066 solver.cpp:229] Iteration 8640, loss = 0.0215191
I0503 09:48:48.455250  2066 solver.cpp:245]     Train net output #0: loss = 0.0215191 (* 1 = 0.0215191 loss)
I0503 09:48:48.455270  2066 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I0503 09:49:31.479364  2066 solver.cpp:229] Iteration 8660, loss = 0.0171458
I0503 09:49:31.480506  2066 solver.cpp:245]     Train net output #0: loss = 0.0171457 (* 1 = 0.0171457 loss)
I0503 09:49:31.480522  2066 sgd_solver.cpp:106] Iteration 8660, lr = 0.01
I0503 09:50:14.500313  2066 solver.cpp:229] Iteration 8680, loss = 0.00747079
I0503 09:50:14.501431  2066 solver.cpp:245]     Train net output #0: loss = 0.00747077 (* 1 = 0.00747077 loss)
I0503 09:50:14.501449  2066 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I0503 09:50:57.519356  2066 solver.cpp:229] Iteration 8700, loss = 0.00291987
I0503 09:50:57.520443  2066 solver.cpp:245]     Train net output #0: loss = 0.00291985 (* 1 = 0.00291985 loss)
I0503 09:50:57.520459  2066 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0503 09:51:40.535207  2066 solver.cpp:229] Iteration 8720, loss = 0.00277114
I0503 09:51:40.536402  2066 solver.cpp:245]     Train net output #0: loss = 0.00277112 (* 1 = 0.00277112 loss)
I0503 09:51:40.536422  2066 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I0503 09:52:23.552067  2066 solver.cpp:229] Iteration 8740, loss = 0.0128521
I0503 09:52:23.553192  2066 solver.cpp:245]     Train net output #0: loss = 0.0128521 (* 1 = 0.0128521 loss)
I0503 09:52:23.553208  2066 sgd_solver.cpp:106] Iteration 8740, lr = 0.01
I0503 09:53:06.567675  2066 solver.cpp:229] Iteration 8760, loss = 0.00457463
I0503 09:53:06.568776  2066 solver.cpp:245]     Train net output #0: loss = 0.0045746 (* 1 = 0.0045746 loss)
I0503 09:53:06.568792  2066 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I0503 09:53:49.584125  2066 solver.cpp:229] Iteration 8780, loss = 0.00211823
I0503 09:53:49.585206  2066 solver.cpp:245]     Train net output #0: loss = 0.00211821 (* 1 = 0.00211821 loss)
I0503 09:53:49.585223  2066 sgd_solver.cpp:106] Iteration 8780, lr = 0.01
I0503 09:54:32.601109  2066 solver.cpp:229] Iteration 8800, loss = 0.010795
I0503 09:54:32.602236  2066 solver.cpp:245]     Train net output #0: loss = 0.0107949 (* 1 = 0.0107949 loss)
I0503 09:54:32.602254  2066 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0503 09:55:15.616226  2066 solver.cpp:229] Iteration 8820, loss = 0.0340123
I0503 09:55:15.617365  2066 solver.cpp:245]     Train net output #0: loss = 0.0340123 (* 1 = 0.0340123 loss)
I0503 09:55:15.617383  2066 sgd_solver.cpp:106] Iteration 8820, lr = 0.01
I0503 09:55:58.630206  2066 solver.cpp:229] Iteration 8840, loss = 0.00356442
I0503 09:55:58.631281  2066 solver.cpp:245]     Train net output #0: loss = 0.00356439 (* 1 = 0.00356439 loss)
I0503 09:55:58.631299  2066 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I0503 09:56:41.644083  2066 solver.cpp:229] Iteration 8860, loss = 0.00321278
I0503 09:56:41.645174  2066 solver.cpp:245]     Train net output #0: loss = 0.00321275 (* 1 = 0.00321275 loss)
I0503 09:56:41.645190  2066 sgd_solver.cpp:106] Iteration 8860, lr = 0.01
I0503 09:57:24.658957  2066 solver.cpp:229] Iteration 8880, loss = 0.00153199
I0503 09:57:24.659950  2066 solver.cpp:245]     Train net output #0: loss = 0.00153196 (* 1 = 0.00153196 loss)
I0503 09:57:24.659966  2066 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I0503 09:58:07.673857  2066 solver.cpp:229] Iteration 8900, loss = 0.00688749
I0503 09:58:07.674867  2066 solver.cpp:245]     Train net output #0: loss = 0.00688746 (* 1 = 0.00688746 loss)
I0503 09:58:07.674883  2066 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0503 09:58:50.687883  2066 solver.cpp:229] Iteration 8920, loss = 0.00210362
I0503 09:58:50.688971  2066 solver.cpp:245]     Train net output #0: loss = 0.00210359 (* 1 = 0.00210359 loss)
I0503 09:58:50.688987  2066 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I0503 09:59:33.700649  2066 solver.cpp:229] Iteration 8940, loss = 0.0321833
I0503 09:59:33.701678  2066 solver.cpp:245]     Train net output #0: loss = 0.0321833 (* 1 = 0.0321833 loss)
I0503 09:59:33.701696  2066 sgd_solver.cpp:106] Iteration 8940, lr = 0.01
I0503 10:00:16.708917  2066 solver.cpp:229] Iteration 8960, loss = 0.00365728
I0503 10:00:16.710011  2066 solver.cpp:245]     Train net output #0: loss = 0.00365725 (* 1 = 0.00365725 loss)
I0503 10:00:16.710029  2066 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I0503 10:00:59.718734  2066 solver.cpp:229] Iteration 8980, loss = 0.0166516
I0503 10:00:59.719945  2066 solver.cpp:245]     Train net output #0: loss = 0.0166516 (* 1 = 0.0166516 loss)
I0503 10:00:59.719967  2066 sgd_solver.cpp:106] Iteration 8980, lr = 0.01
I0503 10:01:40.585880  2066 solver.cpp:338] Iteration 9000, Testing net (#0)
I0503 10:04:30.477596  2066 solver.cpp:406]     Test net output #0: accuracy = 0.995799
I0503 10:04:30.478885  2066 solver.cpp:406]     Test net output #1: loss = 0.0149922 (* 1 = 0.0149922 loss)
I0503 10:04:32.445781  2066 solver.cpp:229] Iteration 9000, loss = 0.0148309
I0503 10:04:32.445848  2066 solver.cpp:245]     Train net output #0: loss = 0.0148309 (* 1 = 0.0148309 loss)
I0503 10:04:32.445863  2066 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0503 10:05:15.472795  2066 solver.cpp:229] Iteration 9020, loss = 0.00105555
I0503 10:05:15.473942  2066 solver.cpp:245]     Train net output #0: loss = 0.00105551 (* 1 = 0.00105551 loss)
I0503 10:05:15.473960  2066 sgd_solver.cpp:106] Iteration 9020, lr = 0.01
I0503 10:05:58.500797  2066 solver.cpp:229] Iteration 9040, loss = 0.0106154
I0503 10:05:58.501916  2066 solver.cpp:245]     Train net output #0: loss = 0.0106154 (* 1 = 0.0106154 loss)
I0503 10:05:58.501932  2066 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I0503 10:06:41.527166  2066 solver.cpp:229] Iteration 9060, loss = 0.0047533
I0503 10:06:41.528344  2066 solver.cpp:245]     Train net output #0: loss = 0.00475326 (* 1 = 0.00475326 loss)
I0503 10:06:41.528362  2066 sgd_solver.cpp:106] Iteration 9060, lr = 0.01
I0503 10:07:24.557543  2066 solver.cpp:229] Iteration 9080, loss = 0.00783655
I0503 10:07:24.558553  2066 solver.cpp:245]     Train net output #0: loss = 0.00783652 (* 1 = 0.00783652 loss)
I0503 10:07:24.558569  2066 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
I0503 10:08:07.590093  2066 solver.cpp:229] Iteration 9100, loss = 0.0108503
I0503 10:08:07.591186  2066 solver.cpp:245]     Train net output #0: loss = 0.0108502 (* 1 = 0.0108502 loss)
I0503 10:08:07.591200  2066 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0503 10:08:50.620892  2066 solver.cpp:229] Iteration 9120, loss = 0.00129912
I0503 10:08:50.622089  2066 solver.cpp:245]     Train net output #0: loss = 0.00129909 (* 1 = 0.00129909 loss)
I0503 10:08:50.622107  2066 sgd_solver.cpp:106] Iteration 9120, lr = 0.01
I0503 10:09:33.650818  2066 solver.cpp:229] Iteration 9140, loss = 0.00727742
I0503 10:09:33.651903  2066 solver.cpp:245]     Train net output #0: loss = 0.00727739 (* 1 = 0.00727739 loss)
I0503 10:09:33.651921  2066 sgd_solver.cpp:106] Iteration 9140, lr = 0.01
I0503 10:10:16.680959  2066 solver.cpp:229] Iteration 9160, loss = 0.00265798
I0503 10:10:16.681988  2066 solver.cpp:245]     Train net output #0: loss = 0.00265795 (* 1 = 0.00265795 loss)
I0503 10:10:16.682005  2066 sgd_solver.cpp:106] Iteration 9160, lr = 0.01
I0503 10:10:59.708009  2066 solver.cpp:229] Iteration 9180, loss = 0.00344471
I0503 10:10:59.709264  2066 solver.cpp:245]     Train net output #0: loss = 0.00344468 (* 1 = 0.00344468 loss)
I0503 10:10:59.709282  2066 sgd_solver.cpp:106] Iteration 9180, lr = 0.01
I0503 10:11:42.736850  2066 solver.cpp:229] Iteration 9200, loss = 0.00335916
I0503 10:11:42.737951  2066 solver.cpp:245]     Train net output #0: loss = 0.00335913 (* 1 = 0.00335913 loss)
I0503 10:11:42.737968  2066 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0503 10:12:25.765768  2066 solver.cpp:229] Iteration 9220, loss = 0.0128988
I0503 10:12:25.766755  2066 solver.cpp:245]     Train net output #0: loss = 0.0128988 (* 1 = 0.0128988 loss)
I0503 10:12:25.766772  2066 sgd_solver.cpp:106] Iteration 9220, lr = 0.01
I0503 10:13:08.795419  2066 solver.cpp:229] Iteration 9240, loss = 0.00401566
I0503 10:13:08.796538  2066 solver.cpp:245]     Train net output #0: loss = 0.00401563 (* 1 = 0.00401563 loss)
I0503 10:13:08.796557  2066 sgd_solver.cpp:106] Iteration 9240, lr = 0.01
I0503 10:13:51.822862  2066 solver.cpp:229] Iteration 9260, loss = 0.00801737
I0503 10:13:51.824031  2066 solver.cpp:245]     Train net output #0: loss = 0.00801734 (* 1 = 0.00801734 loss)
I0503 10:13:51.824059  2066 sgd_solver.cpp:106] Iteration 9260, lr = 0.01
I0503 10:14:34.854075  2066 solver.cpp:229] Iteration 9280, loss = 0.00246559
I0503 10:14:34.855209  2066 solver.cpp:245]     Train net output #0: loss = 0.00246556 (* 1 = 0.00246556 loss)
I0503 10:14:34.855226  2066 sgd_solver.cpp:106] Iteration 9280, lr = 0.01
I0503 10:15:17.884660  2066 solver.cpp:229] Iteration 9300, loss = 0.0132179
I0503 10:15:17.885728  2066 solver.cpp:245]     Train net output #0: loss = 0.0132179 (* 1 = 0.0132179 loss)
I0503 10:15:17.885745  2066 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0503 10:16:00.912739  2066 solver.cpp:229] Iteration 9320, loss = 0.00275004
I0503 10:16:00.914077  2066 solver.cpp:245]     Train net output #0: loss = 0.00275001 (* 1 = 0.00275001 loss)
I0503 10:16:00.914096  2066 sgd_solver.cpp:106] Iteration 9320, lr = 0.01
I0503 10:16:43.943835  2066 solver.cpp:229] Iteration 9340, loss = 0.0212106
I0503 10:16:43.944974  2066 solver.cpp:245]     Train net output #0: loss = 0.0212105 (* 1 = 0.0212105 loss)
I0503 10:16:43.944990  2066 sgd_solver.cpp:106] Iteration 9340, lr = 0.01
I0503 10:17:26.974110  2066 solver.cpp:229] Iteration 9360, loss = 0.000547228
I0503 10:17:26.975314  2066 solver.cpp:245]     Train net output #0: loss = 0.000547202 (* 1 = 0.000547202 loss)
I0503 10:17:26.975332  2066 sgd_solver.cpp:106] Iteration 9360, lr = 0.01
I0503 10:18:10.004204  2066 solver.cpp:229] Iteration 9380, loss = 0.00506279
I0503 10:18:10.005326  2066 solver.cpp:245]     Train net output #0: loss = 0.00506276 (* 1 = 0.00506276 loss)
I0503 10:18:10.005345  2066 sgd_solver.cpp:106] Iteration 9380, lr = 0.01
I0503 10:18:53.033758  2066 solver.cpp:229] Iteration 9400, loss = 0.00158668
I0503 10:18:53.034853  2066 solver.cpp:245]     Train net output #0: loss = 0.00158666 (* 1 = 0.00158666 loss)
I0503 10:18:53.034869  2066 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0503 10:19:36.064358  2066 solver.cpp:229] Iteration 9420, loss = 0.037069
I0503 10:19:36.065436  2066 solver.cpp:245]     Train net output #0: loss = 0.037069 (* 1 = 0.037069 loss)
I0503 10:19:36.065454  2066 sgd_solver.cpp:106] Iteration 9420, lr = 0.01
I0503 10:20:19.098350  2066 solver.cpp:229] Iteration 9440, loss = 0.0102688
I0503 10:20:19.099473  2066 solver.cpp:245]     Train net output #0: loss = 0.0102687 (* 1 = 0.0102687 loss)
I0503 10:20:19.099493  2066 sgd_solver.cpp:106] Iteration 9440, lr = 0.01
I0503 10:21:02.129962  2066 solver.cpp:229] Iteration 9460, loss = 0.0152638
I0503 10:21:02.131122  2066 solver.cpp:245]     Train net output #0: loss = 0.0152638 (* 1 = 0.0152638 loss)
I0503 10:21:02.131139  2066 sgd_solver.cpp:106] Iteration 9460, lr = 0.01
I0503 10:21:45.161183  2066 solver.cpp:229] Iteration 9480, loss = 0.00206003
I0503 10:21:45.162256  2066 solver.cpp:245]     Train net output #0: loss = 0.00206 (* 1 = 0.00206 loss)
I0503 10:21:45.162272  2066 sgd_solver.cpp:106] Iteration 9480, lr = 0.01
I0503 10:22:28.194850  2066 solver.cpp:229] Iteration 9500, loss = 0.00976723
I0503 10:22:28.195960  2066 solver.cpp:245]     Train net output #0: loss = 0.00976721 (* 1 = 0.00976721 loss)
I0503 10:22:28.195977  2066 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0503 10:23:11.227871  2066 solver.cpp:229] Iteration 9520, loss = 0.0123966
I0503 10:23:11.229070  2066 solver.cpp:245]     Train net output #0: loss = 0.0123966 (* 1 = 0.0123966 loss)
I0503 10:23:11.229089  2066 sgd_solver.cpp:106] Iteration 9520, lr = 0.01
I0503 10:23:54.262729  2066 solver.cpp:229] Iteration 9540, loss = 0.00178652
I0503 10:23:54.263833  2066 solver.cpp:245]     Train net output #0: loss = 0.00178649 (* 1 = 0.00178649 loss)
I0503 10:23:54.263850  2066 sgd_solver.cpp:106] Iteration 9540, lr = 0.01
I0503 10:24:37.297461  2066 solver.cpp:229] Iteration 9560, loss = 0.000748422
I0503 10:24:37.298573  2066 solver.cpp:245]     Train net output #0: loss = 0.000748399 (* 1 = 0.000748399 loss)
I0503 10:24:37.298589  2066 sgd_solver.cpp:106] Iteration 9560, lr = 0.01
I0503 10:25:20.336292  2066 solver.cpp:229] Iteration 9580, loss = 0.00271449
I0503 10:25:20.337381  2066 solver.cpp:245]     Train net output #0: loss = 0.00271447 (* 1 = 0.00271447 loss)
I0503 10:25:20.337399  2066 sgd_solver.cpp:106] Iteration 9580, lr = 0.01
I0503 10:26:03.370985  2066 solver.cpp:229] Iteration 9600, loss = 0.00590362
I0503 10:26:03.372251  2066 solver.cpp:245]     Train net output #0: loss = 0.0059036 (* 1 = 0.0059036 loss)
I0503 10:26:03.372269  2066 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0503 10:26:46.406103  2066 solver.cpp:229] Iteration 9620, loss = 0.0108484
I0503 10:26:46.407201  2066 solver.cpp:245]     Train net output #0: loss = 0.0108484 (* 1 = 0.0108484 loss)
I0503 10:26:46.407217  2066 sgd_solver.cpp:106] Iteration 9620, lr = 0.01
I0503 10:27:29.442548  2066 solver.cpp:229] Iteration 9640, loss = 0.0281769
I0503 10:27:29.443716  2066 solver.cpp:245]     Train net output #0: loss = 0.0281769 (* 1 = 0.0281769 loss)
I0503 10:27:29.443737  2066 sgd_solver.cpp:106] Iteration 9640, lr = 0.01
I0503 10:28:12.477424  2066 solver.cpp:229] Iteration 9660, loss = 0.0116809
I0503 10:28:12.478556  2066 solver.cpp:245]     Train net output #0: loss = 0.0116808 (* 1 = 0.0116808 loss)
I0503 10:28:12.478572  2066 sgd_solver.cpp:106] Iteration 9660, lr = 0.01
I0503 10:28:55.511646  2066 solver.cpp:229] Iteration 9680, loss = 0.0246888
I0503 10:28:55.512755  2066 solver.cpp:245]     Train net output #0: loss = 0.0246888 (* 1 = 0.0246888 loss)
I0503 10:28:55.512775  2066 sgd_solver.cpp:106] Iteration 9680, lr = 0.01
I0503 10:29:38.549623  2066 solver.cpp:229] Iteration 9700, loss = 0.0114954
I0503 10:29:38.550701  2066 solver.cpp:245]     Train net output #0: loss = 0.0114954 (* 1 = 0.0114954 loss)
I0503 10:29:38.550720  2066 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0503 10:30:21.583946  2066 solver.cpp:229] Iteration 9720, loss = 0.00671748
I0503 10:30:21.584998  2066 solver.cpp:245]     Train net output #0: loss = 0.00671745 (* 1 = 0.00671745 loss)
I0503 10:30:21.585016  2066 sgd_solver.cpp:106] Iteration 9720, lr = 0.01
I0503 10:31:04.620988  2066 solver.cpp:229] Iteration 9740, loss = 0.00267657
I0503 10:31:04.621969  2066 solver.cpp:245]     Train net output #0: loss = 0.00267654 (* 1 = 0.00267654 loss)
I0503 10:31:04.621986  2066 sgd_solver.cpp:106] Iteration 9740, lr = 0.01
I0503 10:31:47.653698  2066 solver.cpp:229] Iteration 9760, loss = 0.0246382
I0503 10:31:47.655040  2066 solver.cpp:245]     Train net output #0: loss = 0.0246381 (* 1 = 0.0246381 loss)
I0503 10:31:47.655056  2066 sgd_solver.cpp:106] Iteration 9760, lr = 0.01
I0503 10:32:30.689246  2066 solver.cpp:229] Iteration 9780, loss = 0.00138138
I0503 10:32:30.690420  2066 solver.cpp:245]     Train net output #0: loss = 0.00138136 (* 1 = 0.00138136 loss)
I0503 10:32:30.690438  2066 sgd_solver.cpp:106] Iteration 9780, lr = 0.01
I0503 10:33:13.723273  2066 solver.cpp:229] Iteration 9800, loss = 0.00222012
I0503 10:33:13.724433  2066 solver.cpp:245]     Train net output #0: loss = 0.00222011 (* 1 = 0.00222011 loss)
I0503 10:33:13.724450  2066 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0503 10:33:56.758090  2066 solver.cpp:229] Iteration 9820, loss = 0.00913753
I0503 10:33:56.759183  2066 solver.cpp:245]     Train net output #0: loss = 0.00913751 (* 1 = 0.00913751 loss)
I0503 10:33:56.759201  2066 sgd_solver.cpp:106] Iteration 9820, lr = 0.01
I0503 10:34:39.792208  2066 solver.cpp:229] Iteration 9840, loss = 0.00868705
I0503 10:34:39.793367  2066 solver.cpp:245]     Train net output #0: loss = 0.00868703 (* 1 = 0.00868703 loss)
I0503 10:34:39.793385  2066 sgd_solver.cpp:106] Iteration 9840, lr = 0.01
I0503 10:35:22.827775  2066 solver.cpp:229] Iteration 9860, loss = 0.00307405
I0503 10:35:22.828845  2066 solver.cpp:245]     Train net output #0: loss = 0.00307402 (* 1 = 0.00307402 loss)
I0503 10:35:22.828860  2066 sgd_solver.cpp:106] Iteration 9860, lr = 0.01
I0503 10:36:05.863281  2066 solver.cpp:229] Iteration 9880, loss = 0.0156569
I0503 10:36:05.864326  2066 solver.cpp:245]     Train net output #0: loss = 0.0156569 (* 1 = 0.0156569 loss)
I0503 10:36:05.864343  2066 sgd_solver.cpp:106] Iteration 9880, lr = 0.01
I0503 10:36:48.898548  2066 solver.cpp:229] Iteration 9900, loss = 0.00317869
I0503 10:36:48.899612  2066 solver.cpp:245]     Train net output #0: loss = 0.00317867 (* 1 = 0.00317867 loss)
I0503 10:36:48.899633  2066 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0503 10:37:31.932945  2066 solver.cpp:229] Iteration 9920, loss = 0.0198663
I0503 10:37:31.934032  2066 solver.cpp:245]     Train net output #0: loss = 0.0198663 (* 1 = 0.0198663 loss)
I0503 10:37:31.934049  2066 sgd_solver.cpp:106] Iteration 9920, lr = 0.01
I0503 10:38:14.965930  2066 solver.cpp:229] Iteration 9940, loss = 0.0169032
I0503 10:38:14.967079  2066 solver.cpp:245]     Train net output #0: loss = 0.0169032 (* 1 = 0.0169032 loss)
I0503 10:38:14.967100  2066 sgd_solver.cpp:106] Iteration 9940, lr = 0.01
I0503 10:38:58.001675  2066 solver.cpp:229] Iteration 9960, loss = 0.000885252
I0503 10:38:58.002735  2066 solver.cpp:245]     Train net output #0: loss = 0.000885237 (* 1 = 0.000885237 loss)
I0503 10:38:58.002751  2066 sgd_solver.cpp:106] Iteration 9960, lr = 0.01
I0503 10:39:41.034487  2066 solver.cpp:229] Iteration 9980, loss = 0.00493157
I0503 10:39:41.035764  2066 solver.cpp:245]     Train net output #0: loss = 0.00493156 (* 1 = 0.00493156 loss)
I0503 10:39:41.035781  2066 sgd_solver.cpp:106] Iteration 9980, lr = 0.01
I0503 10:40:21.926223  2066 solver.cpp:456] Snapshotting to binary proto file /home/user012/caffe/models/driving_caffenet/driving_caffenet_iter_10000.caffemodel
I0503 10:40:30.208096  2066 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/user012/caffe/models/driving_caffenet/driving_caffenet_iter_10000.solverstate
I0503 10:40:37.728448  2066 solver.cpp:338] Iteration 10000, Testing net (#0)
I0503 10:43:27.458168  2066 solver.cpp:406]     Test net output #0: accuracy = 0.995979
I0503 10:43:27.459306  2066 solver.cpp:406]     Test net output #1: loss = 0.0140455 (* 1 = 0.0140455 loss)
I0503 10:43:29.425482  2066 solver.cpp:229] Iteration 10000, loss = 0.00306332
I0503 10:43:29.425554  2066 solver.cpp:245]     Train net output #0: loss = 0.00306331 (* 1 = 0.00306331 loss)
I0503 10:43:29.425568  2066 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0503 10:44:12.452255  2066 solver.cpp:229] Iteration 10020, loss = 0.0130472
I0503 10:44:12.453575  2066 solver.cpp:245]     Train net output #0: loss = 0.0130472 (* 1 = 0.0130472 loss)
I0503 10:44:12.453594  2066 sgd_solver.cpp:106] Iteration 10020, lr = 0.01
I0503 10:44:55.480006  2066 solver.cpp:229] Iteration 10040, loss = 0.00223882
I0503 10:44:55.481041  2066 solver.cpp:245]     Train net output #0: loss = 0.0022388 (* 1 = 0.0022388 loss)
I0503 10:44:55.481058  2066 sgd_solver.cpp:106] Iteration 10040, lr = 0.01
I0503 10:45:38.510268  2066 solver.cpp:229] Iteration 10060, loss = 0.00104688
I0503 10:45:38.511416  2066 solver.cpp:245]     Train net output #0: loss = 0.00104687 (* 1 = 0.00104687 loss)
I0503 10:45:38.511433  2066 sgd_solver.cpp:106] Iteration 10060, lr = 0.01
I0503 10:46:21.539155  2066 solver.cpp:229] Iteration 10080, loss = 0.0105039
I0503 10:46:21.540278  2066 solver.cpp:245]     Train net output #0: loss = 0.0105039 (* 1 = 0.0105039 loss)
I0503 10:46:21.540297  2066 sgd_solver.cpp:106] Iteration 10080, lr = 0.01
I0503 10:47:04.566709  2066 solver.cpp:229] Iteration 10100, loss = 0.00112952
I0503 10:47:04.567749  2066 solver.cpp:245]     Train net output #0: loss = 0.00112951 (* 1 = 0.00112951 loss)
I0503 10:47:04.567766  2066 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0503 10:47:47.596300  2066 solver.cpp:229] Iteration 10120, loss = 0.00678705
I0503 10:47:47.597820  2066 solver.cpp:245]     Train net output #0: loss = 0.00678704 (* 1 = 0.00678704 loss)
I0503 10:47:47.597837  2066 sgd_solver.cpp:106] Iteration 10120, lr = 0.01
I0503 10:48:30.629055  2066 solver.cpp:229] Iteration 10140, loss = 0.000953089
I0503 10:48:30.630144  2066 solver.cpp:245]     Train net output #0: loss = 0.000953078 (* 1 = 0.000953078 loss)
I0503 10:48:30.630163  2066 sgd_solver.cpp:106] Iteration 10140, lr = 0.01
I0503 10:49:13.659207  2066 solver.cpp:229] Iteration 10160, loss = 0.00415616
I0503 10:49:13.660329  2066 solver.cpp:245]     Train net output #0: loss = 0.00415615 (* 1 = 0.00415615 loss)
I0503 10:49:13.660349  2066 sgd_solver.cpp:106] Iteration 10160, lr = 0.01
I0503 10:49:56.689628  2066 solver.cpp:229] Iteration 10180, loss = 0.0205285
I0503 10:49:56.690757  2066 solver.cpp:245]     Train net output #0: loss = 0.0205285 (* 1 = 0.0205285 loss)
I0503 10:49:56.690774  2066 sgd_solver.cpp:106] Iteration 10180, lr = 0.01
I0503 10:50:39.720244  2066 solver.cpp:229] Iteration 10200, loss = 0.00357234
I0503 10:50:39.721314  2066 solver.cpp:245]     Train net output #0: loss = 0.00357232 (* 1 = 0.00357232 loss)
I0503 10:50:39.721333  2066 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0503 10:51:22.751767  2066 solver.cpp:229] Iteration 10220, loss = 0.0027803
I0503 10:51:22.752889  2066 solver.cpp:245]     Train net output #0: loss = 0.00278028 (* 1 = 0.00278028 loss)
I0503 10:51:22.752905  2066 sgd_solver.cpp:106] Iteration 10220, lr = 0.01
I0503 10:52:05.784391  2066 solver.cpp:229] Iteration 10240, loss = 0.00176261
I0503 10:52:05.785498  2066 solver.cpp:245]     Train net output #0: loss = 0.00176259 (* 1 = 0.00176259 loss)
I0503 10:52:05.785516  2066 sgd_solver.cpp:106] Iteration 10240, lr = 0.01
I0503 10:52:48.816613  2066 solver.cpp:229] Iteration 10260, loss = 0.00905715
I0503 10:52:48.817667  2066 solver.cpp:245]     Train net output #0: loss = 0.00905714 (* 1 = 0.00905714 loss)
I0503 10:52:48.817684  2066 sgd_solver.cpp:106] Iteration 10260, lr = 0.01
I0503 10:53:31.848503  2066 solver.cpp:229] Iteration 10280, loss = 0.0114045
I0503 10:53:31.849658  2066 solver.cpp:245]     Train net output #0: loss = 0.0114044 (* 1 = 0.0114044 loss)
I0503 10:53:31.849675  2066 sgd_solver.cpp:106] Iteration 10280, lr = 0.01
I0503 10:54:14.880959  2066 solver.cpp:229] Iteration 10300, loss = 0.0270884
I0503 10:54:14.882014  2066 solver.cpp:245]     Train net output #0: loss = 0.0270884 (* 1 = 0.0270884 loss)
I0503 10:54:14.882030  2066 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0503 10:54:57.912425  2066 solver.cpp:229] Iteration 10320, loss = 0.0170158
I0503 10:54:57.913465  2066 solver.cpp:245]     Train net output #0: loss = 0.0170158 (* 1 = 0.0170158 loss)
I0503 10:54:57.913481  2066 sgd_solver.cpp:106] Iteration 10320, lr = 0.01
I0503 10:55:40.946493  2066 solver.cpp:229] Iteration 10340, loss = 0.00439053
I0503 10:55:40.947556  2066 solver.cpp:245]     Train net output #0: loss = 0.00439053 (* 1 = 0.00439053 loss)
I0503 10:55:40.947573  2066 sgd_solver.cpp:106] Iteration 10340, lr = 0.01
I0503 10:56:23.977730  2066 solver.cpp:229] Iteration 10360, loss = 0.00368487
I0503 10:56:23.978772  2066 solver.cpp:245]     Train net output #0: loss = 0.00368486 (* 1 = 0.00368486 loss)
I0503 10:56:23.978790  2066 sgd_solver.cpp:106] Iteration 10360, lr = 0.01
I0503 10:57:07.009951  2066 solver.cpp:229] Iteration 10380, loss = 0.00973838
I0503 10:57:07.010974  2066 solver.cpp:245]     Train net output #0: loss = 0.00973837 (* 1 = 0.00973837 loss)
I0503 10:57:07.010990  2066 sgd_solver.cpp:106] Iteration 10380, lr = 0.01
I0503 10:57:50.043707  2066 solver.cpp:229] Iteration 10400, loss = 0.0126362
I0503 10:57:50.044901  2066 solver.cpp:245]     Train net output #0: loss = 0.0126362 (* 1 = 0.0126362 loss)
I0503 10:57:50.044917  2066 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0503 10:58:33.077018  2066 solver.cpp:229] Iteration 10420, loss = 0.0106855
I0503 10:58:33.078148  2066 solver.cpp:245]     Train net output #0: loss = 0.0106855 (* 1 = 0.0106855 loss)
I0503 10:58:33.078166  2066 sgd_solver.cpp:106] Iteration 10420, lr = 0.01
I0503 10:59:16.109266  2066 solver.cpp:229] Iteration 10440, loss = 0.00176334
I0503 10:59:16.110363  2066 solver.cpp:245]     Train net output #0: loss = 0.00176333 (* 1 = 0.00176333 loss)
I0503 10:59:16.110383  2066 sgd_solver.cpp:106] Iteration 10440, lr = 0.01
I0503 10:59:59.143096  2066 solver.cpp:229] Iteration 10460, loss = 0.00283373
I0503 10:59:59.144304  2066 solver.cpp:245]     Train net output #0: loss = 0.00283373 (* 1 = 0.00283373 loss)
I0503 10:59:59.144320  2066 sgd_solver.cpp:106] Iteration 10460, lr = 0.01
I0503 11:00:42.180810  2066 solver.cpp:229] Iteration 10480, loss = 0.0173459
I0503 11:00:42.181910  2066 solver.cpp:245]     Train net output #0: loss = 0.0173459 (* 1 = 0.0173459 loss)
I0503 11:00:42.181926  2066 sgd_solver.cpp:106] Iteration 10480, lr = 0.01
I0503 11:01:25.217794  2066 solver.cpp:229] Iteration 10500, loss = 0.0124515
I0503 11:01:25.218905  2066 solver.cpp:245]     Train net output #0: loss = 0.0124515 (* 1 = 0.0124515 loss)
I0503 11:01:25.218925  2066 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0503 11:02:08.255514  2066 solver.cpp:229] Iteration 10520, loss = 0.00679795
I0503 11:02:08.256662  2066 solver.cpp:245]     Train net output #0: loss = 0.00679795 (* 1 = 0.00679795 loss)
I0503 11:02:08.256680  2066 sgd_solver.cpp:106] Iteration 10520, lr = 0.01
I0503 11:02:51.289968  2066 solver.cpp:229] Iteration 10540, loss = 0.00252191
I0503 11:02:51.291124  2066 solver.cpp:245]     Train net output #0: loss = 0.0025219 (* 1 = 0.0025219 loss)
I0503 11:02:51.291143  2066 sgd_solver.cpp:106] Iteration 10540, lr = 0.01
I0503 11:03:34.327183  2066 solver.cpp:229] Iteration 10560, loss = 0.00810787
I0503 11:03:34.328282  2066 solver.cpp:245]     Train net output #0: loss = 0.00810786 (* 1 = 0.00810786 loss)
I0503 11:03:34.328299  2066 sgd_solver.cpp:106] Iteration 10560, lr = 0.01
I0503 11:04:17.363483  2066 solver.cpp:229] Iteration 10580, loss = 0.00115452
I0503 11:04:17.364636  2066 solver.cpp:245]     Train net output #0: loss = 0.00115451 (* 1 = 0.00115451 loss)
I0503 11:04:17.364653  2066 sgd_solver.cpp:106] Iteration 10580, lr = 0.01
I0503 11:05:00.399502  2066 solver.cpp:229] Iteration 10600, loss = 0.0128794
I0503 11:05:00.400760  2066 solver.cpp:245]     Train net output #0: loss = 0.0128794 (* 1 = 0.0128794 loss)
I0503 11:05:00.400779  2066 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0503 11:05:43.435981  2066 solver.cpp:229] Iteration 10620, loss = 0.00401116
I0503 11:05:43.437072  2066 solver.cpp:245]     Train net output #0: loss = 0.00401115 (* 1 = 0.00401115 loss)
I0503 11:05:43.437088  2066 sgd_solver.cpp:106] Iteration 10620, lr = 0.01
I0503 11:06:26.470095  2066 solver.cpp:229] Iteration 10640, loss = 0.0227346
I0503 11:06:26.471186  2066 solver.cpp:245]     Train net output #0: loss = 0.0227345 (* 1 = 0.0227345 loss)
I0503 11:06:26.471202  2066 sgd_solver.cpp:106] Iteration 10640, lr = 0.01
I0503 11:07:09.507380  2066 solver.cpp:229] Iteration 10660, loss = 0.00418049
I0503 11:07:09.508561  2066 solver.cpp:245]     Train net output #0: loss = 0.00418048 (* 1 = 0.00418048 loss)
I0503 11:07:09.508580  2066 sgd_solver.cpp:106] Iteration 10660, lr = 0.01
I0503 11:07:52.543746  2066 solver.cpp:229] Iteration 10680, loss = 0.00539001
I0503 11:07:52.544869  2066 solver.cpp:245]     Train net output #0: loss = 0.00538999 (* 1 = 0.00538999 loss)
I0503 11:07:52.544886  2066 sgd_solver.cpp:106] Iteration 10680, lr = 0.01
I0503 11:08:35.579583  2066 solver.cpp:229] Iteration 10700, loss = 0.0190552
I0503 11:08:35.586673  2066 solver.cpp:245]     Train net output #0: loss = 0.0190552 (* 1 = 0.0190552 loss)
I0503 11:08:35.586690  2066 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0503 11:09:18.617517  2066 solver.cpp:229] Iteration 10720, loss = 0.00687897
I0503 11:09:18.618597  2066 solver.cpp:245]     Train net output #0: loss = 0.00687895 (* 1 = 0.00687895 loss)
I0503 11:09:18.618614  2066 sgd_solver.cpp:106] Iteration 10720, lr = 0.01
I0503 11:10:01.652526  2066 solver.cpp:229] Iteration 10740, loss = 0.00275177
I0503 11:10:01.653738  2066 solver.cpp:245]     Train net output #0: loss = 0.00275175 (* 1 = 0.00275175 loss)
I0503 11:10:01.653755  2066 sgd_solver.cpp:106] Iteration 10740, lr = 0.01
I0503 11:10:44.689115  2066 solver.cpp:229] Iteration 10760, loss = 0.0186988
I0503 11:10:44.690183  2066 solver.cpp:245]     Train net output #0: loss = 0.0186987 (* 1 = 0.0186987 loss)
I0503 11:10:44.690199  2066 sgd_solver.cpp:106] Iteration 10760, lr = 0.01
I0503 11:11:27.725805  2066 solver.cpp:229] Iteration 10780, loss = 0.00715368
I0503 11:11:27.727095  2066 solver.cpp:245]     Train net output #0: loss = 0.00715367 (* 1 = 0.00715367 loss)
I0503 11:11:27.727115  2066 sgd_solver.cpp:106] Iteration 10780, lr = 0.01
I0503 11:12:10.761402  2066 solver.cpp:229] Iteration 10800, loss = 0.00892192
I0503 11:12:10.762531  2066 solver.cpp:245]     Train net output #0: loss = 0.00892191 (* 1 = 0.00892191 loss)
I0503 11:12:10.762547  2066 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0503 11:12:53.798929  2066 solver.cpp:229] Iteration 10820, loss = 0.00181778
I0503 11:12:53.800019  2066 solver.cpp:245]     Train net output #0: loss = 0.00181777 (* 1 = 0.00181777 loss)
I0503 11:12:53.800035  2066 sgd_solver.cpp:106] Iteration 10820, lr = 0.01
I0503 11:13:36.835062  2066 solver.cpp:229] Iteration 10840, loss = 0.00118857
I0503 11:13:36.836107  2066 solver.cpp:245]     Train net output #0: loss = 0.00118856 (* 1 = 0.00118856 loss)
I0503 11:13:36.836123  2066 sgd_solver.cpp:106] Iteration 10840, lr = 0.01
I0503 11:14:19.870884  2066 solver.cpp:229] Iteration 10860, loss = 0.00213912
I0503 11:14:19.871965  2066 solver.cpp:245]     Train net output #0: loss = 0.0021391 (* 1 = 0.0021391 loss)
I0503 11:14:19.871986  2066 sgd_solver.cpp:106] Iteration 10860, lr = 0.01
I0503 11:15:02.909613  2066 solver.cpp:229] Iteration 10880, loss = 0.00933793
I0503 11:15:02.910786  2066 solver.cpp:245]     Train net output #0: loss = 0.00933792 (* 1 = 0.00933792 loss)
I0503 11:15:02.910804  2066 sgd_solver.cpp:106] Iteration 10880, lr = 0.01
I0503 11:15:45.946146  2066 solver.cpp:229] Iteration 10900, loss = 0.0101345
I0503 11:15:45.947170  2066 solver.cpp:245]     Train net output #0: loss = 0.0101345 (* 1 = 0.0101345 loss)
I0503 11:15:45.947190  2066 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0503 11:16:28.981611  2066 solver.cpp:229] Iteration 10920, loss = 0.0149763
I0503 11:16:28.982643  2066 solver.cpp:245]     Train net output #0: loss = 0.0149763 (* 1 = 0.0149763 loss)
I0503 11:16:28.982661  2066 sgd_solver.cpp:106] Iteration 10920, lr = 0.01
I0503 11:17:12.015696  2066 solver.cpp:229] Iteration 10940, loss = 0.00440078
I0503 11:17:12.016748  2066 solver.cpp:245]     Train net output #0: loss = 0.00440077 (* 1 = 0.00440077 loss)
I0503 11:17:12.016765  2066 sgd_solver.cpp:106] Iteration 10940, lr = 0.01
I0503 11:17:55.050945  2066 solver.cpp:229] Iteration 10960, loss = 0.000328431
I0503 11:17:55.052065  2066 solver.cpp:245]     Train net output #0: loss = 0.000328423 (* 1 = 0.000328423 loss)
I0503 11:17:55.052083  2066 sgd_solver.cpp:106] Iteration 10960, lr = 0.01
I0503 11:18:38.087716  2066 solver.cpp:229] Iteration 10980, loss = 0.00408996
I0503 11:18:38.088866  2066 solver.cpp:245]     Train net output #0: loss = 0.00408995 (* 1 = 0.00408995 loss)
I0503 11:18:38.088886  2066 sgd_solver.cpp:106] Iteration 10980, lr = 0.01
I0503 11:19:18.981103  2066 solver.cpp:338] Iteration 11000, Testing net (#0)
I0503 11:22:09.016322  2066 solver.cpp:406]     Test net output #0: accuracy = 0.995359
I0503 11:22:09.017529  2066 solver.cpp:406]     Test net output #1: loss = 0.0161685 (* 1 = 0.0161685 loss)
I0503 11:22:10.984282  2066 solver.cpp:229] Iteration 11000, loss = 0.00244115
I0503 11:22:10.984356  2066 solver.cpp:245]     Train net output #0: loss = 0.00244114 (* 1 = 0.00244114 loss)
I0503 11:22:10.984371  2066 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0503 11:22:54.008853  2066 solver.cpp:229] Iteration 11020, loss = 0.0217555
I0503 11:22:54.009977  2066 solver.cpp:245]     Train net output #0: loss = 0.0217555 (* 1 = 0.0217555 loss)
I0503 11:22:54.009996  2066 sgd_solver.cpp:106] Iteration 11020, lr = 0.01
I0503 11:23:37.033947  2066 solver.cpp:229] Iteration 11040, loss = 0.026044
I0503 11:23:37.035090  2066 solver.cpp:245]     Train net output #0: loss = 0.026044 (* 1 = 0.026044 loss)
I0503 11:23:37.035109  2066 sgd_solver.cpp:106] Iteration 11040, lr = 0.01
I0503 11:24:20.059787  2066 solver.cpp:229] Iteration 11060, loss = 0.00232349
I0503 11:24:20.060951  2066 solver.cpp:245]     Train net output #0: loss = 0.00232349 (* 1 = 0.00232349 loss)
I0503 11:24:20.060968  2066 sgd_solver.cpp:106] Iteration 11060, lr = 0.01
I0503 11:25:03.084790  2066 solver.cpp:229] Iteration 11080, loss = 0.0139801
I0503 11:25:03.086072  2066 solver.cpp:245]     Train net output #0: loss = 0.0139801 (* 1 = 0.0139801 loss)
I0503 11:25:03.086089  2066 sgd_solver.cpp:106] Iteration 11080, lr = 0.01
I0503 11:25:46.110648  2066 solver.cpp:229] Iteration 11100, loss = 0.00314697
I0503 11:25:46.111773  2066 solver.cpp:245]     Train net output #0: loss = 0.00314697 (* 1 = 0.00314697 loss)
I0503 11:25:46.111790  2066 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0503 11:26:29.136437  2066 solver.cpp:229] Iteration 11120, loss = 0.0106907
I0503 11:26:29.137585  2066 solver.cpp:245]     Train net output #0: loss = 0.0106907 (* 1 = 0.0106907 loss)
I0503 11:26:29.137603  2066 sgd_solver.cpp:106] Iteration 11120, lr = 0.01
I0503 11:27:12.160495  2066 solver.cpp:229] Iteration 11140, loss = 0.00503088
I0503 11:27:12.161586  2066 solver.cpp:245]     Train net output #0: loss = 0.00503088 (* 1 = 0.00503088 loss)
I0503 11:27:12.161602  2066 sgd_solver.cpp:106] Iteration 11140, lr = 0.01
I0503 11:27:55.187155  2066 solver.cpp:229] Iteration 11160, loss = 0.00413005
I0503 11:27:55.188271  2066 solver.cpp:245]     Train net output #0: loss = 0.00413004 (* 1 = 0.00413004 loss)
I0503 11:27:55.188289  2066 sgd_solver.cpp:106] Iteration 11160, lr = 0.01
I0503 11:28:38.213585  2066 solver.cpp:229] Iteration 11180, loss = 0.00522404
I0503 11:28:38.214679  2066 solver.cpp:245]     Train net output #0: loss = 0.00522403 (* 1 = 0.00522403 loss)
I0503 11:28:38.214695  2066 sgd_solver.cpp:106] Iteration 11180, lr = 0.01
I0503 11:29:21.239483  2066 solver.cpp:229] Iteration 11200, loss = 0.00873783
I0503 11:29:21.240559  2066 solver.cpp:245]     Train net output #0: loss = 0.00873782 (* 1 = 0.00873782 loss)
I0503 11:29:21.240576  2066 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0503 11:30:04.264385  2066 solver.cpp:229] Iteration 11220, loss = 0.00739932
I0503 11:30:04.265586  2066 solver.cpp:245]     Train net output #0: loss = 0.00739932 (* 1 = 0.00739932 loss)
I0503 11:30:04.265604  2066 sgd_solver.cpp:106] Iteration 11220, lr = 0.01
I0503 11:30:47.288895  2066 solver.cpp:229] Iteration 11240, loss = 0.000920594
I0503 11:30:47.290135  2066 solver.cpp:245]     Train net output #0: loss = 0.000920588 (* 1 = 0.000920588 loss)
I0503 11:30:47.290155  2066 sgd_solver.cpp:106] Iteration 11240, lr = 0.01
I0503 11:31:30.317950  2066 solver.cpp:229] Iteration 11260, loss = 0.0160815
I0503 11:31:30.319077  2066 solver.cpp:245]     Train net output #0: loss = 0.0160815 (* 1 = 0.0160815 loss)
I0503 11:31:30.319093  2066 sgd_solver.cpp:106] Iteration 11260, lr = 0.01
I0503 11:32:13.345517  2066 solver.cpp:229] Iteration 11280, loss = 0.00741616
I0503 11:32:13.346729  2066 solver.cpp:245]     Train net output #0: loss = 0.00741615 (* 1 = 0.00741615 loss)
I0503 11:32:13.346747  2066 sgd_solver.cpp:106] Iteration 11280, lr = 0.01
I0503 11:32:56.371948  2066 solver.cpp:229] Iteration 11300, loss = 0.015935
I0503 11:32:56.373085  2066 solver.cpp:245]     Train net output #0: loss = 0.015935 (* 1 = 0.015935 loss)
I0503 11:32:56.373105  2066 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0503 11:33:39.398008  2066 solver.cpp:229] Iteration 11320, loss = 0.00145155
I0503 11:33:39.399111  2066 solver.cpp:245]     Train net output #0: loss = 0.00145155 (* 1 = 0.00145155 loss)
I0503 11:33:39.399127  2066 sgd_solver.cpp:106] Iteration 11320, lr = 0.01
I0503 11:34:22.423475  2066 solver.cpp:229] Iteration 11340, loss = 0.00523377
I0503 11:34:22.424732  2066 solver.cpp:245]     Train net output #0: loss = 0.00523377 (* 1 = 0.00523377 loss)
I0503 11:34:22.424748  2066 sgd_solver.cpp:106] Iteration 11340, lr = 0.01
I0503 11:35:05.449425  2066 solver.cpp:229] Iteration 11360, loss = 0.00228749
I0503 11:35:05.450588  2066 solver.cpp:245]     Train net output #0: loss = 0.00228748 (* 1 = 0.00228748 loss)
I0503 11:35:05.450606  2066 sgd_solver.cpp:106] Iteration 11360, lr = 0.01
I0503 11:35:48.476800  2066 solver.cpp:229] Iteration 11380, loss = 0.0073608
I0503 11:35:48.477972  2066 solver.cpp:245]     Train net output #0: loss = 0.0073608 (* 1 = 0.0073608 loss)
I0503 11:35:48.477993  2066 sgd_solver.cpp:106] Iteration 11380, lr = 0.01
I0503 11:36:31.511554  2066 solver.cpp:229] Iteration 11400, loss = 0.0124031
I0503 11:36:31.512750  2066 solver.cpp:245]     Train net output #0: loss = 0.0124031 (* 1 = 0.0124031 loss)
I0503 11:36:31.512769  2066 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0503 11:37:14.539348  2066 solver.cpp:229] Iteration 11420, loss = 0.0082813
I0503 11:37:14.540433  2066 solver.cpp:245]     Train net output #0: loss = 0.00828129 (* 1 = 0.00828129 loss)
I0503 11:37:14.540449  2066 sgd_solver.cpp:106] Iteration 11420, lr = 0.01
I0503 11:37:57.561030  2066 solver.cpp:229] Iteration 11440, loss = 0.00927869
I0503 11:37:57.562165  2066 solver.cpp:245]     Train net output #0: loss = 0.00927868 (* 1 = 0.00927868 loss)
I0503 11:37:57.562185  2066 sgd_solver.cpp:106] Iteration 11440, lr = 0.01
I0503 11:38:40.585129  2066 solver.cpp:229] Iteration 11460, loss = 0.00595712
I0503 11:38:40.586195  2066 solver.cpp:245]     Train net output #0: loss = 0.00595711 (* 1 = 0.00595711 loss)
I0503 11:38:40.586211  2066 sgd_solver.cpp:106] Iteration 11460, lr = 0.01
I0503 11:39:23.606768  2066 solver.cpp:229] Iteration 11480, loss = 0.00063252
I0503 11:39:23.607862  2066 solver.cpp:245]     Train net output #0: loss = 0.000632509 (* 1 = 0.000632509 loss)
I0503 11:39:23.607879  2066 sgd_solver.cpp:106] Iteration 11480, lr = 0.01
I0503 11:40:06.627300  2066 solver.cpp:229] Iteration 11500, loss = 0.0218387
I0503 11:40:06.628388  2066 solver.cpp:245]     Train net output #0: loss = 0.0218387 (* 1 = 0.0218387 loss)
I0503 11:40:06.628406  2066 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0503 11:40:49.649991  2066 solver.cpp:229] Iteration 11520, loss = 0.0109552
I0503 11:40:49.651113  2066 solver.cpp:245]     Train net output #0: loss = 0.0109552 (* 1 = 0.0109552 loss)
I0503 11:40:49.651129  2066 sgd_solver.cpp:106] Iteration 11520, lr = 0.01
I0503 11:41:32.674334  2066 solver.cpp:229] Iteration 11540, loss = 0.0032362
I0503 11:41:32.675393  2066 solver.cpp:245]     Train net output #0: loss = 0.00323619 (* 1 = 0.00323619 loss)
I0503 11:41:32.675410  2066 sgd_solver.cpp:106] Iteration 11540, lr = 0.01
I0503 11:42:15.695677  2066 solver.cpp:229] Iteration 11560, loss = 0.0177569
I0503 11:42:15.696841  2066 solver.cpp:245]     Train net output #0: loss = 0.0177569 (* 1 = 0.0177569 loss)
I0503 11:42:15.696856  2066 sgd_solver.cpp:106] Iteration 11560, lr = 0.01
I0503 11:42:58.718580  2066 solver.cpp:229] Iteration 11580, loss = 0.000748067
I0503 11:42:58.719599  2066 solver.cpp:245]     Train net output #0: loss = 0.000748056 (* 1 = 0.000748056 loss)
I0503 11:42:58.719614  2066 sgd_solver.cpp:106] Iteration 11580, lr = 0.01
I0503 11:43:41.739827  2066 solver.cpp:229] Iteration 11600, loss = 0.0168559
I0503 11:43:41.740936  2066 solver.cpp:245]     Train net output #0: loss = 0.0168559 (* 1 = 0.0168559 loss)
I0503 11:43:41.740952  2066 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0503 11:44:24.759269  2066 solver.cpp:229] Iteration 11620, loss = 0.00144633
I0503 11:44:24.760238  2066 solver.cpp:245]     Train net output #0: loss = 0.00144632 (* 1 = 0.00144632 loss)
I0503 11:44:24.760256  2066 sgd_solver.cpp:106] Iteration 11620, lr = 0.01
I0503 11:45:07.778782  2066 solver.cpp:229] Iteration 11640, loss = 0.00118865
I0503 11:45:07.779884  2066 solver.cpp:245]     Train net output #0: loss = 0.00118864 (* 1 = 0.00118864 loss)
I0503 11:45:07.779901  2066 sgd_solver.cpp:106] Iteration 11640, lr = 0.01
I0503 11:45:50.797082  2066 solver.cpp:229] Iteration 11660, loss = 0.0068001
I0503 11:45:50.798166  2066 solver.cpp:245]     Train net output #0: loss = 0.00680009 (* 1 = 0.00680009 loss)
I0503 11:45:50.798182  2066 sgd_solver.cpp:106] Iteration 11660, lr = 0.01
I0503 11:46:33.819732  2066 solver.cpp:229] Iteration 11680, loss = 0.00312872
I0503 11:46:33.820853  2066 solver.cpp:245]     Train net output #0: loss = 0.00312871 (* 1 = 0.00312871 loss)
I0503 11:46:33.820870  2066 sgd_solver.cpp:106] Iteration 11680, lr = 0.01
I0503 11:47:16.839851  2066 solver.cpp:229] Iteration 11700, loss = 0.00548108
I0503 11:47:16.841071  2066 solver.cpp:245]     Train net output #0: loss = 0.00548108 (* 1 = 0.00548108 loss)
I0503 11:47:16.841089  2066 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0503 11:47:59.862399  2066 solver.cpp:229] Iteration 11720, loss = 0.0218925
I0503 11:47:59.863664  2066 solver.cpp:245]     Train net output #0: loss = 0.0218925 (* 1 = 0.0218925 loss)
I0503 11:47:59.863683  2066 sgd_solver.cpp:106] Iteration 11720, lr = 0.01
I0503 11:48:42.884016  2066 solver.cpp:229] Iteration 11740, loss = 0.00689881
I0503 11:48:42.885143  2066 solver.cpp:245]     Train net output #0: loss = 0.0068988 (* 1 = 0.0068988 loss)
I0503 11:48:42.885159  2066 sgd_solver.cpp:106] Iteration 11740, lr = 0.01
I0503 11:49:25.906083  2066 solver.cpp:229] Iteration 11760, loss = 0.0195581
I0503 11:49:25.907217  2066 solver.cpp:245]     Train net output #0: loss = 0.0195581 (* 1 = 0.0195581 loss)
I0503 11:49:25.907235  2066 sgd_solver.cpp:106] Iteration 11760, lr = 0.01
I0503 11:50:08.926790  2066 solver.cpp:229] Iteration 11780, loss = 0.0262309
I0503 11:50:08.927924  2066 solver.cpp:245]     Train net output #0: loss = 0.0262309 (* 1 = 0.0262309 loss)
I0503 11:50:08.927944  2066 sgd_solver.cpp:106] Iteration 11780, lr = 0.01
I0503 11:50:51.945746  2066 solver.cpp:229] Iteration 11800, loss = 0.0168803
I0503 11:50:51.946882  2066 solver.cpp:245]     Train net output #0: loss = 0.0168803 (* 1 = 0.0168803 loss)
I0503 11:50:51.946899  2066 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0503 11:51:34.966377  2066 solver.cpp:229] Iteration 11820, loss = 0.0241514
I0503 11:51:34.967608  2066 solver.cpp:245]     Train net output #0: loss = 0.0241514 (* 1 = 0.0241514 loss)
I0503 11:51:34.967628  2066 sgd_solver.cpp:106] Iteration 11820, lr = 0.01
I0503 11:52:17.986398  2066 solver.cpp:229] Iteration 11840, loss = 0.00756702
I0503 11:52:17.987478  2066 solver.cpp:245]     Train net output #0: loss = 0.00756702 (* 1 = 0.00756702 loss)
I0503 11:52:17.987496  2066 sgd_solver.cpp:106] Iteration 11840, lr = 0.01
I0503 11:53:01.000938  2066 solver.cpp:229] Iteration 11860, loss = 0.0039936
I0503 11:53:01.002195  2066 solver.cpp:245]     Train net output #0: loss = 0.0039936 (* 1 = 0.0039936 loss)
I0503 11:53:01.002213  2066 sgd_solver.cpp:106] Iteration 11860, lr = 0.01
I0503 11:53:44.019212  2066 solver.cpp:229] Iteration 11880, loss = 0.00155523
I0503 11:53:44.025754  2066 solver.cpp:245]     Train net output #0: loss = 0.00155522 (* 1 = 0.00155522 loss)
I0503 11:53:44.025775  2066 sgd_solver.cpp:106] Iteration 11880, lr = 0.01
I0503 11:54:27.036206  2066 solver.cpp:229] Iteration 11900, loss = 0.0014878
I0503 11:54:27.037312  2066 solver.cpp:245]     Train net output #0: loss = 0.0014878 (* 1 = 0.0014878 loss)
I0503 11:54:27.037329  2066 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0503 11:55:10.054507  2066 solver.cpp:229] Iteration 11920, loss = 0.00629868
I0503 11:55:10.055563  2066 solver.cpp:245]     Train net output #0: loss = 0.00629867 (* 1 = 0.00629867 loss)
I0503 11:55:10.055585  2066 sgd_solver.cpp:106] Iteration 11920, lr = 0.01
I0503 11:55:53.070750  2066 solver.cpp:229] Iteration 11940, loss = 0.00468515
I0503 11:55:53.071827  2066 solver.cpp:245]     Train net output #0: loss = 0.00468514 (* 1 = 0.00468514 loss)
I0503 11:55:53.071843  2066 sgd_solver.cpp:106] Iteration 11940, lr = 0.01
I0503 11:56:36.090951  2066 solver.cpp:229] Iteration 11960, loss = 0.0443664
I0503 11:56:36.092020  2066 solver.cpp:245]     Train net output #0: loss = 0.0443664 (* 1 = 0.0443664 loss)
I0503 11:56:36.092037  2066 sgd_solver.cpp:106] Iteration 11960, lr = 0.01
I0503 11:57:19.111459  2066 solver.cpp:229] Iteration 11980, loss = 0.00388227
I0503 11:57:19.112560  2066 solver.cpp:245]     Train net output #0: loss = 0.00388226 (* 1 = 0.00388226 loss)
I0503 11:57:19.112577  2066 sgd_solver.cpp:106] Iteration 11980, lr = 0.01
I0503 11:57:59.987960  2066 solver.cpp:338] Iteration 12000, Testing net (#0)
I0503 12:00:49.901340  2066 solver.cpp:406]     Test net output #0: accuracy = 0.996879
I0503 12:00:49.904083  2066 solver.cpp:406]     Test net output #1: loss = 0.00984132 (* 1 = 0.00984132 loss)
I0503 12:00:51.869954  2066 solver.cpp:229] Iteration 12000, loss = 0.00134215
I0503 12:00:51.870018  2066 solver.cpp:245]     Train net output #0: loss = 0.00134214 (* 1 = 0.00134214 loss)
I0503 12:00:51.870033  2066 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0503 12:01:34.889158  2066 solver.cpp:229] Iteration 12020, loss = 0.00311158
I0503 12:01:34.890281  2066 solver.cpp:245]     Train net output #0: loss = 0.00311157 (* 1 = 0.00311157 loss)
I0503 12:01:34.890300  2066 sgd_solver.cpp:106] Iteration 12020, lr = 0.01
I0503 12:02:17.910223  2066 solver.cpp:229] Iteration 12040, loss = 0.000835493
I0503 12:02:17.911283  2066 solver.cpp:245]     Train net output #0: loss = 0.000835485 (* 1 = 0.000835485 loss)
I0503 12:02:17.911301  2066 sgd_solver.cpp:106] Iteration 12040, lr = 0.01
I0503 12:03:00.929610  2066 solver.cpp:229] Iteration 12060, loss = 0.0271117
I0503 12:03:00.930819  2066 solver.cpp:245]     Train net output #0: loss = 0.0271117 (* 1 = 0.0271117 loss)
I0503 12:03:00.930836  2066 sgd_solver.cpp:106] Iteration 12060, lr = 0.01
I0503 12:03:43.950515  2066 solver.cpp:229] Iteration 12080, loss = 0.00114258
I0503 12:03:43.951630  2066 solver.cpp:245]     Train net output #0: loss = 0.00114258 (* 1 = 0.00114258 loss)
I0503 12:03:43.951647  2066 sgd_solver.cpp:106] Iteration 12080, lr = 0.01
I0503 12:04:26.972399  2066 solver.cpp:229] Iteration 12100, loss = 0.0122528
I0503 12:04:26.974632  2066 solver.cpp:245]     Train net output #0: loss = 0.0122528 (* 1 = 0.0122528 loss)
I0503 12:04:26.974648  2066 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0503 12:05:09.993336  2066 solver.cpp:229] Iteration 12120, loss = 0.0014896
I0503 12:05:09.994490  2066 solver.cpp:245]     Train net output #0: loss = 0.0014896 (* 1 = 0.0014896 loss)
I0503 12:05:09.994508  2066 sgd_solver.cpp:106] Iteration 12120, lr = 0.01
I0503 12:05:53.014261  2066 solver.cpp:229] Iteration 12140, loss = 0.000889455
I0503 12:05:53.015339  2066 solver.cpp:245]     Train net output #0: loss = 0.000889455 (* 1 = 0.000889455 loss)
I0503 12:05:53.015357  2066 sgd_solver.cpp:106] Iteration 12140, lr = 0.01
I0503 12:06:36.038547  2066 solver.cpp:229] Iteration 12160, loss = 0.00219462
I0503 12:06:36.039683  2066 solver.cpp:245]     Train net output #0: loss = 0.00219462 (* 1 = 0.00219462 loss)
I0503 12:06:36.039702  2066 sgd_solver.cpp:106] Iteration 12160, lr = 0.01
I0503 12:07:19.064079  2066 solver.cpp:229] Iteration 12180, loss = 0.00274733
I0503 12:07:19.065156  2066 solver.cpp:245]     Train net output #0: loss = 0.00274733 (* 1 = 0.00274733 loss)
I0503 12:07:19.065173  2066 sgd_solver.cpp:106] Iteration 12180, lr = 0.01
I0503 12:08:02.089202  2066 solver.cpp:229] Iteration 12200, loss = 0.00149752
I0503 12:08:02.090338  2066 solver.cpp:245]     Train net output #0: loss = 0.00149752 (* 1 = 0.00149752 loss)
I0503 12:08:02.090355  2066 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0503 12:08:45.111739  2066 solver.cpp:229] Iteration 12220, loss = 0.00229821
I0503 12:08:45.112850  2066 solver.cpp:245]     Train net output #0: loss = 0.00229821 (* 1 = 0.00229821 loss)
I0503 12:08:45.112869  2066 sgd_solver.cpp:106] Iteration 12220, lr = 0.01
I0503 12:09:28.137308  2066 solver.cpp:229] Iteration 12240, loss = 0.00369423
I0503 12:09:28.138386  2066 solver.cpp:245]     Train net output #0: loss = 0.00369423 (* 1 = 0.00369423 loss)
I0503 12:09:28.138404  2066 sgd_solver.cpp:106] Iteration 12240, lr = 0.01
I0503 12:10:11.163837  2066 solver.cpp:229] Iteration 12260, loss = 0.00763542
I0503 12:10:11.165026  2066 solver.cpp:245]     Train net output #0: loss = 0.00763541 (* 1 = 0.00763541 loss)
I0503 12:10:11.165043  2066 sgd_solver.cpp:106] Iteration 12260, lr = 0.01
I0503 12:10:54.188149  2066 solver.cpp:229] Iteration 12280, loss = 0.00396562
I0503 12:10:54.189261  2066 solver.cpp:245]     Train net output #0: loss = 0.00396562 (* 1 = 0.00396562 loss)
I0503 12:10:54.189277  2066 sgd_solver.cpp:106] Iteration 12280, lr = 0.01
I0503 12:11:37.213778  2066 solver.cpp:229] Iteration 12300, loss = 0.00074223
I0503 12:11:37.215001  2066 solver.cpp:245]     Train net output #0: loss = 0.000742224 (* 1 = 0.000742224 loss)
I0503 12:11:37.215020  2066 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0503 12:12:20.239397  2066 solver.cpp:229] Iteration 12320, loss = 0.000438372
I0503 12:12:20.240496  2066 solver.cpp:245]     Train net output #0: loss = 0.000438366 (* 1 = 0.000438366 loss)
I0503 12:12:20.240514  2066 sgd_solver.cpp:106] Iteration 12320, lr = 0.01
I0503 12:13:03.265507  2066 solver.cpp:229] Iteration 12340, loss = 0.00691872
I0503 12:13:03.266609  2066 solver.cpp:245]     Train net output #0: loss = 0.00691871 (* 1 = 0.00691871 loss)
I0503 12:13:03.266628  2066 sgd_solver.cpp:106] Iteration 12340, lr = 0.01
I0503 12:13:46.292229  2066 solver.cpp:229] Iteration 12360, loss = 0.0105386
I0503 12:13:46.293246  2066 solver.cpp:245]     Train net output #0: loss = 0.0105386 (* 1 = 0.0105386 loss)
I0503 12:13:46.293262  2066 sgd_solver.cpp:106] Iteration 12360, lr = 0.01
I0503 12:14:29.317598  2066 solver.cpp:229] Iteration 12380, loss = 0.000355815
I0503 12:14:29.318733  2066 solver.cpp:245]     Train net output #0: loss = 0.000355811 (* 1 = 0.000355811 loss)
I0503 12:14:29.318750  2066 sgd_solver.cpp:106] Iteration 12380, lr = 0.01
I0503 12:15:12.342448  2066 solver.cpp:229] Iteration 12400, loss = 0.00580403
I0503 12:15:12.343556  2066 solver.cpp:245]     Train net output #0: loss = 0.00580402 (* 1 = 0.00580402 loss)
I0503 12:15:12.343576  2066 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0503 12:15:55.366575  2066 solver.cpp:229] Iteration 12420, loss = 0.00691021
I0503 12:15:55.367691  2066 solver.cpp:245]     Train net output #0: loss = 0.00691021 (* 1 = 0.00691021 loss)
I0503 12:15:55.367707  2066 sgd_solver.cpp:106] Iteration 12420, lr = 0.01
I0503 12:16:38.392509  2066 solver.cpp:229] Iteration 12440, loss = 0.0213844
I0503 12:16:38.393718  2066 solver.cpp:245]     Train net output #0: loss = 0.0213844 (* 1 = 0.0213844 loss)
I0503 12:16:38.393734  2066 sgd_solver.cpp:106] Iteration 12440, lr = 0.01
I0503 12:17:21.418540  2066 solver.cpp:229] Iteration 12460, loss = 0.000943216
I0503 12:17:21.419664  2066 solver.cpp:245]     Train net output #0: loss = 0.00094321 (* 1 = 0.00094321 loss)
I0503 12:17:21.419682  2066 sgd_solver.cpp:106] Iteration 12460, lr = 0.01
I0503 12:18:04.444813  2066 solver.cpp:229] Iteration 12480, loss = 0.00209745
I0503 12:18:04.445993  2066 solver.cpp:245]     Train net output #0: loss = 0.00209744 (* 1 = 0.00209744 loss)
I0503 12:18:04.446013  2066 sgd_solver.cpp:106] Iteration 12480, lr = 0.01
I0503 12:18:47.473036  2066 solver.cpp:229] Iteration 12500, loss = 0.000541598
I0503 12:18:47.474105  2066 solver.cpp:245]     Train net output #0: loss = 0.000541593 (* 1 = 0.000541593 loss)
I0503 12:18:47.474123  2066 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0503 12:19:30.498836  2066 solver.cpp:229] Iteration 12520, loss = 0.00108607
I0503 12:19:30.500047  2066 solver.cpp:245]     Train net output #0: loss = 0.00108606 (* 1 = 0.00108606 loss)
I0503 12:19:30.500064  2066 sgd_solver.cpp:106] Iteration 12520, lr = 0.01
I0503 12:20:13.524252  2066 solver.cpp:229] Iteration 12540, loss = 0.0169598
I0503 12:20:13.525388  2066 solver.cpp:245]     Train net output #0: loss = 0.0169598 (* 1 = 0.0169598 loss)
I0503 12:20:13.525404  2066 sgd_solver.cpp:106] Iteration 12540, lr = 0.01
I0503 12:20:56.545419  2066 solver.cpp:229] Iteration 12560, loss = 0.000503949
I0503 12:20:56.546545  2066 solver.cpp:245]     Train net output #0: loss = 0.000503941 (* 1 = 0.000503941 loss)
I0503 12:20:56.546562  2066 sgd_solver.cpp:106] Iteration 12560, lr = 0.01
I0503 12:21:39.568347  2066 solver.cpp:229] Iteration 12580, loss = 0.00173941
I0503 12:21:39.569658  2066 solver.cpp:245]     Train net output #0: loss = 0.0017394 (* 1 = 0.0017394 loss)
I0503 12:21:39.569676  2066 sgd_solver.cpp:106] Iteration 12580, lr = 0.01
I0503 12:22:22.592386  2066 solver.cpp:229] Iteration 12600, loss = 0.00911171
I0503 12:22:22.593485  2066 solver.cpp:245]     Train net output #0: loss = 0.0091117 (* 1 = 0.0091117 loss)
I0503 12:22:22.593505  2066 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0503 12:23:05.614611  2066 solver.cpp:229] Iteration 12620, loss = 0.0117366
I0503 12:23:05.615730  2066 solver.cpp:245]     Train net output #0: loss = 0.0117366 (* 1 = 0.0117366 loss)
I0503 12:23:05.615746  2066 sgd_solver.cpp:106] Iteration 12620, lr = 0.01
I0503 12:23:48.637702  2066 solver.cpp:229] Iteration 12640, loss = 0.00823982
I0503 12:23:48.638816  2066 solver.cpp:245]     Train net output #0: loss = 0.00823981 (* 1 = 0.00823981 loss)
I0503 12:23:48.638833  2066 sgd_solver.cpp:106] Iteration 12640, lr = 0.01
I0503 12:24:31.661804  2066 solver.cpp:229] Iteration 12660, loss = 0.00115004
I0503 12:24:31.663015  2066 solver.cpp:245]     Train net output #0: loss = 0.00115004 (* 1 = 0.00115004 loss)
I0503 12:24:31.663033  2066 sgd_solver.cpp:106] Iteration 12660, lr = 0.01
I0503 12:25:14.684665  2066 solver.cpp:229] Iteration 12680, loss = 0.00200801
I0503 12:25:14.685739  2066 solver.cpp:245]     Train net output #0: loss = 0.002008 (* 1 = 0.002008 loss)
I0503 12:25:14.685755  2066 sgd_solver.cpp:106] Iteration 12680, lr = 0.01
I0503 12:25:57.706266  2066 solver.cpp:229] Iteration 12700, loss = 0.0121628
I0503 12:25:57.707450  2066 solver.cpp:245]     Train net output #0: loss = 0.0121628 (* 1 = 0.0121628 loss)
I0503 12:25:57.707468  2066 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0503 12:26:40.730248  2066 solver.cpp:229] Iteration 12720, loss = 0.00214098
I0503 12:26:40.731318  2066 solver.cpp:245]     Train net output #0: loss = 0.00214097 (* 1 = 0.00214097 loss)
I0503 12:26:40.731335  2066 sgd_solver.cpp:106] Iteration 12720, lr = 0.01
I0503 12:27:23.757696  2066 solver.cpp:229] Iteration 12740, loss = 0.00580157
I0503 12:27:23.758745  2066 solver.cpp:245]     Train net output #0: loss = 0.00580157 (* 1 = 0.00580157 loss)
I0503 12:27:23.758761  2066 sgd_solver.cpp:106] Iteration 12740, lr = 0.01
I0503 12:28:06.782610  2066 solver.cpp:229] Iteration 12760, loss = 0.00822661
I0503 12:28:06.783630  2066 solver.cpp:245]     Train net output #0: loss = 0.0082266 (* 1 = 0.0082266 loss)
I0503 12:28:06.783646  2066 sgd_solver.cpp:106] Iteration 12760, lr = 0.01
I0503 12:28:49.808199  2066 solver.cpp:229] Iteration 12780, loss = 0.0237628
I0503 12:28:49.809243  2066 solver.cpp:245]     Train net output #0: loss = 0.0237628 (* 1 = 0.0237628 loss)
I0503 12:28:49.809259  2066 sgd_solver.cpp:106] Iteration 12780, lr = 0.01
I0503 12:29:32.835502  2066 solver.cpp:229] Iteration 12800, loss = 0.00550778
I0503 12:29:32.836655  2066 solver.cpp:245]     Train net output #0: loss = 0.00550778 (* 1 = 0.00550778 loss)
I0503 12:29:32.836671  2066 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0503 12:30:15.859319  2066 solver.cpp:229] Iteration 12820, loss = 0.0163736
I0503 12:30:15.860427  2066 solver.cpp:245]     Train net output #0: loss = 0.0163735 (* 1 = 0.0163735 loss)
I0503 12:30:15.860445  2066 sgd_solver.cpp:106] Iteration 12820, lr = 0.01
I0503 12:30:58.885218  2066 solver.cpp:229] Iteration 12840, loss = 0.00808726
I0503 12:30:58.886531  2066 solver.cpp:245]     Train net output #0: loss = 0.00808725 (* 1 = 0.00808725 loss)
I0503 12:30:58.886548  2066 sgd_solver.cpp:106] Iteration 12840, lr = 0.01
I0503 12:31:41.913437  2066 solver.cpp:229] Iteration 12860, loss = 0.0349125
I0503 12:31:41.914492  2066 solver.cpp:245]     Train net output #0: loss = 0.0349125 (* 1 = 0.0349125 loss)
I0503 12:31:41.914510  2066 sgd_solver.cpp:106] Iteration 12860, lr = 0.01
I0503 12:32:24.942730  2066 solver.cpp:229] Iteration 12880, loss = 0.00283819
I0503 12:32:24.943605  2066 solver.cpp:245]     Train net output #0: loss = 0.00283818 (* 1 = 0.00283818 loss)
I0503 12:32:24.943622  2066 sgd_solver.cpp:106] Iteration 12880, lr = 0.01
I0503 12:33:07.968461  2066 solver.cpp:229] Iteration 12900, loss = 0.00946432
I0503 12:33:07.969666  2066 solver.cpp:245]     Train net output #0: loss = 0.00946431 (* 1 = 0.00946431 loss)
I0503 12:33:07.969682  2066 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0503 12:33:50.995614  2066 solver.cpp:229] Iteration 12920, loss = 0.020524
I0503 12:33:50.996757  2066 solver.cpp:245]     Train net output #0: loss = 0.020524 (* 1 = 0.020524 loss)
I0503 12:33:50.996773  2066 sgd_solver.cpp:106] Iteration 12920, lr = 0.01
I0503 12:34:34.023574  2066 solver.cpp:229] Iteration 12940, loss = 0.00555544
I0503 12:34:34.024689  2066 solver.cpp:245]     Train net output #0: loss = 0.00555543 (* 1 = 0.00555543 loss)
I0503 12:34:34.024706  2066 sgd_solver.cpp:106] Iteration 12940, lr = 0.01
I0503 12:35:17.051146  2066 solver.cpp:229] Iteration 12960, loss = 0.00299389
I0503 12:35:17.052451  2066 solver.cpp:245]     Train net output #0: loss = 0.00299388 (* 1 = 0.00299388 loss)
I0503 12:35:17.052469  2066 sgd_solver.cpp:106] Iteration 12960, lr = 0.01
I0503 12:36:00.075748  2066 solver.cpp:229] Iteration 12980, loss = 0.00150847
I0503 12:36:00.076905  2066 solver.cpp:245]     Train net output #0: loss = 0.00150846 (* 1 = 0.00150846 loss)
I0503 12:36:00.076922  2066 sgd_solver.cpp:106] Iteration 12980, lr = 0.01
I0503 12:36:40.960057  2066 solver.cpp:338] Iteration 13000, Testing net (#0)
I0503 12:39:30.825098  2066 solver.cpp:406]     Test net output #0: accuracy = 0.996379
I0503 12:39:30.826402  2066 solver.cpp:406]     Test net output #1: loss = 0.0141197 (* 1 = 0.0141197 loss)
I0503 12:39:32.793064  2066 solver.cpp:229] Iteration 13000, loss = 0.00193009
I0503 12:39:32.793123  2066 solver.cpp:245]     Train net output #0: loss = 0.00193008 (* 1 = 0.00193008 loss)
I0503 12:39:32.793138  2066 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0503 12:40:15.818505  2066 solver.cpp:229] Iteration 13020, loss = 0.00120777
I0503 12:40:15.819622  2066 solver.cpp:245]     Train net output #0: loss = 0.00120776 (* 1 = 0.00120776 loss)
I0503 12:40:15.819638  2066 sgd_solver.cpp:106] Iteration 13020, lr = 0.01
I0503 12:40:58.846731  2066 solver.cpp:229] Iteration 13040, loss = 0.00445138
I0503 12:40:58.848016  2066 solver.cpp:245]     Train net output #0: loss = 0.00445137 (* 1 = 0.00445137 loss)
I0503 12:40:58.848040  2066 sgd_solver.cpp:106] Iteration 13040, lr = 0.01
I0503 12:41:41.874215  2066 solver.cpp:229] Iteration 13060, loss = 0.00148014
I0503 12:41:41.875268  2066 solver.cpp:245]     Train net output #0: loss = 0.00148013 (* 1 = 0.00148013 loss)
I0503 12:41:41.875285  2066 sgd_solver.cpp:106] Iteration 13060, lr = 0.01
I0503 12:42:24.902755  2066 solver.cpp:229] Iteration 13080, loss = 0.016401
I0503 12:42:24.903725  2066 solver.cpp:245]     Train net output #0: loss = 0.016401 (* 1 = 0.016401 loss)
I0503 12:42:24.903741  2066 sgd_solver.cpp:106] Iteration 13080, lr = 0.01
I0503 12:43:07.928042  2066 solver.cpp:229] Iteration 13100, loss = 0.0193287
I0503 12:43:07.929092  2066 solver.cpp:245]     Train net output #0: loss = 0.0193287 (* 1 = 0.0193287 loss)
I0503 12:43:07.929110  2066 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0503 12:43:50.951977  2066 solver.cpp:229] Iteration 13120, loss = 0.00298771
I0503 12:43:50.953116  2066 solver.cpp:245]     Train net output #0: loss = 0.00298769 (* 1 = 0.00298769 loss)
I0503 12:43:50.953133  2066 sgd_solver.cpp:106] Iteration 13120, lr = 0.01
I0503 12:44:33.981112  2066 solver.cpp:229] Iteration 13140, loss = 0.00699277
I0503 12:44:33.982245  2066 solver.cpp:245]     Train net output #0: loss = 0.00699275 (* 1 = 0.00699275 loss)
I0503 12:44:33.982262  2066 sgd_solver.cpp:106] Iteration 13140, lr = 0.01
I0503 12:45:17.006355  2066 solver.cpp:229] Iteration 13160, loss = 0.00704923
I0503 12:45:17.007447  2066 solver.cpp:245]     Train net output #0: loss = 0.00704922 (* 1 = 0.00704922 loss)
I0503 12:45:17.007464  2066 sgd_solver.cpp:106] Iteration 13160, lr = 0.01
I0503 12:46:00.028242  2066 solver.cpp:229] Iteration 13180, loss = 0.0131213
I0503 12:46:00.029299  2066 solver.cpp:245]     Train net output #0: loss = 0.0131213 (* 1 = 0.0131213 loss)
I0503 12:46:00.029319  2066 sgd_solver.cpp:106] Iteration 13180, lr = 0.01
I0503 12:46:43.054404  2066 solver.cpp:229] Iteration 13200, loss = 0.0116983
I0503 12:46:43.055559  2066 solver.cpp:245]     Train net output #0: loss = 0.0116983 (* 1 = 0.0116983 loss)
I0503 12:46:43.055580  2066 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0503 12:47:26.083164  2066 solver.cpp:229] Iteration 13220, loss = 0.00543999
I0503 12:47:26.084270  2066 solver.cpp:245]     Train net output #0: loss = 0.00543998 (* 1 = 0.00543998 loss)
I0503 12:47:26.084288  2066 sgd_solver.cpp:106] Iteration 13220, lr = 0.01
I0503 12:48:09.110420  2066 solver.cpp:229] Iteration 13240, loss = 0.00272273
I0503 12:48:09.111538  2066 solver.cpp:245]     Train net output #0: loss = 0.00272272 (* 1 = 0.00272272 loss)
I0503 12:48:09.111557  2066 sgd_solver.cpp:106] Iteration 13240, lr = 0.01
I0503 12:48:52.136189  2066 solver.cpp:229] Iteration 13260, loss = 0.00301318
I0503 12:48:52.137259  2066 solver.cpp:245]     Train net output #0: loss = 0.00301317 (* 1 = 0.00301317 loss)
I0503 12:48:52.137276  2066 sgd_solver.cpp:106] Iteration 13260, lr = 0.01
I0503 12:49:35.162760  2066 solver.cpp:229] Iteration 13280, loss = 0.00036353
I0503 12:49:35.168634  2066 solver.cpp:245]     Train net output #0: loss = 0.00036352 (* 1 = 0.00036352 loss)
I0503 12:49:35.168653  2066 sgd_solver.cpp:106] Iteration 13280, lr = 0.01
I0503 12:50:18.190840  2066 solver.cpp:229] Iteration 13300, loss = 0.00105071
I0503 12:50:18.191947  2066 solver.cpp:245]     Train net output #0: loss = 0.0010507 (* 1 = 0.0010507 loss)
I0503 12:50:18.191965  2066 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0503 12:51:01.218189  2066 solver.cpp:229] Iteration 13320, loss = 0.0257484
I0503 12:51:01.219406  2066 solver.cpp:245]     Train net output #0: loss = 0.0257484 (* 1 = 0.0257484 loss)
I0503 12:51:01.219425  2066 sgd_solver.cpp:106] Iteration 13320, lr = 0.01
I0503 12:51:44.244961  2066 solver.cpp:229] Iteration 13340, loss = 0.00262313
I0503 12:51:44.246106  2066 solver.cpp:245]     Train net output #0: loss = 0.00262312 (* 1 = 0.00262312 loss)
I0503 12:51:44.246124  2066 sgd_solver.cpp:106] Iteration 13340, lr = 0.01
I0503 12:52:27.273955  2066 solver.cpp:229] Iteration 13360, loss = 0.00114837
I0503 12:52:27.275061  2066 solver.cpp:245]     Train net output #0: loss = 0.00114836 (* 1 = 0.00114836 loss)
I0503 12:52:27.275079  2066 sgd_solver.cpp:106] Iteration 13360, lr = 0.01
I0503 12:53:10.299857  2066 solver.cpp:229] Iteration 13380, loss = 0.00315651
I0503 12:53:10.300920  2066 solver.cpp:245]     Train net output #0: loss = 0.0031565 (* 1 = 0.0031565 loss)
I0503 12:53:10.300936  2066 sgd_solver.cpp:106] Iteration 13380, lr = 0.01
I0503 12:53:53.326207  2066 solver.cpp:229] Iteration 13400, loss = 0.00207814
I0503 12:53:53.327324  2066 solver.cpp:245]     Train net output #0: loss = 0.00207813 (* 1 = 0.00207813 loss)
I0503 12:53:53.327342  2066 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0503 12:54:36.352382  2066 solver.cpp:229] Iteration 13420, loss = 0.00396079
I0503 12:54:36.353524  2066 solver.cpp:245]     Train net output #0: loss = 0.00396078 (* 1 = 0.00396078 loss)
I0503 12:54:36.353541  2066 sgd_solver.cpp:106] Iteration 13420, lr = 0.01
I0503 12:55:19.379683  2066 solver.cpp:229] Iteration 13440, loss = 0.00161763
I0503 12:55:19.380839  2066 solver.cpp:245]     Train net output #0: loss = 0.00161762 (* 1 = 0.00161762 loss)
I0503 12:55:19.380856  2066 sgd_solver.cpp:106] Iteration 13440, lr = 0.01
I0503 12:56:02.403913  2066 solver.cpp:229] Iteration 13460, loss = 0.00467504
I0503 12:56:02.405095  2066 solver.cpp:245]     Train net output #0: loss = 0.00467503 (* 1 = 0.00467503 loss)
I0503 12:56:02.405113  2066 sgd_solver.cpp:106] Iteration 13460, lr = 0.01
I0503 12:56:45.426456  2066 solver.cpp:229] Iteration 13480, loss = 0.00634503
I0503 12:56:45.427597  2066 solver.cpp:245]     Train net output #0: loss = 0.00634502 (* 1 = 0.00634502 loss)
I0503 12:56:45.427618  2066 sgd_solver.cpp:106] Iteration 13480, lr = 0.01
I0503 12:57:28.451354  2066 solver.cpp:229] Iteration 13500, loss = 0.0028958
I0503 12:57:28.452456  2066 solver.cpp:245]     Train net output #0: loss = 0.00289579 (* 1 = 0.00289579 loss)
I0503 12:57:28.452472  2066 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0503 12:58:11.475786  2066 solver.cpp:229] Iteration 13520, loss = 0.00195101
I0503 12:58:11.476979  2066 solver.cpp:245]     Train net output #0: loss = 0.001951 (* 1 = 0.001951 loss)
I0503 12:58:11.476999  2066 sgd_solver.cpp:106] Iteration 13520, lr = 0.01
I0503 12:58:54.500624  2066 solver.cpp:229] Iteration 13540, loss = 0.000730448
I0503 12:58:54.501698  2066 solver.cpp:245]     Train net output #0: loss = 0.000730441 (* 1 = 0.000730441 loss)
I0503 12:58:54.501713  2066 sgd_solver.cpp:106] Iteration 13540, lr = 0.01
I0503 12:59:37.524556  2066 solver.cpp:229] Iteration 13560, loss = 0.00278552
I0503 12:59:37.525601  2066 solver.cpp:245]     Train net output #0: loss = 0.00278551 (* 1 = 0.00278551 loss)
I0503 12:59:37.525619  2066 sgd_solver.cpp:106] Iteration 13560, lr = 0.01
I0503 13:00:20.549651  2066 solver.cpp:229] Iteration 13580, loss = 0.00236568
I0503 13:00:20.550797  2066 solver.cpp:245]     Train net output #0: loss = 0.00236567 (* 1 = 0.00236567 loss)
I0503 13:00:20.550815  2066 sgd_solver.cpp:106] Iteration 13580, lr = 0.01
I0503 13:01:03.574440  2066 solver.cpp:229] Iteration 13600, loss = 0.00386579
I0503 13:01:03.575567  2066 solver.cpp:245]     Train net output #0: loss = 0.00386578 (* 1 = 0.00386578 loss)
I0503 13:01:03.575584  2066 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0503 13:01:46.599395  2066 solver.cpp:229] Iteration 13620, loss = 0.0299356
I0503 13:01:46.600385  2066 solver.cpp:245]     Train net output #0: loss = 0.0299356 (* 1 = 0.0299356 loss)
I0503 13:01:46.600401  2066 sgd_solver.cpp:106] Iteration 13620, lr = 0.01
I0503 13:02:29.624532  2066 solver.cpp:229] Iteration 13640, loss = 0.00916117
I0503 13:02:29.625658  2066 solver.cpp:245]     Train net output #0: loss = 0.00916116 (* 1 = 0.00916116 loss)
I0503 13:02:29.625676  2066 sgd_solver.cpp:106] Iteration 13640, lr = 0.01
I0503 13:03:12.648701  2066 solver.cpp:229] Iteration 13660, loss = 0.000674595
I0503 13:03:12.649750  2066 solver.cpp:245]     Train net output #0: loss = 0.000674583 (* 1 = 0.000674583 loss)
I0503 13:03:12.649767  2066 sgd_solver.cpp:106] Iteration 13660, lr = 0.01
I0503 13:03:55.673845  2066 solver.cpp:229] Iteration 13680, loss = 0.00114052
I0503 13:03:55.674954  2066 solver.cpp:245]     Train net output #0: loss = 0.00114051 (* 1 = 0.00114051 loss)
I0503 13:03:55.674973  2066 sgd_solver.cpp:106] Iteration 13680, lr = 0.01
I0503 13:04:38.697880  2066 solver.cpp:229] Iteration 13700, loss = 0.00434722
I0503 13:04:38.698976  2066 solver.cpp:245]     Train net output #0: loss = 0.00434721 (* 1 = 0.00434721 loss)
I0503 13:04:38.698992  2066 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0503 13:05:21.721446  2066 solver.cpp:229] Iteration 13720, loss = 0.00170162
I0503 13:05:21.722591  2066 solver.cpp:245]     Train net output #0: loss = 0.00170161 (* 1 = 0.00170161 loss)
I0503 13:05:21.722610  2066 sgd_solver.cpp:106] Iteration 13720, lr = 0.01
I0503 13:06:04.746412  2066 solver.cpp:229] Iteration 13740, loss = 0.0009426
I0503 13:06:04.747630  2066 solver.cpp:245]     Train net output #0: loss = 0.000942586 (* 1 = 0.000942586 loss)
I0503 13:06:04.747648  2066 sgd_solver.cpp:106] Iteration 13740, lr = 0.01
I0503 13:06:47.770809  2066 solver.cpp:229] Iteration 13760, loss = 0.000813171
I0503 13:06:47.778143  2066 solver.cpp:245]     Train net output #0: loss = 0.000813157 (* 1 = 0.000813157 loss)
I0503 13:06:47.778162  2066 sgd_solver.cpp:106] Iteration 13760, lr = 0.01
I0503 13:07:30.797850  2066 solver.cpp:229] Iteration 13780, loss = 0.00277279
I0503 13:07:30.799098  2066 solver.cpp:245]     Train net output #0: loss = 0.00277278 (* 1 = 0.00277278 loss)
I0503 13:07:30.799121  2066 sgd_solver.cpp:106] Iteration 13780, lr = 0.01
I0503 13:08:13.824014  2066 solver.cpp:229] Iteration 13800, loss = 0.000694751
I0503 13:08:13.825139  2066 solver.cpp:245]     Train net output #0: loss = 0.000694742 (* 1 = 0.000694742 loss)
I0503 13:08:13.825157  2066 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0503 13:08:56.851019  2066 solver.cpp:229] Iteration 13820, loss = 0.00103978
I0503 13:08:56.852120  2066 solver.cpp:245]     Train net output #0: loss = 0.00103977 (* 1 = 0.00103977 loss)
I0503 13:08:56.852143  2066 sgd_solver.cpp:106] Iteration 13820, lr = 0.01
I0503 13:09:39.875532  2066 solver.cpp:229] Iteration 13840, loss = 0.0016667
I0503 13:09:39.876690  2066 solver.cpp:245]     Train net output #0: loss = 0.0016667 (* 1 = 0.0016667 loss)
I0503 13:09:39.876706  2066 sgd_solver.cpp:106] Iteration 13840, lr = 0.01
I0503 13:10:22.903162  2066 solver.cpp:229] Iteration 13860, loss = 0.011315
I0503 13:10:22.904480  2066 solver.cpp:245]     Train net output #0: loss = 0.011315 (* 1 = 0.011315 loss)
I0503 13:10:22.904500  2066 sgd_solver.cpp:106] Iteration 13860, lr = 0.01
I0503 13:11:05.927317  2066 solver.cpp:229] Iteration 13880, loss = 0.0246194
I0503 13:11:05.928390  2066 solver.cpp:245]     Train net output #0: loss = 0.0246193 (* 1 = 0.0246193 loss)
I0503 13:11:05.928409  2066 sgd_solver.cpp:106] Iteration 13880, lr = 0.01
I0503 13:11:48.951110  2066 solver.cpp:229] Iteration 13900, loss = 0.0164454
I0503 13:11:48.952219  2066 solver.cpp:245]     Train net output #0: loss = 0.0164454 (* 1 = 0.0164454 loss)
I0503 13:11:48.952234  2066 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0503 13:12:31.975595  2066 solver.cpp:229] Iteration 13920, loss = 0.00579491
I0503 13:12:31.976707  2066 solver.cpp:245]     Train net output #0: loss = 0.00579491 (* 1 = 0.00579491 loss)
I0503 13:12:31.976725  2066 sgd_solver.cpp:106] Iteration 13920, lr = 0.01
I0503 13:13:15.004190  2066 solver.cpp:229] Iteration 13940, loss = 0.000661848
I0503 13:13:15.005242  2066 solver.cpp:245]     Train net output #0: loss = 0.000661837 (* 1 = 0.000661837 loss)
I0503 13:13:15.005260  2066 sgd_solver.cpp:106] Iteration 13940, lr = 0.01
I0503 13:13:58.029399  2066 solver.cpp:229] Iteration 13960, loss = 0.00036096
I0503 13:13:58.030578  2066 solver.cpp:245]     Train net output #0: loss = 0.000360948 (* 1 = 0.000360948 loss)
I0503 13:13:58.030598  2066 sgd_solver.cpp:106] Iteration 13960, lr = 0.01
I0503 13:14:41.058933  2066 solver.cpp:229] Iteration 13980, loss = 0.00242684
I0503 13:14:41.059967  2066 solver.cpp:245]     Train net output #0: loss = 0.00242683 (* 1 = 0.00242683 loss)
I0503 13:14:41.059988  2066 sgd_solver.cpp:106] Iteration 13980, lr = 0.01
I0503 13:15:21.948196  2066 solver.cpp:338] Iteration 14000, Testing net (#0)
I0503 13:18:11.927173  2066 solver.cpp:406]     Test net output #0: accuracy = 0.996999
I0503 13:18:11.928374  2066 solver.cpp:406]     Test net output #1: loss = 0.0121267 (* 1 = 0.0121267 loss)
I0503 13:18:13.894706  2066 solver.cpp:229] Iteration 14000, loss = 0.00476027
I0503 13:18:13.894767  2066 solver.cpp:245]     Train net output #0: loss = 0.00476026 (* 1 = 0.00476026 loss)
I0503 13:18:13.894779  2066 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0503 13:18:56.921397  2066 solver.cpp:229] Iteration 14020, loss = 0.009554
I0503 13:18:56.922408  2066 solver.cpp:245]     Train net output #0: loss = 0.00955399 (* 1 = 0.00955399 loss)
I0503 13:18:56.922425  2066 sgd_solver.cpp:106] Iteration 14020, lr = 0.01
I0503 13:19:39.947496  2066 solver.cpp:229] Iteration 14040, loss = 0.00153296
I0503 13:19:39.948597  2066 solver.cpp:245]     Train net output #0: loss = 0.00153295 (* 1 = 0.00153295 loss)
I0503 13:19:39.948614  2066 sgd_solver.cpp:106] Iteration 14040, lr = 0.01
I0503 13:20:22.976574  2066 solver.cpp:229] Iteration 14060, loss = 0.00241873
I0503 13:20:22.977674  2066 solver.cpp:245]     Train net output #0: loss = 0.00241872 (* 1 = 0.00241872 loss)
I0503 13:20:22.977689  2066 sgd_solver.cpp:106] Iteration 14060, lr = 0.01
I0503 13:21:06.007493  2066 solver.cpp:229] Iteration 14080, loss = 0.00342696
I0503 13:21:06.008510  2066 solver.cpp:245]     Train net output #0: loss = 0.00342695 (* 1 = 0.00342695 loss)
I0503 13:21:06.008528  2066 sgd_solver.cpp:106] Iteration 14080, lr = 0.01
I0503 13:21:49.037138  2066 solver.cpp:229] Iteration 14100, loss = 0.00158151
I0503 13:21:49.038193  2066 solver.cpp:245]     Train net output #0: loss = 0.0015815 (* 1 = 0.0015815 loss)
I0503 13:21:49.038209  2066 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0503 13:22:32.070286  2066 solver.cpp:229] Iteration 14120, loss = 0.00353105
I0503 13:22:32.071389  2066 solver.cpp:245]     Train net output #0: loss = 0.00353104 (* 1 = 0.00353104 loss)
I0503 13:22:32.071408  2066 sgd_solver.cpp:106] Iteration 14120, lr = 0.01
I0503 13:23:15.101582  2066 solver.cpp:229] Iteration 14140, loss = 0.00241911
I0503 13:23:15.108937  2066 solver.cpp:245]     Train net output #0: loss = 0.0024191 (* 1 = 0.0024191 loss)
I0503 13:23:15.108953  2066 sgd_solver.cpp:106] Iteration 14140, lr = 0.01
I0503 13:23:58.131551  2066 solver.cpp:229] Iteration 14160, loss = 0.0131429
I0503 13:23:58.132645  2066 solver.cpp:245]     Train net output #0: loss = 0.0131429 (* 1 = 0.0131429 loss)
I0503 13:23:58.132663  2066 sgd_solver.cpp:106] Iteration 14160, lr = 0.01
I0503 13:24:41.160837  2066 solver.cpp:229] Iteration 14180, loss = 0.000390463
I0503 13:24:41.162017  2066 solver.cpp:245]     Train net output #0: loss = 0.000390455 (* 1 = 0.000390455 loss)
I0503 13:24:41.162034  2066 sgd_solver.cpp:106] Iteration 14180, lr = 0.01
I0503 13:25:24.196403  2066 solver.cpp:229] Iteration 14200, loss = 0.00973128
I0503 13:25:24.197551  2066 solver.cpp:245]     Train net output #0: loss = 0.00973126 (* 1 = 0.00973126 loss)
I0503 13:25:24.197568  2066 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0503 13:26:07.227658  2066 solver.cpp:229] Iteration 14220, loss = 0.020619
I0503 13:26:07.228795  2066 solver.cpp:245]     Train net output #0: loss = 0.020619 (* 1 = 0.020619 loss)
I0503 13:26:07.228811  2066 sgd_solver.cpp:106] Iteration 14220, lr = 0.01
I0503 13:26:50.258942  2066 solver.cpp:229] Iteration 14240, loss = 0.00455325
I0503 13:26:50.260102  2066 solver.cpp:245]     Train net output #0: loss = 0.00455324 (* 1 = 0.00455324 loss)
I0503 13:26:50.260120  2066 sgd_solver.cpp:106] Iteration 14240, lr = 0.01
I0503 13:27:33.290653  2066 solver.cpp:229] Iteration 14260, loss = 0.000601063
I0503 13:27:33.291787  2066 solver.cpp:245]     Train net output #0: loss = 0.00060105 (* 1 = 0.00060105 loss)
I0503 13:27:33.291803  2066 sgd_solver.cpp:106] Iteration 14260, lr = 0.01
I0503 13:28:16.324705  2066 solver.cpp:229] Iteration 14280, loss = 0.0077726
I0503 13:28:16.325770  2066 solver.cpp:245]     Train net output #0: loss = 0.00777259 (* 1 = 0.00777259 loss)
I0503 13:28:16.325788  2066 sgd_solver.cpp:106] Iteration 14280, lr = 0.01
I0503 13:28:59.356087  2066 solver.cpp:229] Iteration 14300, loss = 0.0182964
I0503 13:28:59.357403  2066 solver.cpp:245]     Train net output #0: loss = 0.0182964 (* 1 = 0.0182964 loss)
I0503 13:28:59.357571  2066 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0503 13:29:42.388972  2066 solver.cpp:229] Iteration 14320, loss = 0.00729467
I0503 13:29:42.390084  2066 solver.cpp:245]     Train net output #0: loss = 0.00729466 (* 1 = 0.00729466 loss)
I0503 13:29:42.390101  2066 sgd_solver.cpp:106] Iteration 14320, lr = 0.01
I0503 13:30:25.422482  2066 solver.cpp:229] Iteration 14340, loss = 0.000292615
I0503 13:30:25.423548  2066 solver.cpp:245]     Train net output #0: loss = 0.000292604 (* 1 = 0.000292604 loss)
I0503 13:30:25.423564  2066 sgd_solver.cpp:106] Iteration 14340, lr = 0.01
I0503 13:31:08.455174  2066 solver.cpp:229] Iteration 14360, loss = 0.00711471
I0503 13:31:08.456264  2066 solver.cpp:245]     Train net output #0: loss = 0.0071147 (* 1 = 0.0071147 loss)
I0503 13:31:08.456282  2066 sgd_solver.cpp:106] Iteration 14360, lr = 0.01
I0503 13:31:51.487887  2066 solver.cpp:229] Iteration 14380, loss = 0.00883451
I0503 13:31:51.488984  2066 solver.cpp:245]     Train net output #0: loss = 0.0088345 (* 1 = 0.0088345 loss)
I0503 13:31:51.489003  2066 sgd_solver.cpp:106] Iteration 14380, lr = 0.01
I0503 13:32:34.522824  2066 solver.cpp:229] Iteration 14400, loss = 0.00782707
I0503 13:32:34.523993  2066 solver.cpp:245]     Train net output #0: loss = 0.00782706 (* 1 = 0.00782706 loss)
I0503 13:32:34.524008  2066 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0503 13:33:17.556880  2066 solver.cpp:229] Iteration 14420, loss = 0.00142313
I0503 13:33:17.558075  2066 solver.cpp:245]     Train net output #0: loss = 0.00142311 (* 1 = 0.00142311 loss)
I0503 13:33:17.558096  2066 sgd_solver.cpp:106] Iteration 14420, lr = 0.01
I0503 13:34:00.590359  2066 solver.cpp:229] Iteration 14440, loss = 0.005703
I0503 13:34:00.591815  2066 solver.cpp:245]     Train net output #0: loss = 0.00570298 (* 1 = 0.00570298 loss)
I0503 13:34:00.591835  2066 sgd_solver.cpp:106] Iteration 14440, lr = 0.01
I0503 13:34:43.624671  2066 solver.cpp:229] Iteration 14460, loss = 0.000556684
I0503 13:34:43.625790  2066 solver.cpp:245]     Train net output #0: loss = 0.000556673 (* 1 = 0.000556673 loss)
I0503 13:34:43.625808  2066 sgd_solver.cpp:106] Iteration 14460, lr = 0.01
I0503 13:35:26.659752  2066 solver.cpp:229] Iteration 14480, loss = 0.00463145
I0503 13:35:26.660926  2066 solver.cpp:245]     Train net output #0: loss = 0.00463144 (* 1 = 0.00463144 loss)
I0503 13:35:26.660945  2066 sgd_solver.cpp:106] Iteration 14480, lr = 0.01
I0503 13:36:09.692983  2066 solver.cpp:229] Iteration 14500, loss = 0.00365792
I0503 13:36:09.694078  2066 solver.cpp:245]     Train net output #0: loss = 0.00365791 (* 1 = 0.00365791 loss)
I0503 13:36:09.694095  2066 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0503 13:36:52.726434  2066 solver.cpp:229] Iteration 14520, loss = 0.00418176
I0503 13:36:52.727496  2066 solver.cpp:245]     Train net output #0: loss = 0.00418175 (* 1 = 0.00418175 loss)
I0503 13:36:52.727514  2066 sgd_solver.cpp:106] Iteration 14520, lr = 0.01
I0503 13:37:35.761054  2066 solver.cpp:229] Iteration 14540, loss = 0.00354965
I0503 13:37:35.762163  2066 solver.cpp:245]     Train net output #0: loss = 0.00354964 (* 1 = 0.00354964 loss)
I0503 13:37:35.762179  2066 sgd_solver.cpp:106] Iteration 14540, lr = 0.01
I0503 13:38:18.796007  2066 solver.cpp:229] Iteration 14560, loss = 0.00123339
I0503 13:38:18.797107  2066 solver.cpp:245]     Train net output #0: loss = 0.00123337 (* 1 = 0.00123337 loss)
I0503 13:38:18.797124  2066 sgd_solver.cpp:106] Iteration 14560, lr = 0.01
I0503 13:39:01.830844  2066 solver.cpp:229] Iteration 14580, loss = 0.00958269
I0503 13:39:01.832093  2066 solver.cpp:245]     Train net output #0: loss = 0.00958268 (* 1 = 0.00958268 loss)
I0503 13:39:01.832108  2066 sgd_solver.cpp:106] Iteration 14580, lr = 0.01
I0503 13:39:44.863234  2066 solver.cpp:229] Iteration 14600, loss = 0.000785622
I0503 13:39:44.864370  2066 solver.cpp:245]     Train net output #0: loss = 0.000785611 (* 1 = 0.000785611 loss)
I0503 13:39:44.864389  2066 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0503 13:40:27.897969  2066 solver.cpp:229] Iteration 14620, loss = 0.00168809
I0503 13:40:27.899152  2066 solver.cpp:245]     Train net output #0: loss = 0.00168807 (* 1 = 0.00168807 loss)
I0503 13:40:27.899170  2066 sgd_solver.cpp:106] Iteration 14620, lr = 0.01
I0503 13:41:10.933374  2066 solver.cpp:229] Iteration 14640, loss = 0.00200679
I0503 13:41:10.934499  2066 solver.cpp:245]     Train net output #0: loss = 0.00200678 (* 1 = 0.00200678 loss)
I0503 13:41:10.934515  2066 sgd_solver.cpp:106] Iteration 14640, lr = 0.01
I0503 13:41:53.968472  2066 solver.cpp:229] Iteration 14660, loss = 0.00229893
I0503 13:41:53.969596  2066 solver.cpp:245]     Train net output #0: loss = 0.00229891 (* 1 = 0.00229891 loss)
I0503 13:41:53.969612  2066 sgd_solver.cpp:106] Iteration 14660, lr = 0.01
I0503 13:42:37.003334  2066 solver.cpp:229] Iteration 14680, loss = 0.00122073
I0503 13:42:37.004420  2066 solver.cpp:245]     Train net output #0: loss = 0.00122071 (* 1 = 0.00122071 loss)
I0503 13:42:37.004438  2066 sgd_solver.cpp:106] Iteration 14680, lr = 0.01
I0503 13:43:20.039337  2066 solver.cpp:229] Iteration 14700, loss = 0.00528403
I0503 13:43:20.040446  2066 solver.cpp:245]     Train net output #0: loss = 0.00528401 (* 1 = 0.00528401 loss)
I0503 13:43:20.040464  2066 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0503 13:44:03.074679  2066 solver.cpp:229] Iteration 14720, loss = 0.0014228
I0503 13:44:03.076735  2066 solver.cpp:245]     Train net output #0: loss = 0.00142279 (* 1 = 0.00142279 loss)
I0503 13:44:03.076751  2066 sgd_solver.cpp:106] Iteration 14720, lr = 0.01
I0503 13:44:46.109370  2066 solver.cpp:229] Iteration 14740, loss = 0.0235329
I0503 13:44:46.110467  2066 solver.cpp:245]     Train net output #0: loss = 0.0235329 (* 1 = 0.0235329 loss)
I0503 13:44:46.110483  2066 sgd_solver.cpp:106] Iteration 14740, lr = 0.01
I0503 13:45:29.143868  2066 solver.cpp:229] Iteration 14760, loss = 0.00578342
I0503 13:45:29.145005  2066 solver.cpp:245]     Train net output #0: loss = 0.00578341 (* 1 = 0.00578341 loss)
I0503 13:45:29.145023  2066 sgd_solver.cpp:106] Iteration 14760, lr = 0.01
I0503 13:46:12.178675  2066 solver.cpp:229] Iteration 14780, loss = 0.00416687
I0503 13:46:12.189467  2066 solver.cpp:245]     Train net output #0: loss = 0.00416686 (* 1 = 0.00416686 loss)
I0503 13:46:12.189484  2066 sgd_solver.cpp:106] Iteration 14780, lr = 0.01
I0503 13:46:55.211475  2066 solver.cpp:229] Iteration 14800, loss = 0.00154694
I0503 13:46:55.212544  2066 solver.cpp:245]     Train net output #0: loss = 0.00154693 (* 1 = 0.00154693 loss)
I0503 13:46:55.212560  2066 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0503 13:47:38.249235  2066 solver.cpp:229] Iteration 14820, loss = 0.0144952
I0503 13:47:38.250365  2066 solver.cpp:245]     Train net output #0: loss = 0.0144952 (* 1 = 0.0144952 loss)
I0503 13:47:38.250382  2066 sgd_solver.cpp:106] Iteration 14820, lr = 0.01
I0503 13:48:21.287340  2066 solver.cpp:229] Iteration 14840, loss = 0.00200988
I0503 13:48:21.288472  2066 solver.cpp:245]     Train net output #0: loss = 0.00200987 (* 1 = 0.00200987 loss)
I0503 13:48:21.288488  2066 sgd_solver.cpp:106] Iteration 14840, lr = 0.01
I0503 13:49:04.325520  2066 solver.cpp:229] Iteration 14860, loss = 0.00184138
I0503 13:49:04.326831  2066 solver.cpp:245]     Train net output #0: loss = 0.00184137 (* 1 = 0.00184137 loss)
I0503 13:49:04.326851  2066 sgd_solver.cpp:106] Iteration 14860, lr = 0.01
I0503 13:49:47.360986  2066 solver.cpp:229] Iteration 14880, loss = 0.00270703
I0503 13:49:47.362102  2066 solver.cpp:245]     Train net output #0: loss = 0.00270702 (* 1 = 0.00270702 loss)
I0503 13:49:47.362118  2066 sgd_solver.cpp:106] Iteration 14880, lr = 0.01
I0503 13:50:30.396491  2066 solver.cpp:229] Iteration 14900, loss = 0.0197654
I0503 13:50:30.397642  2066 solver.cpp:245]     Train net output #0: loss = 0.0197654 (* 1 = 0.0197654 loss)
I0503 13:50:30.397660  2066 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0503 13:51:13.432068  2066 solver.cpp:229] Iteration 14920, loss = 0.0115279
I0503 13:51:13.433143  2066 solver.cpp:245]     Train net output #0: loss = 0.0115279 (* 1 = 0.0115279 loss)
I0503 13:51:13.433161  2066 sgd_solver.cpp:106] Iteration 14920, lr = 0.01
I0503 13:51:56.468574  2066 solver.cpp:229] Iteration 14940, loss = 0.00130485
I0503 13:51:56.469606  2066 solver.cpp:245]     Train net output #0: loss = 0.00130483 (* 1 = 0.00130483 loss)
I0503 13:51:56.469624  2066 sgd_solver.cpp:106] Iteration 14940, lr = 0.01
I0503 13:52:39.505260  2066 solver.cpp:229] Iteration 14960, loss = 0.000658069
I0503 13:52:39.506372  2066 solver.cpp:245]     Train net output #0: loss = 0.000658051 (* 1 = 0.000658051 loss)
I0503 13:52:39.506391  2066 sgd_solver.cpp:106] Iteration 14960, lr = 0.01
I0503 13:53:22.542477  2066 solver.cpp:229] Iteration 14980, loss = 0.00358268
I0503 13:53:22.543565  2066 solver.cpp:245]     Train net output #0: loss = 0.00358266 (* 1 = 0.00358266 loss)
I0503 13:53:22.543581  2066 sgd_solver.cpp:106] Iteration 14980, lr = 0.01
I0503 13:54:03.436002  2066 solver.cpp:338] Iteration 15000, Testing net (#0)
I0503 13:56:53.419991  2066 solver.cpp:406]     Test net output #0: accuracy = 0.997659
I0503 13:56:53.421111  2066 solver.cpp:406]     Test net output #1: loss = 0.0106407 (* 1 = 0.0106407 loss)
I0503 13:56:55.387167  2066 solver.cpp:229] Iteration 15000, loss = 0.0409818
I0503 13:56:55.387230  2066 solver.cpp:245]     Train net output #0: loss = 0.0409818 (* 1 = 0.0409818 loss)
I0503 13:56:55.387244  2066 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0503 13:57:38.406672  2066 solver.cpp:229] Iteration 15020, loss = 0.00122528
I0503 13:57:38.407829  2066 solver.cpp:245]     Train net output #0: loss = 0.00122527 (* 1 = 0.00122527 loss)
I0503 13:57:38.407852  2066 sgd_solver.cpp:106] Iteration 15020, lr = 0.01
I0503 13:58:21.426082  2066 solver.cpp:229] Iteration 15040, loss = 0.0153514
I0503 13:58:21.427266  2066 solver.cpp:245]     Train net output #0: loss = 0.0153514 (* 1 = 0.0153514 loss)
I0503 13:58:21.427284  2066 sgd_solver.cpp:106] Iteration 15040, lr = 0.01
I0503 13:59:04.444357  2066 solver.cpp:229] Iteration 15060, loss = 0.000737061
I0503 13:59:04.445505  2066 solver.cpp:245]     Train net output #0: loss = 0.000737046 (* 1 = 0.000737046 loss)
I0503 13:59:04.445523  2066 sgd_solver.cpp:106] Iteration 15060, lr = 0.01
I0503 13:59:47.462002  2066 solver.cpp:229] Iteration 15080, loss = 0.00421268
I0503 13:59:47.463112  2066 solver.cpp:245]     Train net output #0: loss = 0.00421266 (* 1 = 0.00421266 loss)
I0503 13:59:47.463129  2066 sgd_solver.cpp:106] Iteration 15080, lr = 0.01
I0503 14:00:30.479912  2066 solver.cpp:229] Iteration 15100, loss = 0.00245181
I0503 14:00:30.481077  2066 solver.cpp:245]     Train net output #0: loss = 0.00245179 (* 1 = 0.00245179 loss)
I0503 14:00:30.481094  2066 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0503 14:01:13.495287  2066 solver.cpp:229] Iteration 15120, loss = 0.00141299
I0503 14:01:13.496402  2066 solver.cpp:245]     Train net output #0: loss = 0.00141297 (* 1 = 0.00141297 loss)
I0503 14:01:13.496419  2066 sgd_solver.cpp:106] Iteration 15120, lr = 0.01
I0503 14:01:56.513725  2066 solver.cpp:229] Iteration 15140, loss = 0.00193696
I0503 14:01:56.514811  2066 solver.cpp:245]     Train net output #0: loss = 0.00193695 (* 1 = 0.00193695 loss)
I0503 14:01:56.514827  2066 sgd_solver.cpp:106] Iteration 15140, lr = 0.01
I0503 14:02:39.531404  2066 solver.cpp:229] Iteration 15160, loss = 0.00151917
I0503 14:02:39.532616  2066 solver.cpp:245]     Train net output #0: loss = 0.00151915 (* 1 = 0.00151915 loss)
I0503 14:02:39.532634  2066 sgd_solver.cpp:106] Iteration 15160, lr = 0.01
I0503 14:03:22.550240  2066 solver.cpp:229] Iteration 15180, loss = 0.00253344
I0503 14:03:22.551301  2066 solver.cpp:245]     Train net output #0: loss = 0.00253343 (* 1 = 0.00253343 loss)
I0503 14:03:22.551317  2066 sgd_solver.cpp:106] Iteration 15180, lr = 0.01
I0503 14:04:05.572280  2066 solver.cpp:229] Iteration 15200, loss = 0.000514243
I0503 14:04:05.573302  2066 solver.cpp:245]     Train net output #0: loss = 0.000514228 (* 1 = 0.000514228 loss)
I0503 14:04:05.573318  2066 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0503 14:04:48.592651  2066 solver.cpp:229] Iteration 15220, loss = 0.00878698
I0503 14:04:48.593734  2066 solver.cpp:245]     Train net output #0: loss = 0.00878696 (* 1 = 0.00878696 loss)
I0503 14:04:48.593751  2066 sgd_solver.cpp:106] Iteration 15220, lr = 0.01
I0503 14:05:31.612401  2066 solver.cpp:229] Iteration 15240, loss = 0.00642017
I0503 14:05:31.613507  2066 solver.cpp:245]     Train net output #0: loss = 0.00642016 (* 1 = 0.00642016 loss)
I0503 14:05:31.613524  2066 sgd_solver.cpp:106] Iteration 15240, lr = 0.01
I0503 14:06:14.636754  2066 solver.cpp:229] Iteration 15260, loss = 0.00535277
I0503 14:06:14.638093  2066 solver.cpp:245]     Train net output #0: loss = 0.00535276 (* 1 = 0.00535276 loss)
I0503 14:06:14.638113  2066 sgd_solver.cpp:106] Iteration 15260, lr = 0.01
I0503 14:06:57.656222  2066 solver.cpp:229] Iteration 15280, loss = 0.0317952
I0503 14:06:57.657326  2066 solver.cpp:245]     Train net output #0: loss = 0.0317952 (* 1 = 0.0317952 loss)
I0503 14:06:57.657343  2066 sgd_solver.cpp:106] Iteration 15280, lr = 0.01
I0503 14:07:40.679096  2066 solver.cpp:229] Iteration 15300, loss = 0.010953
I0503 14:07:40.680210  2066 solver.cpp:245]     Train net output #0: loss = 0.010953 (* 1 = 0.010953 loss)
I0503 14:07:40.680227  2066 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0503 14:08:23.699764  2066 solver.cpp:229] Iteration 15320, loss = 0.0054542
I0503 14:08:23.709251  2066 solver.cpp:245]     Train net output #0: loss = 0.00545418 (* 1 = 0.00545418 loss)
I0503 14:08:23.709269  2066 sgd_solver.cpp:106] Iteration 15320, lr = 0.01
I0503 14:09:06.722692  2066 solver.cpp:229] Iteration 15340, loss = 0.000854878
I0503 14:09:06.723851  2066 solver.cpp:245]     Train net output #0: loss = 0.000854863 (* 1 = 0.000854863 loss)
I0503 14:09:06.723868  2066 sgd_solver.cpp:106] Iteration 15340, lr = 0.01
I0503 14:09:49.745376  2066 solver.cpp:229] Iteration 15360, loss = 0.00183658
I0503 14:09:49.746377  2066 solver.cpp:245]     Train net output #0: loss = 0.00183656 (* 1 = 0.00183656 loss)
I0503 14:09:49.746394  2066 sgd_solver.cpp:106] Iteration 15360, lr = 0.01
I0503 14:10:32.769248  2066 solver.cpp:229] Iteration 15380, loss = 0.00216637
I0503 14:10:32.770411  2066 solver.cpp:245]     Train net output #0: loss = 0.00216636 (* 1 = 0.00216636 loss)
I0503 14:10:32.770429  2066 sgd_solver.cpp:106] Iteration 15380, lr = 0.01
I0503 14:11:15.790166  2066 solver.cpp:229] Iteration 15400, loss = 0.00793228
I0503 14:11:15.791201  2066 solver.cpp:245]     Train net output #0: loss = 0.00793226 (* 1 = 0.00793226 loss)
I0503 14:11:15.791219  2066 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0503 14:11:58.813773  2066 solver.cpp:229] Iteration 15420, loss = 0.00260136
I0503 14:11:58.814971  2066 solver.cpp:245]     Train net output #0: loss = 0.00260135 (* 1 = 0.00260135 loss)
I0503 14:11:58.814987  2066 sgd_solver.cpp:106] Iteration 15420, lr = 0.01
I0503 14:12:41.836241  2066 solver.cpp:229] Iteration 15440, loss = 0.0100554
I0503 14:12:41.837461  2066 solver.cpp:245]     Train net output #0: loss = 0.0100554 (* 1 = 0.0100554 loss)
I0503 14:12:41.837477  2066 sgd_solver.cpp:106] Iteration 15440, lr = 0.01
I0503 14:13:24.859484  2066 solver.cpp:229] Iteration 15460, loss = 0.000794868
I0503 14:13:24.860587  2066 solver.cpp:245]     Train net output #0: loss = 0.000794854 (* 1 = 0.000794854 loss)
I0503 14:13:24.860606  2066 sgd_solver.cpp:106] Iteration 15460, lr = 0.01
I0503 14:14:07.883332  2066 solver.cpp:229] Iteration 15480, loss = 0.00125598
I0503 14:14:07.884508  2066 solver.cpp:245]     Train net output #0: loss = 0.00125597 (* 1 = 0.00125597 loss)
I0503 14:14:07.884526  2066 sgd_solver.cpp:106] Iteration 15480, lr = 0.01
I0503 14:14:50.905931  2066 solver.cpp:229] Iteration 15500, loss = 0.00182914
I0503 14:14:50.907016  2066 solver.cpp:245]     Train net output #0: loss = 0.00182912 (* 1 = 0.00182912 loss)
I0503 14:14:50.907038  2066 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0503 14:15:33.929432  2066 solver.cpp:229] Iteration 15520, loss = 0.0065731
I0503 14:15:33.930507  2066 solver.cpp:245]     Train net output #0: loss = 0.00657308 (* 1 = 0.00657308 loss)
I0503 14:15:33.930528  2066 sgd_solver.cpp:106] Iteration 15520, lr = 0.01
I0503 14:16:16.953559  2066 solver.cpp:229] Iteration 15540, loss = 0.0107515
I0503 14:16:16.954648  2066 solver.cpp:245]     Train net output #0: loss = 0.0107514 (* 1 = 0.0107514 loss)
I0503 14:16:16.954663  2066 sgd_solver.cpp:106] Iteration 15540, lr = 0.01
I0503 14:16:59.976161  2066 solver.cpp:229] Iteration 15560, loss = 0.000381142
I0503 14:16:59.977435  2066 solver.cpp:245]     Train net output #0: loss = 0.000381124 (* 1 = 0.000381124 loss)
I0503 14:16:59.977598  2066 sgd_solver.cpp:106] Iteration 15560, lr = 0.01
I0503 14:17:43.000774  2066 solver.cpp:229] Iteration 15580, loss = 0.00445523
I0503 14:17:43.001871  2066 solver.cpp:245]     Train net output #0: loss = 0.00445522 (* 1 = 0.00445522 loss)
I0503 14:17:43.001888  2066 sgd_solver.cpp:106] Iteration 15580, lr = 0.01
I0503 14:18:26.025153  2066 solver.cpp:229] Iteration 15600, loss = 0.00128257
I0503 14:18:26.026182  2066 solver.cpp:245]     Train net output #0: loss = 0.00128256 (* 1 = 0.00128256 loss)
I0503 14:18:26.026198  2066 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0503 14:19:09.051234  2066 solver.cpp:229] Iteration 15620, loss = 0.0028887
I0503 14:19:09.052312  2066 solver.cpp:245]     Train net output #0: loss = 0.00288869 (* 1 = 0.00288869 loss)
I0503 14:19:09.052330  2066 sgd_solver.cpp:106] Iteration 15620, lr = 0.01
I0503 14:19:52.075278  2066 solver.cpp:229] Iteration 15640, loss = 0.00384822
I0503 14:19:52.076478  2066 solver.cpp:245]     Train net output #0: loss = 0.00384821 (* 1 = 0.00384821 loss)
I0503 14:19:52.076498  2066 sgd_solver.cpp:106] Iteration 15640, lr = 0.01
I0503 14:20:35.100585  2066 solver.cpp:229] Iteration 15660, loss = 0.0259634
I0503 14:20:35.101788  2066 solver.cpp:245]     Train net output #0: loss = 0.0259634 (* 1 = 0.0259634 loss)
I0503 14:20:35.101814  2066 sgd_solver.cpp:106] Iteration 15660, lr = 0.01
I0503 14:21:18.122114  2066 solver.cpp:229] Iteration 15680, loss = 0.00931831
I0503 14:21:18.123093  2066 solver.cpp:245]     Train net output #0: loss = 0.0093183 (* 1 = 0.0093183 loss)
I0503 14:21:18.123111  2066 sgd_solver.cpp:106] Iteration 15680, lr = 0.01
I0503 14:22:01.144372  2066 solver.cpp:229] Iteration 15700, loss = 0.00909491
I0503 14:22:01.145593  2066 solver.cpp:245]     Train net output #0: loss = 0.0090949 (* 1 = 0.0090949 loss)
I0503 14:22:01.145611  2066 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0503 14:22:44.167387  2066 solver.cpp:229] Iteration 15720, loss = 0.0109783
I0503 14:22:44.168519  2066 solver.cpp:245]     Train net output #0: loss = 0.0109783 (* 1 = 0.0109783 loss)
I0503 14:22:44.168537  2066 sgd_solver.cpp:106] Iteration 15720, lr = 0.01
I0503 14:23:27.191665  2066 solver.cpp:229] Iteration 15740, loss = 0.00416475
I0503 14:23:27.192795  2066 solver.cpp:245]     Train net output #0: loss = 0.00416474 (* 1 = 0.00416474 loss)
I0503 14:23:27.192809  2066 sgd_solver.cpp:106] Iteration 15740, lr = 0.01
I0503 14:24:10.216716  2066 solver.cpp:229] Iteration 15760, loss = 0.000598665
I0503 14:24:10.217850  2066 solver.cpp:245]     Train net output #0: loss = 0.000598654 (* 1 = 0.000598654 loss)
I0503 14:24:10.217867  2066 sgd_solver.cpp:106] Iteration 15760, lr = 0.01
I0503 14:24:53.239867  2066 solver.cpp:229] Iteration 15780, loss = 0.00155541
I0503 14:24:53.240973  2066 solver.cpp:245]     Train net output #0: loss = 0.0015554 (* 1 = 0.0015554 loss)
I0503 14:24:53.240993  2066 sgd_solver.cpp:106] Iteration 15780, lr = 0.01
I0503 14:25:36.262645  2066 solver.cpp:229] Iteration 15800, loss = 0.00603458
I0503 14:25:36.263767  2066 solver.cpp:245]     Train net output #0: loss = 0.00603457 (* 1 = 0.00603457 loss)
I0503 14:25:36.263783  2066 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0503 14:26:19.285524  2066 solver.cpp:229] Iteration 15820, loss = 0.023398
I0503 14:26:19.286603  2066 solver.cpp:245]     Train net output #0: loss = 0.0233979 (* 1 = 0.0233979 loss)
I0503 14:26:19.286619  2066 sgd_solver.cpp:106] Iteration 15820, lr = 0.01
I0503 14:27:02.308480  2066 solver.cpp:229] Iteration 15840, loss = 0.0160134
I0503 14:27:02.309581  2066 solver.cpp:245]     Train net output #0: loss = 0.0160134 (* 1 = 0.0160134 loss)
I0503 14:27:02.309598  2066 sgd_solver.cpp:106] Iteration 15840, lr = 0.01
I0503 14:27:45.331776  2066 solver.cpp:229] Iteration 15860, loss = 0.0180594
I0503 14:27:45.332893  2066 solver.cpp:245]     Train net output #0: loss = 0.0180594 (* 1 = 0.0180594 loss)
I0503 14:27:45.332911  2066 sgd_solver.cpp:106] Iteration 15860, lr = 0.01
I0503 14:28:28.356804  2066 solver.cpp:229] Iteration 15880, loss = 0.0133332
I0503 14:28:28.357931  2066 solver.cpp:245]     Train net output #0: loss = 0.0133332 (* 1 = 0.0133332 loss)
I0503 14:28:28.357951  2066 sgd_solver.cpp:106] Iteration 15880, lr = 0.01
I0503 14:29:11.383610  2066 solver.cpp:229] Iteration 15900, loss = 0.00448369
I0503 14:29:11.384858  2066 solver.cpp:245]     Train net output #0: loss = 0.00448368 (* 1 = 0.00448368 loss)
I0503 14:29:11.384876  2066 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0503 14:29:54.408581  2066 solver.cpp:229] Iteration 15920, loss = 0.000711171
I0503 14:29:54.409574  2066 solver.cpp:245]     Train net output #0: loss = 0.000711163 (* 1 = 0.000711163 loss)
I0503 14:29:54.409590  2066 sgd_solver.cpp:106] Iteration 15920, lr = 0.01
I0503 14:30:37.433364  2066 solver.cpp:229] Iteration 15940, loss = 0.00117587
I0503 14:30:37.434473  2066 solver.cpp:245]     Train net output #0: loss = 0.00117587 (* 1 = 0.00117587 loss)
I0503 14:30:37.434489  2066 sgd_solver.cpp:106] Iteration 15940, lr = 0.01
I0503 14:31:20.458015  2066 solver.cpp:229] Iteration 15960, loss = 0.00587396
I0503 14:31:20.459157  2066 solver.cpp:245]     Train net output #0: loss = 0.00587395 (* 1 = 0.00587395 loss)
I0503 14:31:20.459177  2066 sgd_solver.cpp:106] Iteration 15960, lr = 0.01
I0503 14:32:03.484490  2066 solver.cpp:229] Iteration 15980, loss = 0.00113366
I0503 14:32:03.485652  2066 solver.cpp:245]     Train net output #0: loss = 0.00113365 (* 1 = 0.00113365 loss)
I0503 14:32:03.485668  2066 sgd_solver.cpp:106] Iteration 15980, lr = 0.01
I0503 14:32:44.367822  2066 solver.cpp:338] Iteration 16000, Testing net (#0)
I0503 14:35:34.414753  2066 solver.cpp:406]     Test net output #0: accuracy = 0.997279
I0503 14:35:34.415915  2066 solver.cpp:406]     Test net output #1: loss = 0.0123758 (* 1 = 0.0123758 loss)
I0503 14:35:36.381846  2066 solver.cpp:229] Iteration 16000, loss = 0.00193592
I0503 14:35:36.381909  2066 solver.cpp:245]     Train net output #0: loss = 0.00193591 (* 1 = 0.00193591 loss)
I0503 14:35:36.381923  2066 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0503 14:36:19.392150  2066 solver.cpp:229] Iteration 16020, loss = 0.00445541
I0503 14:36:19.393362  2066 solver.cpp:245]     Train net output #0: loss = 0.0044554 (* 1 = 0.0044554 loss)
I0503 14:36:19.393378  2066 sgd_solver.cpp:106] Iteration 16020, lr = 0.01
I0503 14:37:02.405551  2066 solver.cpp:229] Iteration 16040, loss = 0.00733963
I0503 14:37:02.406863  2066 solver.cpp:245]     Train net output #0: loss = 0.00733962 (* 1 = 0.00733962 loss)
I0503 14:37:02.406880  2066 sgd_solver.cpp:106] Iteration 16040, lr = 0.01
I0503 14:37:45.414428  2066 solver.cpp:229] Iteration 16060, loss = 0.000698219
I0503 14:37:45.415598  2066 solver.cpp:245]     Train net output #0: loss = 0.00069821 (* 1 = 0.00069821 loss)
I0503 14:37:45.415617  2066 sgd_solver.cpp:106] Iteration 16060, lr = 0.01
I0503 14:38:28.429551  2066 solver.cpp:229] Iteration 16080, loss = 0.00166661
I0503 14:38:28.430538  2066 solver.cpp:245]     Train net output #0: loss = 0.00166659 (* 1 = 0.00166659 loss)
I0503 14:38:28.430557  2066 sgd_solver.cpp:106] Iteration 16080, lr = 0.01
I0503 14:39:11.445622  2066 solver.cpp:229] Iteration 16100, loss = 0.00824871
I0503 14:39:11.446671  2066 solver.cpp:245]     Train net output #0: loss = 0.0082487 (* 1 = 0.0082487 loss)
I0503 14:39:11.446688  2066 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0503 14:39:54.458396  2066 solver.cpp:229] Iteration 16120, loss = 0.00533642
I0503 14:39:54.459571  2066 solver.cpp:245]     Train net output #0: loss = 0.0053364 (* 1 = 0.0053364 loss)
I0503 14:39:54.459590  2066 sgd_solver.cpp:106] Iteration 16120, lr = 0.01
I0503 14:40:37.471372  2066 solver.cpp:229] Iteration 16140, loss = 0.000602493
I0503 14:40:37.472445  2066 solver.cpp:245]     Train net output #0: loss = 0.00060248 (* 1 = 0.00060248 loss)
I0503 14:40:37.472460  2066 sgd_solver.cpp:106] Iteration 16140, lr = 0.01
I0503 14:41:20.486340  2066 solver.cpp:229] Iteration 16160, loss = 0.00399799
I0503 14:41:20.487499  2066 solver.cpp:245]     Train net output #0: loss = 0.00399798 (* 1 = 0.00399798 loss)
I0503 14:41:20.487516  2066 sgd_solver.cpp:106] Iteration 16160, lr = 0.01
I0503 14:42:03.502602  2066 solver.cpp:229] Iteration 16180, loss = 0.00362547
I0503 14:42:03.512996  2066 solver.cpp:245]     Train net output #0: loss = 0.00362545 (* 1 = 0.00362545 loss)
I0503 14:42:03.513015  2066 sgd_solver.cpp:106] Iteration 16180, lr = 0.01
I0503 14:42:46.515772  2066 solver.cpp:229] Iteration 16200, loss = 0.0147956
I0503 14:42:46.516854  2066 solver.cpp:245]     Train net output #0: loss = 0.0147956 (* 1 = 0.0147956 loss)
I0503 14:42:46.516870  2066 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0503 14:43:29.527323  2066 solver.cpp:229] Iteration 16220, loss = 0.0129832
I0503 14:43:29.528569  2066 solver.cpp:245]     Train net output #0: loss = 0.0129832 (* 1 = 0.0129832 loss)
I0503 14:43:29.528589  2066 sgd_solver.cpp:106] Iteration 16220, lr = 0.01
I0503 14:44:12.539111  2066 solver.cpp:229] Iteration 16240, loss = 0.00362759
I0503 14:44:12.540336  2066 solver.cpp:245]     Train net output #0: loss = 0.00362758 (* 1 = 0.00362758 loss)
I0503 14:44:12.540357  2066 sgd_solver.cpp:106] Iteration 16240, lr = 0.01
I0503 14:44:55.553812  2066 solver.cpp:229] Iteration 16260, loss = 0.0228537
I0503 14:44:55.554929  2066 solver.cpp:245]     Train net output #0: loss = 0.0228537 (* 1 = 0.0228537 loss)
I0503 14:44:55.554945  2066 sgd_solver.cpp:106] Iteration 16260, lr = 0.01
I0503 14:45:38.569214  2066 solver.cpp:229] Iteration 16280, loss = 0.0108506
I0503 14:45:38.570472  2066 solver.cpp:245]     Train net output #0: loss = 0.0108506 (* 1 = 0.0108506 loss)
I0503 14:45:38.570500  2066 sgd_solver.cpp:106] Iteration 16280, lr = 0.01
I0503 14:46:21.583231  2066 solver.cpp:229] Iteration 16300, loss = 0.00188342
I0503 14:46:21.584266  2066 solver.cpp:245]     Train net output #0: loss = 0.00188341 (* 1 = 0.00188341 loss)
I0503 14:46:21.584282  2066 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0503 14:47:04.601934  2066 solver.cpp:229] Iteration 16320, loss = 0.000949477
I0503 14:47:04.603099  2066 solver.cpp:245]     Train net output #0: loss = 0.000949468 (* 1 = 0.000949468 loss)
I0503 14:47:04.603118  2066 sgd_solver.cpp:106] Iteration 16320, lr = 0.01
I0503 14:47:47.617424  2066 solver.cpp:229] Iteration 16340, loss = 0.00254086
I0503 14:47:47.618602  2066 solver.cpp:245]     Train net output #0: loss = 0.00254084 (* 1 = 0.00254084 loss)
I0503 14:47:47.618620  2066 sgd_solver.cpp:106] Iteration 16340, lr = 0.01
I0503 14:48:30.638597  2066 solver.cpp:229] Iteration 16360, loss = 0.0284779
I0503 14:48:30.639807  2066 solver.cpp:245]     Train net output #0: loss = 0.0284779 (* 1 = 0.0284779 loss)
I0503 14:48:30.639824  2066 sgd_solver.cpp:106] Iteration 16360, lr = 0.01
I0503 14:49:13.656847  2066 solver.cpp:229] Iteration 16380, loss = 0.00133573
I0503 14:49:13.657986  2066 solver.cpp:245]     Train net output #0: loss = 0.00133572 (* 1 = 0.00133572 loss)
I0503 14:49:13.658004  2066 sgd_solver.cpp:106] Iteration 16380, lr = 0.01
I0503 14:49:56.677333  2066 solver.cpp:229] Iteration 16400, loss = 0.000968036
I0503 14:49:56.678426  2066 solver.cpp:245]     Train net output #0: loss = 0.000968027 (* 1 = 0.000968027 loss)
I0503 14:49:56.678447  2066 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0503 14:50:39.696252  2066 solver.cpp:229] Iteration 16420, loss = 0.0149075
I0503 14:50:39.697387  2066 solver.cpp:245]     Train net output #0: loss = 0.0149075 (* 1 = 0.0149075 loss)
I0503 14:50:39.697403  2066 sgd_solver.cpp:106] Iteration 16420, lr = 0.01
I0503 14:51:22.714779  2066 solver.cpp:229] Iteration 16440, loss = 0.00295912
I0503 14:51:22.715886  2066 solver.cpp:245]     Train net output #0: loss = 0.00295912 (* 1 = 0.00295912 loss)
I0503 14:51:22.715903  2066 sgd_solver.cpp:106] Iteration 16440, lr = 0.01
I0503 14:52:05.733309  2066 solver.cpp:229] Iteration 16460, loss = 0.00153327
I0503 14:52:05.734541  2066 solver.cpp:245]     Train net output #0: loss = 0.00153327 (* 1 = 0.00153327 loss)
I0503 14:52:05.734558  2066 sgd_solver.cpp:106] Iteration 16460, lr = 0.01
I0503 14:52:48.751214  2066 solver.cpp:229] Iteration 16480, loss = 0.0258968
I0503 14:52:48.752331  2066 solver.cpp:245]     Train net output #0: loss = 0.0258968 (* 1 = 0.0258968 loss)
I0503 14:52:48.752349  2066 sgd_solver.cpp:106] Iteration 16480, lr = 0.01
I0503 14:53:31.767959  2066 solver.cpp:229] Iteration 16500, loss = 0.00136975
I0503 14:53:31.769104  2066 solver.cpp:245]     Train net output #0: loss = 0.00136974 (* 1 = 0.00136974 loss)
I0503 14:53:31.769122  2066 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0503 14:54:14.785758  2066 solver.cpp:229] Iteration 16520, loss = 0.000611994
I0503 14:54:14.786869  2066 solver.cpp:245]     Train net output #0: loss = 0.000611989 (* 1 = 0.000611989 loss)
I0503 14:54:14.786885  2066 sgd_solver.cpp:106] Iteration 16520, lr = 0.01
I0503 14:54:57.804203  2066 solver.cpp:229] Iteration 16540, loss = 0.00194563
I0503 14:54:57.805280  2066 solver.cpp:245]     Train net output #0: loss = 0.00194562 (* 1 = 0.00194562 loss)
I0503 14:54:57.805297  2066 sgd_solver.cpp:106] Iteration 16540, lr = 0.01
I0503 14:55:40.822093  2066 solver.cpp:229] Iteration 16560, loss = 0.0023691
I0503 14:55:40.823237  2066 solver.cpp:245]     Train net output #0: loss = 0.00236909 (* 1 = 0.00236909 loss)
I0503 14:55:40.823253  2066 sgd_solver.cpp:106] Iteration 16560, lr = 0.01
I0503 14:56:23.841492  2066 solver.cpp:229] Iteration 16580, loss = 0.00652699
I0503 14:56:23.842593  2066 solver.cpp:245]     Train net output #0: loss = 0.00652699 (* 1 = 0.00652699 loss)
I0503 14:56:23.842610  2066 sgd_solver.cpp:106] Iteration 16580, lr = 0.01
I0503 14:57:06.855031  2066 solver.cpp:229] Iteration 16600, loss = 0.00461385
I0503 14:57:06.856158  2066 solver.cpp:245]     Train net output #0: loss = 0.00461384 (* 1 = 0.00461384 loss)
I0503 14:57:06.856175  2066 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0503 14:57:49.868391  2066 solver.cpp:229] Iteration 16620, loss = 0.00321247
I0503 14:57:49.869529  2066 solver.cpp:245]     Train net output #0: loss = 0.00321247 (* 1 = 0.00321247 loss)
I0503 14:57:49.869547  2066 sgd_solver.cpp:106] Iteration 16620, lr = 0.01
I0503 14:58:32.884196  2066 solver.cpp:229] Iteration 16640, loss = 0.00295501
I0503 14:58:32.885337  2066 solver.cpp:245]     Train net output #0: loss = 0.00295501 (* 1 = 0.00295501 loss)
I0503 14:58:32.885354  2066 sgd_solver.cpp:106] Iteration 16640, lr = 0.01
I0503 14:59:15.898130  2066 solver.cpp:229] Iteration 16660, loss = 0.000189974
I0503 14:59:15.899297  2066 solver.cpp:245]     Train net output #0: loss = 0.000189968 (* 1 = 0.000189968 loss)
I0503 14:59:15.899459  2066 sgd_solver.cpp:106] Iteration 16660, lr = 0.01
I0503 14:59:58.913472  2066 solver.cpp:229] Iteration 16680, loss = 0.00208715
I0503 14:59:58.914703  2066 solver.cpp:245]     Train net output #0: loss = 0.00208715 (* 1 = 0.00208715 loss)
I0503 14:59:58.914722  2066 sgd_solver.cpp:106] Iteration 16680, lr = 0.01
I0503 15:00:41.931236  2066 solver.cpp:229] Iteration 16700, loss = 0.00449988
I0503 15:00:41.932310  2066 solver.cpp:245]     Train net output #0: loss = 0.00449988 (* 1 = 0.00449988 loss)
I0503 15:00:41.932327  2066 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0503 15:01:24.947172  2066 solver.cpp:229] Iteration 16720, loss = 0.00278514
I0503 15:01:24.948302  2066 solver.cpp:245]     Train net output #0: loss = 0.00278514 (* 1 = 0.00278514 loss)
I0503 15:01:24.948319  2066 sgd_solver.cpp:106] Iteration 16720, lr = 0.01
I0503 15:02:07.967295  2066 solver.cpp:229] Iteration 16740, loss = 0.0103902
I0503 15:02:07.968524  2066 solver.cpp:245]     Train net output #0: loss = 0.0103902 (* 1 = 0.0103902 loss)
I0503 15:02:07.968545  2066 sgd_solver.cpp:106] Iteration 16740, lr = 0.01
I0503 15:02:50.987546  2066 solver.cpp:229] Iteration 16760, loss = 0.00345211
I0503 15:02:50.988795  2066 solver.cpp:245]     Train net output #0: loss = 0.0034521 (* 1 = 0.0034521 loss)
I0503 15:02:50.988955  2066 sgd_solver.cpp:106] Iteration 16760, lr = 0.01
I0503 15:03:34.007665  2066 solver.cpp:229] Iteration 16780, loss = 0.00797339
I0503 15:03:34.008817  2066 solver.cpp:245]     Train net output #0: loss = 0.00797338 (* 1 = 0.00797338 loss)
I0503 15:03:34.008834  2066 sgd_solver.cpp:106] Iteration 16780, lr = 0.01
I0503 15:04:17.027293  2066 solver.cpp:229] Iteration 16800, loss = 0.00206529
I0503 15:04:17.028395  2066 solver.cpp:245]     Train net output #0: loss = 0.00206528 (* 1 = 0.00206528 loss)
I0503 15:04:17.028411  2066 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0503 15:05:00.050094  2066 solver.cpp:229] Iteration 16820, loss = 0.00323119
I0503 15:05:00.059392  2066 solver.cpp:245]     Train net output #0: loss = 0.00323119 (* 1 = 0.00323119 loss)
I0503 15:05:00.059411  2066 sgd_solver.cpp:106] Iteration 16820, lr = 0.01
I0503 15:05:43.072110  2066 solver.cpp:229] Iteration 16840, loss = 0.0210382
I0503 15:05:43.073377  2066 solver.cpp:245]     Train net output #0: loss = 0.0210382 (* 1 = 0.0210382 loss)
I0503 15:05:43.073395  2066 sgd_solver.cpp:106] Iteration 16840, lr = 0.01
I0503 15:06:26.093874  2066 solver.cpp:229] Iteration 16860, loss = 0.0158022
I0503 15:06:26.095062  2066 solver.cpp:245]     Train net output #0: loss = 0.0158022 (* 1 = 0.0158022 loss)
I0503 15:06:26.095083  2066 sgd_solver.cpp:106] Iteration 16860, lr = 0.01
I0503 15:07:09.118479  2066 solver.cpp:229] Iteration 16880, loss = 0.00243428
I0503 15:07:09.119781  2066 solver.cpp:245]     Train net output #0: loss = 0.00243428 (* 1 = 0.00243428 loss)
I0503 15:07:09.119797  2066 sgd_solver.cpp:106] Iteration 16880, lr = 0.01
I0503 15:07:52.139612  2066 solver.cpp:229] Iteration 16900, loss = 0.00236966
I0503 15:07:52.140801  2066 solver.cpp:245]     Train net output #0: loss = 0.00236965 (* 1 = 0.00236965 loss)
I0503 15:07:52.140820  2066 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0503 15:08:35.161371  2066 solver.cpp:229] Iteration 16920, loss = 0.00112762
I0503 15:08:35.162849  2066 solver.cpp:245]     Train net output #0: loss = 0.00112761 (* 1 = 0.00112761 loss)
I0503 15:08:35.162865  2066 sgd_solver.cpp:106] Iteration 16920, lr = 0.01
I0503 15:09:18.184576  2066 solver.cpp:229] Iteration 16940, loss = 0.00124449
I0503 15:09:18.185740  2066 solver.cpp:245]     Train net output #0: loss = 0.00124448 (* 1 = 0.00124448 loss)
I0503 15:09:18.185758  2066 sgd_solver.cpp:106] Iteration 16940, lr = 0.01
I0503 15:10:01.209014  2066 solver.cpp:229] Iteration 16960, loss = 0.0107654
I0503 15:10:01.210275  2066 solver.cpp:245]     Train net output #0: loss = 0.0107654 (* 1 = 0.0107654 loss)
I0503 15:10:01.210295  2066 sgd_solver.cpp:106] Iteration 16960, lr = 0.01
I0503 15:10:44.231223  2066 solver.cpp:229] Iteration 16980, loss = 0.000774729
I0503 15:10:44.232313  2066 solver.cpp:245]     Train net output #0: loss = 0.00077472 (* 1 = 0.00077472 loss)
I0503 15:10:44.232332  2066 sgd_solver.cpp:106] Iteration 16980, lr = 0.01
I0503 15:11:25.110719  2066 solver.cpp:338] Iteration 17000, Testing net (#0)
I0503 15:14:15.023531  2066 solver.cpp:406]     Test net output #0: accuracy = 0.996799
I0503 15:14:15.024979  2066 solver.cpp:406]     Test net output #1: loss = 0.0114873 (* 1 = 0.0114873 loss)
I0503 15:14:16.991427  2066 solver.cpp:229] Iteration 17000, loss = 0.00312198
I0503 15:14:16.991489  2066 solver.cpp:245]     Train net output #0: loss = 0.00312197 (* 1 = 0.00312197 loss)
I0503 15:14:16.991505  2066 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0503 15:15:00.017709  2066 solver.cpp:229] Iteration 17020, loss = 0.000996391
I0503 15:15:00.018941  2066 solver.cpp:245]     Train net output #0: loss = 0.000996381 (* 1 = 0.000996381 loss)
I0503 15:15:00.018961  2066 sgd_solver.cpp:106] Iteration 17020, lr = 0.01
I0503 15:15:43.045073  2066 solver.cpp:229] Iteration 17040, loss = 0.0217235
I0503 15:15:43.048465  2066 solver.cpp:245]     Train net output #0: loss = 0.0217235 (* 1 = 0.0217235 loss)
I0503 15:15:43.048482  2066 sgd_solver.cpp:106] Iteration 17040, lr = 0.01
I0503 15:16:26.071081  2066 solver.cpp:229] Iteration 17060, loss = 0.0102844
I0503 15:16:26.072026  2066 solver.cpp:245]     Train net output #0: loss = 0.0102844 (* 1 = 0.0102844 loss)
I0503 15:16:26.072041  2066 sgd_solver.cpp:106] Iteration 17060, lr = 0.01
I0503 15:17:09.098690  2066 solver.cpp:229] Iteration 17080, loss = 0.0172449
I0503 15:17:09.099910  2066 solver.cpp:245]     Train net output #0: loss = 0.0172448 (* 1 = 0.0172448 loss)
I0503 15:17:09.099928  2066 sgd_solver.cpp:106] Iteration 17080, lr = 0.01
I0503 15:17:52.124444  2066 solver.cpp:229] Iteration 17100, loss = 0.00285274
I0503 15:17:52.125589  2066 solver.cpp:245]     Train net output #0: loss = 0.00285273 (* 1 = 0.00285273 loss)
I0503 15:17:52.125608  2066 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0503 15:18:35.150823  2066 solver.cpp:229] Iteration 17120, loss = 0.00201072
I0503 15:18:35.152010  2066 solver.cpp:245]     Train net output #0: loss = 0.00201071 (* 1 = 0.00201071 loss)
I0503 15:18:35.152029  2066 sgd_solver.cpp:106] Iteration 17120, lr = 0.01
I0503 15:19:18.176201  2066 solver.cpp:229] Iteration 17140, loss = 0.00110716
I0503 15:19:18.177358  2066 solver.cpp:245]     Train net output #0: loss = 0.00110715 (* 1 = 0.00110715 loss)
I0503 15:19:18.177377  2066 sgd_solver.cpp:106] Iteration 17140, lr = 0.01
I0503 15:20:01.205214  2066 solver.cpp:229] Iteration 17160, loss = 0.000755457
I0503 15:20:01.206495  2066 solver.cpp:245]     Train net output #0: loss = 0.000755446 (* 1 = 0.000755446 loss)
I0503 15:20:01.206516  2066 sgd_solver.cpp:106] Iteration 17160, lr = 0.01
I0503 15:20:44.232131  2066 solver.cpp:229] Iteration 17180, loss = 0.00894409
I0503 15:20:44.233302  2066 solver.cpp:245]     Train net output #0: loss = 0.00894408 (* 1 = 0.00894408 loss)
I0503 15:20:44.233319  2066 sgd_solver.cpp:106] Iteration 17180, lr = 0.01
I0503 15:21:27.258505  2066 solver.cpp:229] Iteration 17200, loss = 0.0023603
I0503 15:21:27.259655  2066 solver.cpp:245]     Train net output #0: loss = 0.00236029 (* 1 = 0.00236029 loss)
I0503 15:21:27.259671  2066 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0503 15:22:10.284900  2066 solver.cpp:229] Iteration 17220, loss = 0.0153479
I0503 15:22:10.285992  2066 solver.cpp:245]     Train net output #0: loss = 0.0153479 (* 1 = 0.0153479 loss)
I0503 15:22:10.286010  2066 sgd_solver.cpp:106] Iteration 17220, lr = 0.01
I0503 15:22:53.308645  2066 solver.cpp:229] Iteration 17240, loss = 0.00257374
I0503 15:22:53.309762  2066 solver.cpp:245]     Train net output #0: loss = 0.00257372 (* 1 = 0.00257372 loss)
I0503 15:22:53.309780  2066 sgd_solver.cpp:106] Iteration 17240, lr = 0.01
I0503 15:23:36.331926  2066 solver.cpp:229] Iteration 17260, loss = 0.00588922
I0503 15:23:36.332968  2066 solver.cpp:245]     Train net output #0: loss = 0.0058892 (* 1 = 0.0058892 loss)
I0503 15:23:36.332985  2066 sgd_solver.cpp:106] Iteration 17260, lr = 0.01
I0503 15:24:19.357646  2066 solver.cpp:229] Iteration 17280, loss = 0.00108795
I0503 15:24:19.358742  2066 solver.cpp:245]     Train net output #0: loss = 0.00108794 (* 1 = 0.00108794 loss)
I0503 15:24:19.358760  2066 sgd_solver.cpp:106] Iteration 17280, lr = 0.01
I0503 15:25:02.383523  2066 solver.cpp:229] Iteration 17300, loss = 0.00147888
I0503 15:25:02.384693  2066 solver.cpp:245]     Train net output #0: loss = 0.00147887 (* 1 = 0.00147887 loss)
I0503 15:25:02.384712  2066 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0503 15:25:45.405653  2066 solver.cpp:229] Iteration 17320, loss = 0.00447833
I0503 15:25:45.406653  2066 solver.cpp:245]     Train net output #0: loss = 0.00447831 (* 1 = 0.00447831 loss)
I0503 15:25:45.406671  2066 sgd_solver.cpp:106] Iteration 17320, lr = 0.01
I0503 15:26:28.428153  2066 solver.cpp:229] Iteration 17340, loss = 0.0188607
I0503 15:26:28.429309  2066 solver.cpp:245]     Train net output #0: loss = 0.0188607 (* 1 = 0.0188607 loss)
I0503 15:26:28.429329  2066 sgd_solver.cpp:106] Iteration 17340, lr = 0.01
I0503 15:27:11.450340  2066 solver.cpp:229] Iteration 17360, loss = 0.00424681
I0503 15:27:11.451541  2066 solver.cpp:245]     Train net output #0: loss = 0.0042468 (* 1 = 0.0042468 loss)
I0503 15:27:11.451558  2066 sgd_solver.cpp:106] Iteration 17360, lr = 0.01
I0503 15:27:54.472980  2066 solver.cpp:229] Iteration 17380, loss = 0.0112588
I0503 15:27:54.474061  2066 solver.cpp:245]     Train net output #0: loss = 0.0112588 (* 1 = 0.0112588 loss)
I0503 15:27:54.474077  2066 sgd_solver.cpp:106] Iteration 17380, lr = 0.01
I0503 15:28:37.497350  2066 solver.cpp:229] Iteration 17400, loss = 0.00309274
I0503 15:28:37.498456  2066 solver.cpp:245]     Train net output #0: loss = 0.00309273 (* 1 = 0.00309273 loss)
I0503 15:28:37.498473  2066 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0503 15:29:20.522328  2066 solver.cpp:229] Iteration 17420, loss = 0.0048458
I0503 15:29:20.523457  2066 solver.cpp:245]     Train net output #0: loss = 0.00484578 (* 1 = 0.00484578 loss)
I0503 15:29:20.523473  2066 sgd_solver.cpp:106] Iteration 17420, lr = 0.01
I0503 15:30:03.545575  2066 solver.cpp:229] Iteration 17440, loss = 0.00186219
I0503 15:30:03.546735  2066 solver.cpp:245]     Train net output #0: loss = 0.00186218 (* 1 = 0.00186218 loss)
I0503 15:30:03.546751  2066 sgd_solver.cpp:106] Iteration 17440, lr = 0.01
I0503 15:30:46.568698  2066 solver.cpp:229] Iteration 17460, loss = 0.00575037
I0503 15:30:46.569854  2066 solver.cpp:245]     Train net output #0: loss = 0.00575036 (* 1 = 0.00575036 loss)
I0503 15:30:46.569871  2066 sgd_solver.cpp:106] Iteration 17460, lr = 0.01
I0503 15:31:29.590032  2066 solver.cpp:229] Iteration 17480, loss = 0.00288677
I0503 15:31:29.591148  2066 solver.cpp:245]     Train net output #0: loss = 0.00288676 (* 1 = 0.00288676 loss)
I0503 15:31:29.591166  2066 sgd_solver.cpp:106] Iteration 17480, lr = 0.01
I0503 15:32:12.611765  2066 solver.cpp:229] Iteration 17500, loss = 0.00176573
I0503 15:32:12.612946  2066 solver.cpp:245]     Train net output #0: loss = 0.00176572 (* 1 = 0.00176572 loss)
I0503 15:32:12.612963  2066 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0503 15:32:55.631984  2066 solver.cpp:229] Iteration 17520, loss = 0.00176145
I0503 15:32:55.633280  2066 solver.cpp:245]     Train net output #0: loss = 0.00176143 (* 1 = 0.00176143 loss)
I0503 15:32:55.633299  2066 sgd_solver.cpp:106] Iteration 17520, lr = 0.01
I0503 15:33:38.655925  2066 solver.cpp:229] Iteration 17540, loss = 0.00673138
I0503 15:33:38.657068  2066 solver.cpp:245]     Train net output #0: loss = 0.00673137 (* 1 = 0.00673137 loss)
I0503 15:33:38.657088  2066 sgd_solver.cpp:106] Iteration 17540, lr = 0.01
I0503 15:34:21.678102  2066 solver.cpp:229] Iteration 17560, loss = 0.0016187
I0503 15:34:21.679152  2066 solver.cpp:245]     Train net output #0: loss = 0.00161869 (* 1 = 0.00161869 loss)
I0503 15:34:21.679169  2066 sgd_solver.cpp:106] Iteration 17560, lr = 0.01
I0503 15:35:04.702694  2066 solver.cpp:229] Iteration 17580, loss = 0.000478413
I0503 15:35:04.703817  2066 solver.cpp:245]     Train net output #0: loss = 0.000478402 (* 1 = 0.000478402 loss)
I0503 15:35:04.703835  2066 sgd_solver.cpp:106] Iteration 17580, lr = 0.01
I0503 15:35:47.725883  2066 solver.cpp:229] Iteration 17600, loss = 0.00723995
I0503 15:35:47.727025  2066 solver.cpp:245]     Train net output #0: loss = 0.00723994 (* 1 = 0.00723994 loss)
I0503 15:35:47.727046  2066 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0503 15:36:30.750962  2066 solver.cpp:229] Iteration 17620, loss = 0.00316762
I0503 15:36:30.752094  2066 solver.cpp:245]     Train net output #0: loss = 0.00316761 (* 1 = 0.00316761 loss)
I0503 15:36:30.752110  2066 sgd_solver.cpp:106] Iteration 17620, lr = 0.01
I0503 15:37:13.773483  2066 solver.cpp:229] Iteration 17640, loss = 0.00112702
I0503 15:37:13.774610  2066 solver.cpp:245]     Train net output #0: loss = 0.00112701 (* 1 = 0.00112701 loss)
I0503 15:37:13.774627  2066 sgd_solver.cpp:106] Iteration 17640, lr = 0.01
I0503 15:37:56.797495  2066 solver.cpp:229] Iteration 17660, loss = 0.00389572
I0503 15:37:56.798591  2066 solver.cpp:245]     Train net output #0: loss = 0.00389571 (* 1 = 0.00389571 loss)
I0503 15:37:56.798609  2066 sgd_solver.cpp:106] Iteration 17660, lr = 0.01
I0503 15:38:39.819316  2066 solver.cpp:229] Iteration 17680, loss = 0.00878158
I0503 15:38:39.820581  2066 solver.cpp:245]     Train net output #0: loss = 0.00878157 (* 1 = 0.00878157 loss)
I0503 15:38:39.820600  2066 sgd_solver.cpp:106] Iteration 17680, lr = 0.01
I0503 15:39:22.845854  2066 solver.cpp:229] Iteration 17700, loss = 0.00746632
I0503 15:39:22.846897  2066 solver.cpp:245]     Train net output #0: loss = 0.00746631 (* 1 = 0.00746631 loss)
I0503 15:39:22.846914  2066 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0503 15:40:05.869067  2066 solver.cpp:229] Iteration 17720, loss = 0.00349786
I0503 15:40:05.870203  2066 solver.cpp:245]     Train net output #0: loss = 0.00349785 (* 1 = 0.00349785 loss)
I0503 15:40:05.870220  2066 sgd_solver.cpp:106] Iteration 17720, lr = 0.01
I0503 15:40:48.894115  2066 solver.cpp:229] Iteration 17740, loss = 0.00217537
I0503 15:40:48.895282  2066 solver.cpp:245]     Train net output #0: loss = 0.00217536 (* 1 = 0.00217536 loss)
I0503 15:40:48.895299  2066 sgd_solver.cpp:106] Iteration 17740, lr = 0.01
I0503 15:41:31.916729  2066 solver.cpp:229] Iteration 17760, loss = 0.000403239
I0503 15:41:31.917745  2066 solver.cpp:245]     Train net output #0: loss = 0.000403232 (* 1 = 0.000403232 loss)
I0503 15:41:31.917764  2066 sgd_solver.cpp:106] Iteration 17760, lr = 0.01
I0503 15:42:14.944458  2066 solver.cpp:229] Iteration 17780, loss = 0.000929896
I0503 15:42:14.945559  2066 solver.cpp:245]     Train net output #0: loss = 0.000929889 (* 1 = 0.000929889 loss)
I0503 15:42:14.945576  2066 sgd_solver.cpp:106] Iteration 17780, lr = 0.01
I0503 15:42:57.966840  2066 solver.cpp:229] Iteration 17800, loss = 0.00265107
I0503 15:42:57.967939  2066 solver.cpp:245]     Train net output #0: loss = 0.00265107 (* 1 = 0.00265107 loss)
I0503 15:42:57.967957  2066 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0503 15:43:40.988831  2066 solver.cpp:229] Iteration 17820, loss = 0.00167845
I0503 15:43:40.989981  2066 solver.cpp:245]     Train net output #0: loss = 0.00167844 (* 1 = 0.00167844 loss)
I0503 15:43:40.990000  2066 sgd_solver.cpp:106] Iteration 17820, lr = 0.01
I0503 15:44:24.011761  2066 solver.cpp:229] Iteration 17840, loss = 0.00232943
I0503 15:44:24.012806  2066 solver.cpp:245]     Train net output #0: loss = 0.00232943 (* 1 = 0.00232943 loss)
I0503 15:44:24.012823  2066 sgd_solver.cpp:106] Iteration 17840, lr = 0.01
I0503 15:45:07.036447  2066 solver.cpp:229] Iteration 17860, loss = 0.00318865
I0503 15:45:07.037550  2066 solver.cpp:245]     Train net output #0: loss = 0.00318865 (* 1 = 0.00318865 loss)
I0503 15:45:07.037570  2066 sgd_solver.cpp:106] Iteration 17860, lr = 0.01
I0503 15:45:50.058524  2066 solver.cpp:229] Iteration 17880, loss = 0.000599701
I0503 15:45:50.059592  2066 solver.cpp:245]     Train net output #0: loss = 0.000599696 (* 1 = 0.000599696 loss)
I0503 15:45:50.059608  2066 sgd_solver.cpp:106] Iteration 17880, lr = 0.01
I0503 15:46:33.079761  2066 solver.cpp:229] Iteration 17900, loss = 0.0112471
I0503 15:46:33.080902  2066 solver.cpp:245]     Train net output #0: loss = 0.0112471 (* 1 = 0.0112471 loss)
I0503 15:46:33.080922  2066 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0503 15:47:16.098815  2066 solver.cpp:229] Iteration 17920, loss = 0.000476382
I0503 15:47:16.099928  2066 solver.cpp:245]     Train net output #0: loss = 0.000476377 (* 1 = 0.000476377 loss)
I0503 15:47:16.099944  2066 sgd_solver.cpp:106] Iteration 17920, lr = 0.01
I0503 15:47:59.117394  2066 solver.cpp:229] Iteration 17940, loss = 0.00202214
I0503 15:47:59.118654  2066 solver.cpp:245]     Train net output #0: loss = 0.00202214 (* 1 = 0.00202214 loss)
I0503 15:47:59.118677  2066 sgd_solver.cpp:106] Iteration 17940, lr = 0.01
I0503 15:48:42.137712  2066 solver.cpp:229] Iteration 17960, loss = 0.00254385
I0503 15:48:42.138983  2066 solver.cpp:245]     Train net output #0: loss = 0.00254385 (* 1 = 0.00254385 loss)
I0503 15:48:42.139000  2066 sgd_solver.cpp:106] Iteration 17960, lr = 0.01
I0503 15:49:25.160291  2066 solver.cpp:229] Iteration 17980, loss = 0.00395234
I0503 15:49:25.161422  2066 solver.cpp:245]     Train net output #0: loss = 0.00395234 (* 1 = 0.00395234 loss)
I0503 15:49:25.161438  2066 sgd_solver.cpp:106] Iteration 17980, lr = 0.01
I0503 15:50:06.040387  2066 solver.cpp:338] Iteration 18000, Testing net (#0)
I0503 15:52:55.855391  2066 solver.cpp:406]     Test net output #0: accuracy = 0.994898
I0503 15:52:55.856588  2066 solver.cpp:406]     Test net output #1: loss = 0.0196985 (* 1 = 0.0196985 loss)
I0503 15:52:57.822669  2066 solver.cpp:229] Iteration 18000, loss = 0.00854444
I0503 15:52:57.822731  2066 solver.cpp:245]     Train net output #0: loss = 0.00854444 (* 1 = 0.00854444 loss)
I0503 15:52:57.822744  2066 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0503 15:53:40.842674  2066 solver.cpp:229] Iteration 18020, loss = 0.00553907
I0503 15:53:40.843760  2066 solver.cpp:245]     Train net output #0: loss = 0.00553907 (* 1 = 0.00553907 loss)
I0503 15:53:40.843777  2066 sgd_solver.cpp:106] Iteration 18020, lr = 0.01
I0503 15:54:23.858718  2066 solver.cpp:229] Iteration 18040, loss = 0.00262146
I0503 15:54:23.859747  2066 solver.cpp:245]     Train net output #0: loss = 0.00262146 (* 1 = 0.00262146 loss)
I0503 15:54:23.859765  2066 sgd_solver.cpp:106] Iteration 18040, lr = 0.01
I0503 15:55:06.877197  2066 solver.cpp:229] Iteration 18060, loss = 0.00480632
I0503 15:55:06.878336  2066 solver.cpp:245]     Train net output #0: loss = 0.00480633 (* 1 = 0.00480633 loss)
I0503 15:55:06.878353  2066 sgd_solver.cpp:106] Iteration 18060, lr = 0.01
I0503 15:55:49.893656  2066 solver.cpp:229] Iteration 18080, loss = 0.0171629
I0503 15:55:49.894752  2066 solver.cpp:245]     Train net output #0: loss = 0.0171629 (* 1 = 0.0171629 loss)
I0503 15:55:49.894772  2066 sgd_solver.cpp:106] Iteration 18080, lr = 0.01
I0503 15:56:32.909145  2066 solver.cpp:229] Iteration 18100, loss = 0.010821
I0503 15:56:32.910320  2066 solver.cpp:245]     Train net output #0: loss = 0.010821 (* 1 = 0.010821 loss)
I0503 15:56:32.910336  2066 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0503 15:57:15.922518  2066 solver.cpp:229] Iteration 18120, loss = 0.00201855
I0503 15:57:15.923547  2066 solver.cpp:245]     Train net output #0: loss = 0.00201855 (* 1 = 0.00201855 loss)
I0503 15:57:15.923563  2066 sgd_solver.cpp:106] Iteration 18120, lr = 0.01
I0503 15:57:58.935467  2066 solver.cpp:229] Iteration 18140, loss = 0.00486226
I0503 15:57:58.936735  2066 solver.cpp:245]     Train net output #0: loss = 0.00486226 (* 1 = 0.00486226 loss)
I0503 15:57:58.936753  2066 sgd_solver.cpp:106] Iteration 18140, lr = 0.01
I0503 15:58:41.948796  2066 solver.cpp:229] Iteration 18160, loss = 0.0148853
I0503 15:58:41.949910  2066 solver.cpp:245]     Train net output #0: loss = 0.0148853 (* 1 = 0.0148853 loss)
I0503 15:58:41.949928  2066 sgd_solver.cpp:106] Iteration 18160, lr = 0.01
I0503 15:59:24.965085  2066 solver.cpp:229] Iteration 18180, loss = 0.000703745
I0503 15:59:24.966284  2066 solver.cpp:245]     Train net output #0: loss = 0.00070375 (* 1 = 0.00070375 loss)
I0503 15:59:24.966302  2066 sgd_solver.cpp:106] Iteration 18180, lr = 0.01
I0503 16:00:07.986855  2066 solver.cpp:229] Iteration 18200, loss = 0.0109929
I0503 16:00:07.988026  2066 solver.cpp:245]     Train net output #0: loss = 0.0109929 (* 1 = 0.0109929 loss)
I0503 16:00:07.988044  2066 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0503 16:00:51.010599  2066 solver.cpp:229] Iteration 18220, loss = 0.0031795
I0503 16:00:51.011792  2066 solver.cpp:245]     Train net output #0: loss = 0.00317951 (* 1 = 0.00317951 loss)
I0503 16:00:51.011811  2066 sgd_solver.cpp:106] Iteration 18220, lr = 0.01
I0503 16:01:34.032707  2066 solver.cpp:229] Iteration 18240, loss = 0.0038162
I0503 16:01:34.033835  2066 solver.cpp:245]     Train net output #0: loss = 0.0038162 (* 1 = 0.0038162 loss)
I0503 16:01:34.033854  2066 sgd_solver.cpp:106] Iteration 18240, lr = 0.01
I0503 16:02:17.052134  2066 solver.cpp:229] Iteration 18260, loss = 0.00242889
I0503 16:02:17.053369  2066 solver.cpp:245]     Train net output #0: loss = 0.00242889 (* 1 = 0.00242889 loss)
I0503 16:02:17.053387  2066 sgd_solver.cpp:106] Iteration 18260, lr = 0.01
I0503 16:03:00.072624  2066 solver.cpp:229] Iteration 18280, loss = 0.00881192
I0503 16:03:00.073832  2066 solver.cpp:245]     Train net output #0: loss = 0.00881192 (* 1 = 0.00881192 loss)
I0503 16:03:00.073848  2066 sgd_solver.cpp:106] Iteration 18280, lr = 0.01
I0503 16:03:43.093092  2066 solver.cpp:229] Iteration 18300, loss = 0.00667351
I0503 16:03:43.094389  2066 solver.cpp:245]     Train net output #0: loss = 0.00667352 (* 1 = 0.00667352 loss)
I0503 16:03:43.094408  2066 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0503 16:04:26.112303  2066 solver.cpp:229] Iteration 18320, loss = 0.00209089
I0503 16:04:26.113350  2066 solver.cpp:245]     Train net output #0: loss = 0.0020909 (* 1 = 0.0020909 loss)
I0503 16:04:26.113368  2066 sgd_solver.cpp:106] Iteration 18320, lr = 0.01
I0503 16:05:09.132812  2066 solver.cpp:229] Iteration 18340, loss = 0.00247331
I0503 16:05:09.133945  2066 solver.cpp:245]     Train net output #0: loss = 0.00247331 (* 1 = 0.00247331 loss)
I0503 16:05:09.133962  2066 sgd_solver.cpp:106] Iteration 18340, lr = 0.01
I0503 16:05:52.153177  2066 solver.cpp:229] Iteration 18360, loss = 0.0191333
I0503 16:05:52.154295  2066 solver.cpp:245]     Train net output #0: loss = 0.0191334 (* 1 = 0.0191334 loss)
I0503 16:05:52.154317  2066 sgd_solver.cpp:106] Iteration 18360, lr = 0.01
I0503 16:06:35.172245  2066 solver.cpp:229] Iteration 18380, loss = 0.00226236
I0503 16:06:35.183348  2066 solver.cpp:245]     Train net output #0: loss = 0.00226236 (* 1 = 0.00226236 loss)
I0503 16:06:35.183367  2066 sgd_solver.cpp:106] Iteration 18380, lr = 0.01
I0503 16:07:18.191728  2066 solver.cpp:229] Iteration 18400, loss = 0.0307195
I0503 16:07:18.192839  2066 solver.cpp:245]     Train net output #0: loss = 0.0307195 (* 1 = 0.0307195 loss)
I0503 16:07:18.192855  2066 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0503 16:08:01.208379  2066 solver.cpp:229] Iteration 18420, loss = 0.00262704
I0503 16:08:01.209585  2066 solver.cpp:245]     Train net output #0: loss = 0.00262704 (* 1 = 0.00262704 loss)
I0503 16:08:01.209604  2066 sgd_solver.cpp:106] Iteration 18420, lr = 0.01
I0503 16:08:44.223752  2066 solver.cpp:229] Iteration 18440, loss = 0.0143075
I0503 16:08:44.224951  2066 solver.cpp:245]     Train net output #0: loss = 0.0143075 (* 1 = 0.0143075 loss)
I0503 16:08:44.224968  2066 sgd_solver.cpp:106] Iteration 18440, lr = 0.01
I0503 16:09:27.239886  2066 solver.cpp:229] Iteration 18460, loss = 0.00341384
I0503 16:09:27.240985  2066 solver.cpp:245]     Train net output #0: loss = 0.00341385 (* 1 = 0.00341385 loss)
I0503 16:09:27.241001  2066 sgd_solver.cpp:106] Iteration 18460, lr = 0.01
I0503 16:10:10.256249  2066 solver.cpp:229] Iteration 18480, loss = 0.0133798
I0503 16:10:10.257341  2066 solver.cpp:245]     Train net output #0: loss = 0.0133798 (* 1 = 0.0133798 loss)
I0503 16:10:10.257360  2066 sgd_solver.cpp:106] Iteration 18480, lr = 0.01
I0503 16:10:53.275854  2066 solver.cpp:229] Iteration 18500, loss = 0.0195764
I0503 16:10:53.276968  2066 solver.cpp:245]     Train net output #0: loss = 0.0195764 (* 1 = 0.0195764 loss)
I0503 16:10:53.276985  2066 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0503 16:11:36.295521  2066 solver.cpp:229] Iteration 18520, loss = 0.00414355
I0503 16:11:36.296646  2066 solver.cpp:245]     Train net output #0: loss = 0.00414356 (* 1 = 0.00414356 loss)
I0503 16:11:36.296665  2066 sgd_solver.cpp:106] Iteration 18520, lr = 0.01
I0503 16:12:19.314862  2066 solver.cpp:229] Iteration 18540, loss = 0.00524378
I0503 16:12:19.316067  2066 solver.cpp:245]     Train net output #0: loss = 0.0052438 (* 1 = 0.0052438 loss)
I0503 16:12:19.316087  2066 sgd_solver.cpp:106] Iteration 18540, lr = 0.01
I0503 16:13:02.332195  2066 solver.cpp:229] Iteration 18560, loss = 0.000824052
I0503 16:13:02.333504  2066 solver.cpp:245]     Train net output #0: loss = 0.000824068 (* 1 = 0.000824068 loss)
I0503 16:13:02.333521  2066 sgd_solver.cpp:106] Iteration 18560, lr = 0.01
I0503 16:13:45.348449  2066 solver.cpp:229] Iteration 18580, loss = 0.0160684
I0503 16:13:45.349534  2066 solver.cpp:245]     Train net output #0: loss = 0.0160685 (* 1 = 0.0160685 loss)
I0503 16:13:45.349550  2066 sgd_solver.cpp:106] Iteration 18580, lr = 0.01
I0503 16:14:28.365756  2066 solver.cpp:229] Iteration 18600, loss = 0.00255475
I0503 16:14:28.366895  2066 solver.cpp:245]     Train net output #0: loss = 0.00255477 (* 1 = 0.00255477 loss)
I0503 16:14:28.366914  2066 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0503 16:15:11.384323  2066 solver.cpp:229] Iteration 18620, loss = 0.0228719
I0503 16:15:11.385459  2066 solver.cpp:245]     Train net output #0: loss = 0.022872 (* 1 = 0.022872 loss)
I0503 16:15:11.385478  2066 sgd_solver.cpp:106] Iteration 18620, lr = 0.01
I0503 16:15:54.402623  2066 solver.cpp:229] Iteration 18640, loss = 0.00462184
I0503 16:15:54.403790  2066 solver.cpp:245]     Train net output #0: loss = 0.00462185 (* 1 = 0.00462185 loss)
I0503 16:15:54.403806  2066 sgd_solver.cpp:106] Iteration 18640, lr = 0.01
I0503 16:16:37.420711  2066 solver.cpp:229] Iteration 18660, loss = 0.00875064
I0503 16:16:37.421839  2066 solver.cpp:245]     Train net output #0: loss = 0.00875065 (* 1 = 0.00875065 loss)
I0503 16:16:37.421856  2066 sgd_solver.cpp:106] Iteration 18660, lr = 0.01
I0503 16:17:20.440448  2066 solver.cpp:229] Iteration 18680, loss = 0.00605899
I0503 16:17:20.441690  2066 solver.cpp:245]     Train net output #0: loss = 0.006059 (* 1 = 0.006059 loss)
I0503 16:17:20.441709  2066 sgd_solver.cpp:106] Iteration 18680, lr = 0.01
I0503 16:18:03.462250  2066 solver.cpp:229] Iteration 18700, loss = 0.0171785
I0503 16:18:03.463554  2066 solver.cpp:245]     Train net output #0: loss = 0.0171785 (* 1 = 0.0171785 loss)
I0503 16:18:03.463573  2066 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0503 16:18:46.483280  2066 solver.cpp:229] Iteration 18720, loss = 0.00571662
I0503 16:18:46.484431  2066 solver.cpp:245]     Train net output #0: loss = 0.00571663 (* 1 = 0.00571663 loss)
I0503 16:18:46.484448  2066 sgd_solver.cpp:106] Iteration 18720, lr = 0.01
I0503 16:19:29.502395  2066 solver.cpp:229] Iteration 18740, loss = 0.00212661
I0503 16:19:29.503581  2066 solver.cpp:245]     Train net output #0: loss = 0.00212662 (* 1 = 0.00212662 loss)
I0503 16:19:29.503598  2066 sgd_solver.cpp:106] Iteration 18740, lr = 0.01
I0503 16:20:12.522922  2066 solver.cpp:229] Iteration 18760, loss = 0.000742436
I0503 16:20:12.524027  2066 solver.cpp:245]     Train net output #0: loss = 0.000742451 (* 1 = 0.000742451 loss)
I0503 16:20:12.524045  2066 sgd_solver.cpp:106] Iteration 18760, lr = 0.01
I0503 16:20:55.544215  2066 solver.cpp:229] Iteration 18780, loss = 0.0232267
I0503 16:20:55.545373  2066 solver.cpp:245]     Train net output #0: loss = 0.0232267 (* 1 = 0.0232267 loss)
I0503 16:20:55.545389  2066 sgd_solver.cpp:106] Iteration 18780, lr = 0.01
I0503 16:21:38.566181  2066 solver.cpp:229] Iteration 18800, loss = 0.0070556
I0503 16:21:38.567325  2066 solver.cpp:245]     Train net output #0: loss = 0.00705561 (* 1 = 0.00705561 loss)
I0503 16:21:38.567343  2066 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0503 16:22:21.588963  2066 solver.cpp:229] Iteration 18820, loss = 0.00368109
I0503 16:22:21.590034  2066 solver.cpp:245]     Train net output #0: loss = 0.0036811 (* 1 = 0.0036811 loss)
I0503 16:22:21.590050  2066 sgd_solver.cpp:106] Iteration 18820, lr = 0.01
I0503 16:23:04.610801  2066 solver.cpp:229] Iteration 18840, loss = 0.00190187
I0503 16:23:04.611942  2066 solver.cpp:245]     Train net output #0: loss = 0.00190188 (* 1 = 0.00190188 loss)
I0503 16:23:04.611958  2066 sgd_solver.cpp:106] Iteration 18840, lr = 0.01
I0503 16:23:47.630667  2066 solver.cpp:229] Iteration 18860, loss = 0.00592933
I0503 16:23:47.631772  2066 solver.cpp:245]     Train net output #0: loss = 0.00592934 (* 1 = 0.00592934 loss)
I0503 16:23:47.631789  2066 sgd_solver.cpp:106] Iteration 18860, lr = 0.01
I0503 16:24:30.649910  2066 solver.cpp:229] Iteration 18880, loss = 0.0053675
I0503 16:24:30.651010  2066 solver.cpp:245]     Train net output #0: loss = 0.00536751 (* 1 = 0.00536751 loss)
I0503 16:24:30.651027  2066 sgd_solver.cpp:106] Iteration 18880, lr = 0.01
I0503 16:25:13.671056  2066 solver.cpp:229] Iteration 18900, loss = 0.0052371
I0503 16:25:13.672241  2066 solver.cpp:245]     Train net output #0: loss = 0.00523711 (* 1 = 0.00523711 loss)
I0503 16:25:13.672257  2066 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0503 16:25:56.691463  2066 solver.cpp:229] Iteration 18920, loss = 0.00786594
I0503 16:25:56.692651  2066 solver.cpp:245]     Train net output #0: loss = 0.00786595 (* 1 = 0.00786595 loss)
I0503 16:25:56.692669  2066 sgd_solver.cpp:106] Iteration 18920, lr = 0.01
I0503 16:26:39.711436  2066 solver.cpp:229] Iteration 18940, loss = 0.00628545
I0503 16:26:39.712580  2066 solver.cpp:245]     Train net output #0: loss = 0.00628546 (* 1 = 0.00628546 loss)
I0503 16:26:39.712599  2066 sgd_solver.cpp:106] Iteration 18940, lr = 0.01
I0503 16:27:22.729763  2066 solver.cpp:229] Iteration 18960, loss = 0.00728333
I0503 16:27:22.730868  2066 solver.cpp:245]     Train net output #0: loss = 0.00728334 (* 1 = 0.00728334 loss)
I0503 16:27:22.730885  2066 sgd_solver.cpp:106] Iteration 18960, lr = 0.01
I0503 16:28:05.748903  2066 solver.cpp:229] Iteration 18980, loss = 0.00271106
I0503 16:28:05.750053  2066 solver.cpp:245]     Train net output #0: loss = 0.00271107 (* 1 = 0.00271107 loss)
I0503 16:28:05.750077  2066 sgd_solver.cpp:106] Iteration 18980, lr = 0.01
I0503 16:28:46.626756  2066 solver.cpp:338] Iteration 19000, Testing net (#0)
I0503 16:31:36.597538  2066 solver.cpp:406]     Test net output #0: accuracy = 0.997259
I0503 16:31:36.598764  2066 solver.cpp:406]     Test net output #1: loss = 0.0109609 (* 1 = 0.0109609 loss)
I0503 16:31:38.564942  2066 solver.cpp:229] Iteration 19000, loss = 0.00232391
I0503 16:31:38.565003  2066 solver.cpp:245]     Train net output #0: loss = 0.00232392 (* 1 = 0.00232392 loss)
I0503 16:31:38.565016  2066 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0503 16:32:21.588660  2066 solver.cpp:229] Iteration 19020, loss = 0.00240888
I0503 16:32:21.589794  2066 solver.cpp:245]     Train net output #0: loss = 0.00240889 (* 1 = 0.00240889 loss)
I0503 16:32:21.589812  2066 sgd_solver.cpp:106] Iteration 19020, lr = 0.01
I0503 16:33:04.612170  2066 solver.cpp:229] Iteration 19040, loss = 0.0121045
I0503 16:33:04.613301  2066 solver.cpp:245]     Train net output #0: loss = 0.0121045 (* 1 = 0.0121045 loss)
I0503 16:33:04.613317  2066 sgd_solver.cpp:106] Iteration 19040, lr = 0.01
I0503 16:33:47.637429  2066 solver.cpp:229] Iteration 19060, loss = 0.0143314
I0503 16:33:47.638588  2066 solver.cpp:245]     Train net output #0: loss = 0.0143314 (* 1 = 0.0143314 loss)
I0503 16:33:47.638607  2066 sgd_solver.cpp:106] Iteration 19060, lr = 0.01
I0503 16:34:30.658996  2066 solver.cpp:229] Iteration 19080, loss = 0.0012619
I0503 16:34:30.668427  2066 solver.cpp:245]     Train net output #0: loss = 0.0012619 (* 1 = 0.0012619 loss)
I0503 16:34:30.668444  2066 sgd_solver.cpp:106] Iteration 19080, lr = 0.01
I0503 16:35:13.682612  2066 solver.cpp:229] Iteration 19100, loss = 0.00756164
I0503 16:35:13.683737  2066 solver.cpp:245]     Train net output #0: loss = 0.00756164 (* 1 = 0.00756164 loss)
I0503 16:35:13.683754  2066 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0503 16:35:56.704686  2066 solver.cpp:229] Iteration 19120, loss = 0.0037327
I0503 16:35:56.705781  2066 solver.cpp:245]     Train net output #0: loss = 0.0037327 (* 1 = 0.0037327 loss)
I0503 16:35:56.705798  2066 sgd_solver.cpp:106] Iteration 19120, lr = 0.01
I0503 16:36:39.727329  2066 solver.cpp:229] Iteration 19140, loss = 0.00551534
I0503 16:36:39.728428  2066 solver.cpp:245]     Train net output #0: loss = 0.00551534 (* 1 = 0.00551534 loss)
I0503 16:36:39.728446  2066 sgd_solver.cpp:106] Iteration 19140, lr = 0.01
I0503 16:37:22.749842  2066 solver.cpp:229] Iteration 19160, loss = 0.00498207
I0503 16:37:22.750965  2066 solver.cpp:245]     Train net output #0: loss = 0.00498207 (* 1 = 0.00498207 loss)
I0503 16:37:22.750982  2066 sgd_solver.cpp:106] Iteration 19160, lr = 0.01
I0503 16:38:05.773191  2066 solver.cpp:229] Iteration 19180, loss = 0.00338195
I0503 16:38:05.774421  2066 solver.cpp:245]     Train net output #0: loss = 0.00338195 (* 1 = 0.00338195 loss)
I0503 16:38:05.774440  2066 sgd_solver.cpp:106] Iteration 19180, lr = 0.01
I0503 16:38:48.797227  2066 solver.cpp:229] Iteration 19200, loss = 0.00174187
I0503 16:38:48.798387  2066 solver.cpp:245]     Train net output #0: loss = 0.00174188 (* 1 = 0.00174188 loss)
I0503 16:38:48.798403  2066 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0503 16:39:31.820829  2066 solver.cpp:229] Iteration 19220, loss = 0.000558856
I0503 16:39:31.822001  2066 solver.cpp:245]     Train net output #0: loss = 0.00055886 (* 1 = 0.00055886 loss)
I0503 16:39:31.822021  2066 sgd_solver.cpp:106] Iteration 19220, lr = 0.01
I0503 16:40:14.844175  2066 solver.cpp:229] Iteration 19240, loss = 0.00186758
I0503 16:40:14.845275  2066 solver.cpp:245]     Train net output #0: loss = 0.00186758 (* 1 = 0.00186758 loss)
I0503 16:40:14.845293  2066 sgd_solver.cpp:106] Iteration 19240, lr = 0.01
I0503 16:40:57.866637  2066 solver.cpp:229] Iteration 19260, loss = 0.00859653
I0503 16:40:57.867770  2066 solver.cpp:245]     Train net output #0: loss = 0.00859653 (* 1 = 0.00859653 loss)
I0503 16:40:57.867787  2066 sgd_solver.cpp:106] Iteration 19260, lr = 0.01
I0503 16:41:40.890662  2066 solver.cpp:229] Iteration 19280, loss = 0.00757871
I0503 16:41:40.891793  2066 solver.cpp:245]     Train net output #0: loss = 0.00757872 (* 1 = 0.00757872 loss)
I0503 16:41:40.891811  2066 sgd_solver.cpp:106] Iteration 19280, lr = 0.01
I0503 16:42:23.916184  2066 solver.cpp:229] Iteration 19300, loss = 0.00236376
I0503 16:42:23.917312  2066 solver.cpp:245]     Train net output #0: loss = 0.00236377 (* 1 = 0.00236377 loss)
I0503 16:42:23.917330  2066 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0503 16:43:06.942992  2066 solver.cpp:229] Iteration 19320, loss = 0.00499565
I0503 16:43:06.944174  2066 solver.cpp:245]     Train net output #0: loss = 0.00499566 (* 1 = 0.00499566 loss)
I0503 16:43:06.944191  2066 sgd_solver.cpp:106] Iteration 19320, lr = 0.01
I0503 16:43:49.969102  2066 solver.cpp:229] Iteration 19340, loss = 0.00118061
I0503 16:43:49.970183  2066 solver.cpp:245]     Train net output #0: loss = 0.00118062 (* 1 = 0.00118062 loss)
I0503 16:43:49.970201  2066 sgd_solver.cpp:106] Iteration 19340, lr = 0.01
I0503 16:44:32.993391  2066 solver.cpp:229] Iteration 19360, loss = 0.00981271
I0503 16:44:32.994478  2066 solver.cpp:245]     Train net output #0: loss = 0.00981272 (* 1 = 0.00981272 loss)
I0503 16:44:32.994494  2066 sgd_solver.cpp:106] Iteration 19360, lr = 0.01
I0503 16:45:16.017457  2066 solver.cpp:229] Iteration 19380, loss = 0.0191085
I0503 16:45:16.018646  2066 solver.cpp:245]     Train net output #0: loss = 0.0191085 (* 1 = 0.0191085 loss)
I0503 16:45:16.018662  2066 sgd_solver.cpp:106] Iteration 19380, lr = 0.01
I0503 16:45:59.040308  2066 solver.cpp:229] Iteration 19400, loss = 0.00307782
I0503 16:45:59.041620  2066 solver.cpp:245]     Train net output #0: loss = 0.00307783 (* 1 = 0.00307783 loss)
I0503 16:45:59.041638  2066 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0503 16:46:42.065814  2066 solver.cpp:229] Iteration 19420, loss = 0.00338578
I0503 16:46:42.066949  2066 solver.cpp:245]     Train net output #0: loss = 0.00338579 (* 1 = 0.00338579 loss)
I0503 16:46:42.066967  2066 sgd_solver.cpp:106] Iteration 19420, lr = 0.01
I0503 16:47:25.091656  2066 solver.cpp:229] Iteration 19440, loss = 0.00315902
I0503 16:47:25.092742  2066 solver.cpp:245]     Train net output #0: loss = 0.00315903 (* 1 = 0.00315903 loss)
I0503 16:47:25.092759  2066 sgd_solver.cpp:106] Iteration 19440, lr = 0.01
I0503 16:48:08.117218  2066 solver.cpp:229] Iteration 19460, loss = 0.00841049
I0503 16:48:08.118247  2066 solver.cpp:245]     Train net output #0: loss = 0.0084105 (* 1 = 0.0084105 loss)
I0503 16:48:08.118263  2066 sgd_solver.cpp:106] Iteration 19460, lr = 0.01
I0503 16:48:51.147403  2066 solver.cpp:229] Iteration 19480, loss = 0.00517708
I0503 16:48:51.148530  2066 solver.cpp:245]     Train net output #0: loss = 0.0051771 (* 1 = 0.0051771 loss)
I0503 16:48:51.148548  2066 sgd_solver.cpp:106] Iteration 19480, lr = 0.01
I0503 16:49:34.177525  2066 solver.cpp:229] Iteration 19500, loss = 0.00458672
I0503 16:49:34.178622  2066 solver.cpp:245]     Train net output #0: loss = 0.00458673 (* 1 = 0.00458673 loss)
I0503 16:49:34.178637  2066 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0503 16:50:17.202985  2066 solver.cpp:229] Iteration 19520, loss = 0.00983467
I0503 16:50:17.204130  2066 solver.cpp:245]     Train net output #0: loss = 0.00983469 (* 1 = 0.00983469 loss)
I0503 16:50:17.204159  2066 sgd_solver.cpp:106] Iteration 19520, lr = 0.01
I0503 16:51:00.224823  2066 solver.cpp:229] Iteration 19540, loss = 0.00124976
I0503 16:51:00.226073  2066 solver.cpp:245]     Train net output #0: loss = 0.00124977 (* 1 = 0.00124977 loss)
I0503 16:51:00.226089  2066 sgd_solver.cpp:106] Iteration 19540, lr = 0.01
I0503 16:51:43.251770  2066 solver.cpp:229] Iteration 19560, loss = 0.00103604
I0503 16:51:43.252918  2066 solver.cpp:245]     Train net output #0: loss = 0.00103605 (* 1 = 0.00103605 loss)
I0503 16:51:43.252938  2066 sgd_solver.cpp:106] Iteration 19560, lr = 0.01
I0503 16:52:26.276993  2066 solver.cpp:229] Iteration 19580, loss = 0.0011545
I0503 16:52:26.278241  2066 solver.cpp:245]     Train net output #0: loss = 0.00115451 (* 1 = 0.00115451 loss)
I0503 16:52:26.278264  2066 sgd_solver.cpp:106] Iteration 19580, lr = 0.01
I0503 16:53:09.303009  2066 solver.cpp:229] Iteration 19600, loss = 0.00467727
I0503 16:53:09.304071  2066 solver.cpp:245]     Train net output #0: loss = 0.00467728 (* 1 = 0.00467728 loss)
I0503 16:53:09.304087  2066 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0503 16:53:52.326961  2066 solver.cpp:229] Iteration 19620, loss = 0.00709199
I0503 16:53:52.328114  2066 solver.cpp:245]     Train net output #0: loss = 0.007092 (* 1 = 0.007092 loss)
I0503 16:53:52.328131  2066 sgd_solver.cpp:106] Iteration 19620, lr = 0.01
I0503 16:54:35.349477  2066 solver.cpp:229] Iteration 19640, loss = 0.00389137
I0503 16:54:35.350528  2066 solver.cpp:245]     Train net output #0: loss = 0.00389137 (* 1 = 0.00389137 loss)
I0503 16:54:35.350544  2066 sgd_solver.cpp:106] Iteration 19640, lr = 0.01
I0503 16:55:18.374088  2066 solver.cpp:229] Iteration 19660, loss = 0.0230203
I0503 16:55:18.375236  2066 solver.cpp:245]     Train net output #0: loss = 0.0230203 (* 1 = 0.0230203 loss)
I0503 16:55:18.375255  2066 sgd_solver.cpp:106] Iteration 19660, lr = 0.01
I0503 16:56:01.400805  2066 solver.cpp:229] Iteration 19680, loss = 0.00267533
I0503 16:56:01.402076  2066 solver.cpp:245]     Train net output #0: loss = 0.00267534 (* 1 = 0.00267534 loss)
I0503 16:56:01.402093  2066 sgd_solver.cpp:106] Iteration 19680, lr = 0.01
I0503 16:56:44.426391  2066 solver.cpp:229] Iteration 19700, loss = 0.00263387
I0503 16:56:44.427489  2066 solver.cpp:245]     Train net output #0: loss = 0.00263387 (* 1 = 0.00263387 loss)
I0503 16:56:44.427506  2066 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0503 16:57:27.454535  2066 solver.cpp:229] Iteration 19720, loss = 0.00641636
I0503 16:57:27.455678  2066 solver.cpp:245]     Train net output #0: loss = 0.00641636 (* 1 = 0.00641636 loss)
I0503 16:57:27.455696  2066 sgd_solver.cpp:106] Iteration 19720, lr = 0.01
I0503 16:58:10.482458  2066 solver.cpp:229] Iteration 19740, loss = 0.0010014
I0503 16:58:10.483556  2066 solver.cpp:245]     Train net output #0: loss = 0.0010014 (* 1 = 0.0010014 loss)
I0503 16:58:10.483573  2066 sgd_solver.cpp:106] Iteration 19740, lr = 0.01
I0503 16:58:53.508955  2066 solver.cpp:229] Iteration 19760, loss = 0.0051209
I0503 16:58:53.510057  2066 solver.cpp:245]     Train net output #0: loss = 0.0051209 (* 1 = 0.0051209 loss)
I0503 16:58:53.510076  2066 sgd_solver.cpp:106] Iteration 19760, lr = 0.01
I0503 16:59:36.536224  2066 solver.cpp:229] Iteration 19780, loss = 0.013769
I0503 16:59:36.537276  2066 solver.cpp:245]     Train net output #0: loss = 0.013769 (* 1 = 0.013769 loss)
I0503 16:59:36.537292  2066 sgd_solver.cpp:106] Iteration 19780, lr = 0.01
I0503 17:00:19.563580  2066 solver.cpp:229] Iteration 19800, loss = 0.00589989
I0503 17:00:19.564808  2066 solver.cpp:245]     Train net output #0: loss = 0.00589989 (* 1 = 0.00589989 loss)
I0503 17:00:19.564826  2066 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0503 17:01:02.593525  2066 solver.cpp:229] Iteration 19820, loss = 0.00255088
I0503 17:01:02.594686  2066 solver.cpp:245]     Train net output #0: loss = 0.00255089 (* 1 = 0.00255089 loss)
I0503 17:01:02.594704  2066 sgd_solver.cpp:106] Iteration 19820, lr = 0.01
I0503 17:01:45.624529  2066 solver.cpp:229] Iteration 19840, loss = 0.00167901
I0503 17:01:45.625478  2066 solver.cpp:245]     Train net output #0: loss = 0.00167901 (* 1 = 0.00167901 loss)
I0503 17:01:45.625494  2066 sgd_solver.cpp:106] Iteration 19840, lr = 0.01
I0503 17:02:28.651423  2066 solver.cpp:229] Iteration 19860, loss = 0.00414622
I0503 17:02:28.652523  2066 solver.cpp:245]     Train net output #0: loss = 0.00414622 (* 1 = 0.00414622 loss)
I0503 17:02:28.652541  2066 sgd_solver.cpp:106] Iteration 19860, lr = 0.01
I0503 17:03:11.679003  2066 solver.cpp:229] Iteration 19880, loss = 0.00918379
I0503 17:03:11.680130  2066 solver.cpp:245]     Train net output #0: loss = 0.0091838 (* 1 = 0.0091838 loss)
I0503 17:03:11.680148  2066 sgd_solver.cpp:106] Iteration 19880, lr = 0.01
I0503 17:03:54.708223  2066 solver.cpp:229] Iteration 19900, loss = 0.00104092
I0503 17:03:54.709314  2066 solver.cpp:245]     Train net output #0: loss = 0.00104093 (* 1 = 0.00104093 loss)
I0503 17:03:54.709333  2066 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0503 17:04:37.736847  2066 solver.cpp:229] Iteration 19920, loss = 0.0022046
I0503 17:04:37.737931  2066 solver.cpp:245]     Train net output #0: loss = 0.0022046 (* 1 = 0.0022046 loss)
I0503 17:04:37.737948  2066 sgd_solver.cpp:106] Iteration 19920, lr = 0.01
I0503 17:05:20.762980  2066 solver.cpp:229] Iteration 19940, loss = 0.011001
I0503 17:05:20.764111  2066 solver.cpp:245]     Train net output #0: loss = 0.011001 (* 1 = 0.011001 loss)
I0503 17:05:20.764128  2066 sgd_solver.cpp:106] Iteration 19940, lr = 0.01
I0503 17:06:03.792006  2066 solver.cpp:229] Iteration 19960, loss = 0.00181735
I0503 17:06:03.793123  2066 solver.cpp:245]     Train net output #0: loss = 0.00181735 (* 1 = 0.00181735 loss)
I0503 17:06:03.793139  2066 sgd_solver.cpp:106] Iteration 19960, lr = 0.01
I0503 17:06:46.821213  2066 solver.cpp:229] Iteration 19980, loss = 0.00623136
I0503 17:06:46.822427  2066 solver.cpp:245]     Train net output #0: loss = 0.00623136 (* 1 = 0.00623136 loss)
I0503 17:06:46.822444  2066 sgd_solver.cpp:106] Iteration 19980, lr = 0.01
I0503 17:07:27.705274  2066 solver.cpp:456] Snapshotting to binary proto file /home/user012/caffe/models/driving_caffenet/driving_caffenet_iter_20000.caffemodel
I0503 17:07:35.837554  2066 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/user012/caffe/models/driving_caffenet/driving_caffenet_iter_20000.solverstate
I0503 17:07:43.129495  2066 solver.cpp:338] Iteration 20000, Testing net (#0)
I0503 17:10:32.782757  2066 solver.cpp:406]     Test net output #0: accuracy = 0.995979
I0503 17:10:32.783946  2066 solver.cpp:406]     Test net output #1: loss = 0.0170025 (* 1 = 0.0170025 loss)
I0503 17:10:34.749655  2066 solver.cpp:229] Iteration 20000, loss = 0.0112622
I0503 17:10:34.749719  2066 solver.cpp:245]     Train net output #0: loss = 0.0112622 (* 1 = 0.0112622 loss)
I0503 17:10:34.749733  2066 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0503 17:11:17.761831  2066 solver.cpp:229] Iteration 20020, loss = 0.0277686
I0503 17:11:17.763038  2066 solver.cpp:245]     Train net output #0: loss = 0.0277686 (* 1 = 0.0277686 loss)
I0503 17:11:17.763056  2066 sgd_solver.cpp:106] Iteration 20020, lr = 0.01
I0503 17:12:00.775846  2066 solver.cpp:229] Iteration 20040, loss = 0.00113494
I0503 17:12:00.777078  2066 solver.cpp:245]     Train net output #0: loss = 0.00113494 (* 1 = 0.00113494 loss)
I0503 17:12:00.777096  2066 sgd_solver.cpp:106] Iteration 20040, lr = 0.01
I0503 17:12:43.791100  2066 solver.cpp:229] Iteration 20060, loss = 0.025462
I0503 17:12:43.792273  2066 solver.cpp:245]     Train net output #0: loss = 0.025462 (* 1 = 0.025462 loss)
I0503 17:12:43.792291  2066 sgd_solver.cpp:106] Iteration 20060, lr = 0.01
I0503 17:13:26.804982  2066 solver.cpp:229] Iteration 20080, loss = 0.0180307
I0503 17:13:26.806139  2066 solver.cpp:245]     Train net output #0: loss = 0.0180307 (* 1 = 0.0180307 loss)
I0503 17:13:26.806157  2066 sgd_solver.cpp:106] Iteration 20080, lr = 0.01
I0503 17:14:09.818161  2066 solver.cpp:229] Iteration 20100, loss = 0.00419163
I0503 17:14:09.819372  2066 solver.cpp:245]     Train net output #0: loss = 0.00419163 (* 1 = 0.00419163 loss)
I0503 17:14:09.819391  2066 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0503 17:14:52.831362  2066 solver.cpp:229] Iteration 20120, loss = 0.00167807
I0503 17:14:52.832412  2066 solver.cpp:245]     Train net output #0: loss = 0.00167807 (* 1 = 0.00167807 loss)
I0503 17:14:52.832428  2066 sgd_solver.cpp:106] Iteration 20120, lr = 0.01
I0503 17:15:35.845376  2066 solver.cpp:229] Iteration 20140, loss = 0.00172647
I0503 17:15:35.846459  2066 solver.cpp:245]     Train net output #0: loss = 0.00172647 (* 1 = 0.00172647 loss)
I0503 17:15:35.846477  2066 sgd_solver.cpp:106] Iteration 20140, lr = 0.01
I0503 17:16:18.857434  2066 solver.cpp:229] Iteration 20160, loss = 0.00663512
I0503 17:16:18.858541  2066 solver.cpp:245]     Train net output #0: loss = 0.00663512 (* 1 = 0.00663512 loss)
I0503 17:16:18.858561  2066 sgd_solver.cpp:106] Iteration 20160, lr = 0.01
I0503 17:17:01.873806  2066 solver.cpp:229] Iteration 20180, loss = 0.000495654
I0503 17:17:01.874989  2066 solver.cpp:245]     Train net output #0: loss = 0.00049565 (* 1 = 0.00049565 loss)
I0503 17:17:01.875005  2066 sgd_solver.cpp:106] Iteration 20180, lr = 0.01
I0503 17:17:44.887635  2066 solver.cpp:229] Iteration 20200, loss = 0.00452488
I0503 17:17:44.888785  2066 solver.cpp:245]     Train net output #0: loss = 0.00452488 (* 1 = 0.00452488 loss)
I0503 17:17:44.888804  2066 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0503 17:18:27.898990  2066 solver.cpp:229] Iteration 20220, loss = 0.00214163
I0503 17:18:27.900100  2066 solver.cpp:245]     Train net output #0: loss = 0.00214163 (* 1 = 0.00214163 loss)
I0503 17:18:27.900116  2066 sgd_solver.cpp:106] Iteration 20220, lr = 0.01
I0503 17:19:10.912350  2066 solver.cpp:229] Iteration 20240, loss = 0.00679225
I0503 17:19:10.913542  2066 solver.cpp:245]     Train net output #0: loss = 0.00679224 (* 1 = 0.00679224 loss)
I0503 17:19:10.913559  2066 sgd_solver.cpp:106] Iteration 20240, lr = 0.01
I0503 17:19:53.928822  2066 solver.cpp:229] Iteration 20260, loss = 0.0097077
I0503 17:19:53.929944  2066 solver.cpp:245]     Train net output #0: loss = 0.00970769 (* 1 = 0.00970769 loss)
I0503 17:19:53.929960  2066 sgd_solver.cpp:106] Iteration 20260, lr = 0.01
I0503 17:20:36.945336  2066 solver.cpp:229] Iteration 20280, loss = 0.00284816
I0503 17:20:36.946455  2066 solver.cpp:245]     Train net output #0: loss = 0.00284816 (* 1 = 0.00284816 loss)
I0503 17:20:36.946471  2066 sgd_solver.cpp:106] Iteration 20280, lr = 0.01
I0503 17:21:19.958842  2066 solver.cpp:229] Iteration 20300, loss = 0.000434036
I0503 17:21:19.959946  2066 solver.cpp:245]     Train net output #0: loss = 0.000434032 (* 1 = 0.000434032 loss)
I0503 17:21:19.959964  2066 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0503 17:22:02.975688  2066 solver.cpp:229] Iteration 20320, loss = 0.000801303
I0503 17:22:02.976857  2066 solver.cpp:245]     Train net output #0: loss = 0.0008013 (* 1 = 0.0008013 loss)
I0503 17:22:02.976874  2066 sgd_solver.cpp:106] Iteration 20320, lr = 0.01
I0503 17:22:45.994372  2066 solver.cpp:229] Iteration 20340, loss = 0.00165547
I0503 17:22:45.995481  2066 solver.cpp:245]     Train net output #0: loss = 0.00165546 (* 1 = 0.00165546 loss)
I0503 17:22:45.995498  2066 sgd_solver.cpp:106] Iteration 20340, lr = 0.01
I0503 17:23:29.009717  2066 solver.cpp:229] Iteration 20360, loss = 0.00337731
I0503 17:23:29.010844  2066 solver.cpp:245]     Train net output #0: loss = 0.0033773 (* 1 = 0.0033773 loss)
I0503 17:23:29.010861  2066 sgd_solver.cpp:106] Iteration 20360, lr = 0.01
I0503 17:24:12.025190  2066 solver.cpp:229] Iteration 20380, loss = 0.000164178
I0503 17:24:12.026516  2066 solver.cpp:245]     Train net output #0: loss = 0.000164172 (* 1 = 0.000164172 loss)
I0503 17:24:12.026533  2066 sgd_solver.cpp:106] Iteration 20380, lr = 0.01
I0503 17:24:55.042369  2066 solver.cpp:229] Iteration 20400, loss = 0.00111993
I0503 17:24:55.043517  2066 solver.cpp:245]     Train net output #0: loss = 0.00111992 (* 1 = 0.00111992 loss)
I0503 17:24:55.043534  2066 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0503 17:25:38.055359  2066 solver.cpp:229] Iteration 20420, loss = 0.0111727
I0503 17:25:38.067245  2066 solver.cpp:245]     Train net output #0: loss = 0.0111727 (* 1 = 0.0111727 loss)
I0503 17:25:38.067262  2066 sgd_solver.cpp:106] Iteration 20420, lr = 0.01
